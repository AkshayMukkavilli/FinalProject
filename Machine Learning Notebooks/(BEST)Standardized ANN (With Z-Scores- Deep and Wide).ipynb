{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the same Artificial Neural Networks as in ANN(Deep and Wide with High Nodes Vs Low Nodes) but we will scale the dataset using StandardScaler from sklearn and also use the dataset with Z_Scores of Words and Helpful Votes\n",
    "\n",
    "TARGET LABEL: Z_Score_HelpfulVotes\n",
    "\n",
    "SCALER: STANDARD SCALER\n",
    "\n",
    "ANN'S : Combination 1:  7-100-100-1\n",
    "\n",
    "        Combination 2:  7-4-4-1\n",
    "        \n",
    "        Combination 3:  7-50-100-200-100-50-20-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Stars', 'Helpful Votes', 'Z_Score_HelpfulVotes', 'Words',\n",
      "       'Z_Score_Words', 'Paragraphs', 'No.break tags', 'Percentage_Upper_Case',\n",
      "       'Percentage_Lower_Case', 'Avg_len_paragraph_per_review'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Z_Score_Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Z_Score_HelpfulVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6.453577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>3087.000000</td>\n",
       "      <td>-0.235881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.394079</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.915696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.666459</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>468.500000</td>\n",
       "      <td>1.491485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.525083</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>394.272727</td>\n",
       "      <td>5.522007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.795826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>0.339908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Z_Score_Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0      3       6.453577           1              0                      3   \n",
       "1      5       1.394079           3              4                      3   \n",
       "2      4       3.666459           4              6                      4   \n",
       "3      4       8.525083          11             20                      3   \n",
       "4      5       1.795826           2              1                      6   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  Z_Score_HelpfulVotes  \n",
       "0                     93                   3087.000000             -0.235881  \n",
       "1                     91                    300.000000              0.915696  \n",
       "2                     90                    468.500000              1.491485  \n",
       "3                     91                    394.272727              5.522007  \n",
       "4                     91                    492.000000              0.339908  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'../FinalFeatures.csv')\n",
    "\n",
    "# The below line of code is to keep the z-scores of helpful votes and words and remove the actual values.\n",
    "\n",
    "print(dataset.columns)\n",
    "dataset = dataset[['Stars','Z_Score_Words', 'Paragraphs','No.break tags','Percentage_Upper_Case','Percentage_Lower_Case','Avg_len_paragraph_per_review','Z_Score_HelpfulVotes']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the independant variables from the dependant variable which is \"Helpful Votes\" in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting the data into training data and testing data\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "\"\"\"Scaling the data using StandardScaler from sklearn package\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing keras and other required functions\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 5s 202us/step - loss: 0.1554\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.1030\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0911\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.1152\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0818\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0603\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0749\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0864\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0555\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0661\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0590\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0581\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0514\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0651\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 5s 213us/step - loss: 0.0567\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0552\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0444\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0451\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0362\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0369\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0669\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0524\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 4s 185us/step - loss: 0.0519\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0438\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0517\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0432\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0727\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0310\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0365\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 4s 185us/step - loss: 0.0413\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0681\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0453\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0500\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0370\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0366\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0297\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.1197\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0326 0s -\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0386\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0605\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0372\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.2231\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0192\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0475\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0270\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0253\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0293\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0289\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0439\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0258\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0138\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0425\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0191\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0401\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0265\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0391\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0264\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0318\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0145\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0366\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.1000\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0610 0s - loss: 0\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0254\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0273\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0384\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0315\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0271\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0196\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0314\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0325\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0193\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 5s 196us/step - loss: 0.0220\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0220\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0229\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0327\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 5s 203us/step - loss: 0.0138\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0223\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 5s 202us/step - loss: 0.0123\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0118\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0109\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 5s 196us/step - loss: 0.0219\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0370\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0176\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0099\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0311\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 5s 196us/step - loss: 0.0141\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0183\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0249\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0157\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0091\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 5s 196us/step - loss: 0.0294\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0159\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0162\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0143\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0289\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0088\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0166\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0109\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0312\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13543c630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with high number of nodes \"\"\"\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.209429</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219773</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251528</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.173415</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217526</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.309311</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207300</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.206587</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227348</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256143</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212372</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.119941</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201796</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209598</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259842</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222351</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214430</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.946555</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.199806</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220372</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.269090</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>2.107028</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.237179</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227821</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221704</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218955</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222808</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.126996</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259277</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217007</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.233952</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>15.151163</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215166</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.394597</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.239176</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222131</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251556</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.245409</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.203469</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246392</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201367</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215343</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216478</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.085208</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220350</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.087921</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259045</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248661</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.241152</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211192</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211907</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204529</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.196163</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.245442</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217087</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209441</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.258057</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208314</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.209429            0.032207   \n",
       "1         -0.211198         -0.219773            0.032207   \n",
       "2         -0.258092         -0.251528            0.032207   \n",
       "3         -0.196210         -0.173415            0.032207   \n",
       "4         -0.211198         -0.217526            0.032207   \n",
       "5          1.425145          1.309311            0.032207   \n",
       "6         -0.211198         -0.207300            0.032207   \n",
       "7         -0.235881         -0.206587            0.032207   \n",
       "8         -0.211198         -0.227348            0.032207   \n",
       "9         -0.258092         -0.256143            0.032207   \n",
       "10        -0.211198         -0.212372            0.032207   \n",
       "11         3.879658          2.119941            0.032207   \n",
       "12        -0.211198         -0.201796            0.032207   \n",
       "13        -0.211198         -0.209598            0.032207   \n",
       "14        -0.258092         -0.259842            0.032207   \n",
       "15        -0.211198         -0.222351            0.032207   \n",
       "16        -0.211198         -0.214430            0.032207   \n",
       "17         2.243316          1.946555            0.032207   \n",
       "18        -0.211198         -0.199806            0.032207   \n",
       "19        -0.211198         -0.220372            0.032207   \n",
       "20        -0.258092         -0.269090            0.032207   \n",
       "21         2.243316          2.107028            0.032207   \n",
       "22        -0.258092         -0.237179            0.032207   \n",
       "23        -0.211198         -0.227821            0.032207   \n",
       "24        -0.211198         -0.221704            0.032207   \n",
       "25        -0.211198         -0.218955            0.032207   \n",
       "26        -0.211198         -0.222808            0.032207   \n",
       "27         0.821420          0.832354            0.032207   \n",
       "28         0.101746          0.126996            0.032207   \n",
       "29        -0.258092         -0.259277            0.032207   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.217007            0.032207   \n",
       "6062      -0.258092         -0.233952            0.032207   \n",
       "6063      16.152226         15.151163            0.032207   \n",
       "6064      -0.211198         -0.215166            0.032207   \n",
       "6065       0.461583          0.394597            0.032207   \n",
       "6066      -0.258092         -0.239176            0.032207   \n",
       "6067      -0.211198         -0.222131            0.032207   \n",
       "6068      -0.258092         -0.251556            0.032207   \n",
       "6069      -0.258092         -0.245409            0.032207   \n",
       "6070      -0.211198         -0.203469            0.032207   \n",
       "6071      -0.258092         -0.246392            0.032207   \n",
       "6072      -0.211198         -0.201367            0.032207   \n",
       "6073      -0.211198         -0.215343            0.032207   \n",
       "6074      -0.211198         -0.216478            0.032207   \n",
       "6075       3.061487          2.085208            0.032207   \n",
       "6076      -0.211198         -0.220350            0.032207   \n",
       "6077      -0.211198         -0.207203            0.032207   \n",
       "6078       0.101746          0.087921            0.032207   \n",
       "6079      -0.258092         -0.259045            0.032207   \n",
       "6080      -0.258092         -0.248661            0.032207   \n",
       "6081      -0.258092         -0.241152            0.032207   \n",
       "6082      -0.211198         -0.211192            0.032207   \n",
       "6083      -0.211198         -0.211907            0.032207   \n",
       "6084      -0.211198         -0.204529            0.032207   \n",
       "6085      -0.211198         -0.196163            0.032207   \n",
       "6086      -0.258092         -0.245442            0.032207   \n",
       "6087      -0.211198         -0.217087            0.032207   \n",
       "6088      -0.211198         -0.209441            0.032207   \n",
       "6089      -0.258092         -0.258057            0.032207   \n",
       "6090      -0.211198         -0.208314            0.032207   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.179464  \n",
       "1                    0.179464  \n",
       "2                    0.179464  \n",
       "3                    0.179464  \n",
       "4                    0.179464  \n",
       "5                    0.179464  \n",
       "6                    0.179464  \n",
       "7                    0.179464  \n",
       "8                    0.179464  \n",
       "9                    0.179464  \n",
       "10                   0.179464  \n",
       "11                   0.179464  \n",
       "12                   0.179464  \n",
       "13                   0.179464  \n",
       "14                   0.179464  \n",
       "15                   0.179464  \n",
       "16                   0.179464  \n",
       "17                   0.179464  \n",
       "18                   0.179464  \n",
       "19                   0.179464  \n",
       "20                   0.179464  \n",
       "21                   0.179464  \n",
       "22                   0.179464  \n",
       "23                   0.179464  \n",
       "24                   0.179464  \n",
       "25                   0.179464  \n",
       "26                   0.179464  \n",
       "27                   0.179464  \n",
       "28                   0.179464  \n",
       "29                   0.179464  \n",
       "...                       ...  \n",
       "6061                 0.179464  \n",
       "6062                 0.179464  \n",
       "6063                 0.179464  \n",
       "6064                 0.179464  \n",
       "6065                 0.179464  \n",
       "6066                 0.179464  \n",
       "6067                 0.179464  \n",
       "6068                 0.179464  \n",
       "6069                 0.179464  \n",
       "6070                 0.179464  \n",
       "6071                 0.179464  \n",
       "6072                 0.179464  \n",
       "6073                 0.179464  \n",
       "6074                 0.179464  \n",
       "6075                 0.179464  \n",
       "6076                 0.179464  \n",
       "6077                 0.179464  \n",
       "6078                 0.179464  \n",
       "6079                 0.179464  \n",
       "6080                 0.179464  \n",
       "6081                 0.179464  \n",
       "6082                 0.179464  \n",
       "6083                 0.179464  \n",
       "6084                 0.179464  \n",
       "6085                 0.179464  \n",
       "6086                 0.179464  \n",
       "6087                 0.179464  \n",
       "6088                 0.179464  \n",
       "6089                 0.179464  \n",
       "6090                 0.179464  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred = y_pred.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare['Mean Squared Error'] = (np.diff(y_compare.values) ** 2)\n",
    "y_compare['Mean Squared Error'] = np.mean(y_compare['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare['Root Mean Squared Error'] = y_compare['Mean Squared Error']**0.5\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213599</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227191</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.258998</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227299</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.234069</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.272913</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.238209</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.264706</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.270834</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.271790</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.272901</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218712</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.148775</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208886</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.266785</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.240319</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.224319</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224250</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.258598</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224853</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213476</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.245491</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.238679</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.260938</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.273480</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256824</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213519</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208684</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.231489</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222643</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.266252</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.271820</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.269287</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227340</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.234891</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220943</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.114270</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.690939</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212467</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.273511</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213252</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.237890</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.255619</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224431</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248708</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230151</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214245</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.276226</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.249764</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>3.220623</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221955</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230883</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.275948</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.212349</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.181390</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265577</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.237417</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.274764</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265712</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.273079</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.213599   \n",
       "1                    -0.211198                   -0.227191   \n",
       "2                    -0.258092                   -0.258998   \n",
       "3                    -0.211198                   -0.227299   \n",
       "4                    -0.258092                   -0.234069   \n",
       "5                    -0.258092                   -0.272913   \n",
       "6                    -0.211198                   -0.238209   \n",
       "7                    -0.258092                   -0.264706   \n",
       "8                    -0.258092                   -0.270834   \n",
       "9                    -0.258092                   -0.271790   \n",
       "10                   -0.258092                   -0.272901   \n",
       "11                   -0.211198                   -0.218712   \n",
       "12                    0.101746                    0.148775   \n",
       "13                   -0.211198                   -0.208886   \n",
       "14                   -0.258092                   -0.266785   \n",
       "15                   -0.211198                   -0.240319   \n",
       "16                   -0.258092                   -0.224319   \n",
       "17                   -0.211198                   -0.224250   \n",
       "18                   -0.258092                   -0.258598   \n",
       "19                   -0.211198                   -0.224853   \n",
       "20                   -0.211198                   -0.213476   \n",
       "21                   -0.211198                   -0.245491   \n",
       "22                   -0.211198                   -0.238679   \n",
       "23                   -0.258092                   -0.260938   \n",
       "24                   -0.258092                   -0.273480   \n",
       "25                   -0.258092                   -0.256824   \n",
       "26                   -0.211198                   -0.213519   \n",
       "27                   -0.211198                   -0.208684   \n",
       "28                   -0.211198                   -0.231489   \n",
       "29                   -0.211198                   -0.222643   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.266252   \n",
       "24333                -0.258092                   -0.271820   \n",
       "24334                -0.258092                   -0.269287   \n",
       "24335                -0.211198                   -0.227340   \n",
       "24336                -0.211198                   -0.234891   \n",
       "24337                -0.211198                   -0.220943   \n",
       "24338                 0.101746                    0.114270   \n",
       "24339                 0.606973                    0.690939   \n",
       "24340                -0.211198                   -0.212467   \n",
       "24341                -0.258092                   -0.273511   \n",
       "24342                -0.211198                   -0.213252   \n",
       "24343                -0.211198                   -0.237890   \n",
       "24344                -0.258092                   -0.255619   \n",
       "24345                -0.211198                   -0.224431   \n",
       "24346                -0.258092                   -0.248708   \n",
       "24347                -0.211198                   -0.230151   \n",
       "24348                -0.211198                   -0.214245   \n",
       "24349                -0.258092                   -0.276226   \n",
       "24350                -0.258092                   -0.249764   \n",
       "24351                 3.061487                    3.220623   \n",
       "24352                -0.211198                   -0.221955   \n",
       "24353                -0.211198                   -0.230883   \n",
       "24354                -0.258092                   -0.275948   \n",
       "24355                -0.196210                   -0.212349   \n",
       "24356                -0.211198                   -0.181390   \n",
       "24357                -0.258092                   -0.265577   \n",
       "24358                -0.211198                   -0.237417   \n",
       "24359                -0.258092                   -0.274764   \n",
       "24360                -0.258092                   -0.265712   \n",
       "24361                -0.258092                   -0.273079   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.005611                 0.074904  \n",
       "1                0.005611                 0.074904  \n",
       "2                0.005611                 0.074904  \n",
       "3                0.005611                 0.074904  \n",
       "4                0.005611                 0.074904  \n",
       "5                0.005611                 0.074904  \n",
       "6                0.005611                 0.074904  \n",
       "7                0.005611                 0.074904  \n",
       "8                0.005611                 0.074904  \n",
       "9                0.005611                 0.074904  \n",
       "10               0.005611                 0.074904  \n",
       "11               0.005611                 0.074904  \n",
       "12               0.005611                 0.074904  \n",
       "13               0.005611                 0.074904  \n",
       "14               0.005611                 0.074904  \n",
       "15               0.005611                 0.074904  \n",
       "16               0.005611                 0.074904  \n",
       "17               0.005611                 0.074904  \n",
       "18               0.005611                 0.074904  \n",
       "19               0.005611                 0.074904  \n",
       "20               0.005611                 0.074904  \n",
       "21               0.005611                 0.074904  \n",
       "22               0.005611                 0.074904  \n",
       "23               0.005611                 0.074904  \n",
       "24               0.005611                 0.074904  \n",
       "25               0.005611                 0.074904  \n",
       "26               0.005611                 0.074904  \n",
       "27               0.005611                 0.074904  \n",
       "28               0.005611                 0.074904  \n",
       "29               0.005611                 0.074904  \n",
       "...                   ...                      ...  \n",
       "24332            0.005611                 0.074904  \n",
       "24333            0.005611                 0.074904  \n",
       "24334            0.005611                 0.074904  \n",
       "24335            0.005611                 0.074904  \n",
       "24336            0.005611                 0.074904  \n",
       "24337            0.005611                 0.074904  \n",
       "24338            0.005611                 0.074904  \n",
       "24339            0.005611                 0.074904  \n",
       "24340            0.005611                 0.074904  \n",
       "24341            0.005611                 0.074904  \n",
       "24342            0.005611                 0.074904  \n",
       "24343            0.005611                 0.074904  \n",
       "24344            0.005611                 0.074904  \n",
       "24345            0.005611                 0.074904  \n",
       "24346            0.005611                 0.074904  \n",
       "24347            0.005611                 0.074904  \n",
       "24348            0.005611                 0.074904  \n",
       "24349            0.005611                 0.074904  \n",
       "24350            0.005611                 0.074904  \n",
       "24351            0.005611                 0.074904  \n",
       "24352            0.005611                 0.074904  \n",
       "24353            0.005611                 0.074904  \n",
       "24354            0.005611                 0.074904  \n",
       "24355            0.005611                 0.074904  \n",
       "24356            0.005611                 0.074904  \n",
       "24357            0.005611                 0.074904  \n",
       "24358            0.005611                 0.074904  \n",
       "24359            0.005611                 0.074904  \n",
       "24360            0.005611                 0.074904  \n",
       "24361            0.005611                 0.074904  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train = y_pred_train.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train }\n",
    "y_compare_train = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train['Mean Squared Error'] = (np.diff(y_compare_train.values) ** 2)\n",
    "y_compare_train['Mean Squared Error'] = np.mean(y_compare_train['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train['Root Mean Squared Error'] = y_compare_train['Mean Squared Error']**0.5\n",
    "y_compare_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best result that we have obtained so far. This ANN might potentially be the solution for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nNow we will be training a different ANN with lower number of nodes\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now we will be training a different ANN with lower number of nodes\n",
    "\n",
    "7-4-4-1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 5s 217us/step - loss: 0.3420\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 6s 251us/step - loss: 0.1088\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 0.0999\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 6s 238us/step - loss: 0.0921\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.0972\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 5s 207us/step - loss: 0.0882\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 5s 212us/step - loss: 0.0918\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 5s 203us/step - loss: 0.0863\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 0.0828\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 5s 206us/step - loss: 0.0819\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 5s 202us/step - loss: 0.0809\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0783\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0732\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0769\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0702\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0680\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0673\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0667\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0630\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0610\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0645\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 0.0654\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 5s 202us/step - loss: 0.0548\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 5s 207us/step - loss: 0.0518\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 5s 204us/step - loss: 0.0538\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 5s 210us/step - loss: 0.0567\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 5s 206us/step - loss: 0.0571\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 5s 204us/step - loss: 0.0584 0s - loss: 0\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0573\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0543\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0561\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0555\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0504\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0592\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0537\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0547\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0504\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 0.0542\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0444\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0465\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0499\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 0.0557\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0511\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 5s 203us/step - loss: 0.0459\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 5s 196us/step - loss: 0.0470\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 5s 203us/step - loss: 0.0462\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 5s 211us/step - loss: 0.0494\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0470\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 5s 203us/step - loss: 0.0492\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0449 0s - loss: 0.044\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0436\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0433\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0461\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0443\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0509\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 5s 202us/step - loss: 0.0448\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0475\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0435\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0371\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0401\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0490\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0458\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0502\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 5s 219us/step - loss: 0.0349\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 0.0418\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 5s 208us/step - loss: 0.0485\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 5s 211us/step - loss: 0.0459\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0473\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0393\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0480\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0450\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0450\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0389\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0401\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0420\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0406\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0378\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0369\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 5s 207us/step - loss: 0.0468\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 5s 207us/step - loss: 0.0292\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0345\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0481\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0338\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 5s 196us/step - loss: 0.0364\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0377\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 0.0388\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 5s 221us/step - loss: 0.0376 0s \n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0353\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0398\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 5s 202us/step - loss: 0.0455\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0374\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0394\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 5s 204us/step - loss: 0.0409\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0352\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0385\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0390\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0431\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0370\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0368\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 5s 210us/step - loss: 0.0400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1074ca8d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with less number of nodes \"\"\"\n",
    "\n",
    "regressor_1 = Sequential()\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_1.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_1.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.209429</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219773</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251528</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.173415</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217526</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.309311</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207300</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.206587</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227348</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256143</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212372</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.119941</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201796</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209598</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259842</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222351</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214430</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.946555</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.199806</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220372</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.269090</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>2.107028</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.237179</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227821</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221704</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218955</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222808</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.126996</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259277</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217007</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.233952</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>15.151163</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215166</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.394597</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.239176</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222131</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251556</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.245409</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.203469</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246392</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201367</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215343</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216478</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.085208</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220350</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.087921</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259045</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248661</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.241152</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211192</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211907</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204529</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.196163</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.245442</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217087</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209441</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.258057</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208314</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.209429            0.032207   \n",
       "1         -0.211198         -0.219773            0.032207   \n",
       "2         -0.258092         -0.251528            0.032207   \n",
       "3         -0.196210         -0.173415            0.032207   \n",
       "4         -0.211198         -0.217526            0.032207   \n",
       "5          1.425145          1.309311            0.032207   \n",
       "6         -0.211198         -0.207300            0.032207   \n",
       "7         -0.235881         -0.206587            0.032207   \n",
       "8         -0.211198         -0.227348            0.032207   \n",
       "9         -0.258092         -0.256143            0.032207   \n",
       "10        -0.211198         -0.212372            0.032207   \n",
       "11         3.879658          2.119941            0.032207   \n",
       "12        -0.211198         -0.201796            0.032207   \n",
       "13        -0.211198         -0.209598            0.032207   \n",
       "14        -0.258092         -0.259842            0.032207   \n",
       "15        -0.211198         -0.222351            0.032207   \n",
       "16        -0.211198         -0.214430            0.032207   \n",
       "17         2.243316          1.946555            0.032207   \n",
       "18        -0.211198         -0.199806            0.032207   \n",
       "19        -0.211198         -0.220372            0.032207   \n",
       "20        -0.258092         -0.269090            0.032207   \n",
       "21         2.243316          2.107028            0.032207   \n",
       "22        -0.258092         -0.237179            0.032207   \n",
       "23        -0.211198         -0.227821            0.032207   \n",
       "24        -0.211198         -0.221704            0.032207   \n",
       "25        -0.211198         -0.218955            0.032207   \n",
       "26        -0.211198         -0.222808            0.032207   \n",
       "27         0.821420          0.832354            0.032207   \n",
       "28         0.101746          0.126996            0.032207   \n",
       "29        -0.258092         -0.259277            0.032207   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.217007            0.032207   \n",
       "6062      -0.258092         -0.233952            0.032207   \n",
       "6063      16.152226         15.151163            0.032207   \n",
       "6064      -0.211198         -0.215166            0.032207   \n",
       "6065       0.461583          0.394597            0.032207   \n",
       "6066      -0.258092         -0.239176            0.032207   \n",
       "6067      -0.211198         -0.222131            0.032207   \n",
       "6068      -0.258092         -0.251556            0.032207   \n",
       "6069      -0.258092         -0.245409            0.032207   \n",
       "6070      -0.211198         -0.203469            0.032207   \n",
       "6071      -0.258092         -0.246392            0.032207   \n",
       "6072      -0.211198         -0.201367            0.032207   \n",
       "6073      -0.211198         -0.215343            0.032207   \n",
       "6074      -0.211198         -0.216478            0.032207   \n",
       "6075       3.061487          2.085208            0.032207   \n",
       "6076      -0.211198         -0.220350            0.032207   \n",
       "6077      -0.211198         -0.207203            0.032207   \n",
       "6078       0.101746          0.087921            0.032207   \n",
       "6079      -0.258092         -0.259045            0.032207   \n",
       "6080      -0.258092         -0.248661            0.032207   \n",
       "6081      -0.258092         -0.241152            0.032207   \n",
       "6082      -0.211198         -0.211192            0.032207   \n",
       "6083      -0.211198         -0.211907            0.032207   \n",
       "6084      -0.211198         -0.204529            0.032207   \n",
       "6085      -0.211198         -0.196163            0.032207   \n",
       "6086      -0.258092         -0.245442            0.032207   \n",
       "6087      -0.211198         -0.217087            0.032207   \n",
       "6088      -0.211198         -0.209441            0.032207   \n",
       "6089      -0.258092         -0.258057            0.032207   \n",
       "6090      -0.211198         -0.208314            0.032207   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.179464  \n",
       "1                    0.179464  \n",
       "2                    0.179464  \n",
       "3                    0.179464  \n",
       "4                    0.179464  \n",
       "5                    0.179464  \n",
       "6                    0.179464  \n",
       "7                    0.179464  \n",
       "8                    0.179464  \n",
       "9                    0.179464  \n",
       "10                   0.179464  \n",
       "11                   0.179464  \n",
       "12                   0.179464  \n",
       "13                   0.179464  \n",
       "14                   0.179464  \n",
       "15                   0.179464  \n",
       "16                   0.179464  \n",
       "17                   0.179464  \n",
       "18                   0.179464  \n",
       "19                   0.179464  \n",
       "20                   0.179464  \n",
       "21                   0.179464  \n",
       "22                   0.179464  \n",
       "23                   0.179464  \n",
       "24                   0.179464  \n",
       "25                   0.179464  \n",
       "26                   0.179464  \n",
       "27                   0.179464  \n",
       "28                   0.179464  \n",
       "29                   0.179464  \n",
       "...                       ...  \n",
       "6061                 0.179464  \n",
       "6062                 0.179464  \n",
       "6063                 0.179464  \n",
       "6064                 0.179464  \n",
       "6065                 0.179464  \n",
       "6066                 0.179464  \n",
       "6067                 0.179464  \n",
       "6068                 0.179464  \n",
       "6069                 0.179464  \n",
       "6070                 0.179464  \n",
       "6071                 0.179464  \n",
       "6072                 0.179464  \n",
       "6073                 0.179464  \n",
       "6074                 0.179464  \n",
       "6075                 0.179464  \n",
       "6076                 0.179464  \n",
       "6077                 0.179464  \n",
       "6078                 0.179464  \n",
       "6079                 0.179464  \n",
       "6080                 0.179464  \n",
       "6081                 0.179464  \n",
       "6082                 0.179464  \n",
       "6083                 0.179464  \n",
       "6084                 0.179464  \n",
       "6085                 0.179464  \n",
       "6086                 0.179464  \n",
       "6087                 0.179464  \n",
       "6088                 0.179464  \n",
       "6089                 0.179464  \n",
       "6090                 0.179464  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_1 = regressor_1.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_1 = y_pred_1.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare_1 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_1['Mean Squared Error'] = (np.diff(y_compare_1.values) ** 2)\n",
    "y_compare_1['Mean Squared Error'] = np.mean(y_compare_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_1['Root Mean Squared Error'] = y_compare_1['Mean Squared Error']**0.5\n",
    "y_compare_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220391</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.236547</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247619</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.263672</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.249831</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254969</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.251654</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.249146</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.252510</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.250294</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.252940</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.238317</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.188911</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213421</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.253356</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.206590</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243838</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.241299</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256782</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.243278</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222943</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210467</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243130</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251262</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248109</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.228112</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.242083</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.022264</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230754</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.258695</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251618</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246165</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.247020</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208462</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.238353</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.109552</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.670506</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.245631</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.252864</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.186784</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.014743</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.266796</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.240691</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.235521</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.246452</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.236210</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.255288</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.244346</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>3.542372</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224865</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.228264</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.258274</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.136560</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.170112</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.237196</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.235953</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247844</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.255098</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259772</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.220391   \n",
       "1                    -0.211198                   -0.236547   \n",
       "2                    -0.258092                   -0.247619   \n",
       "3                    -0.211198                   -0.263672   \n",
       "4                    -0.258092                   -0.249831   \n",
       "5                    -0.258092                   -0.254969   \n",
       "6                    -0.211198                   -0.251654   \n",
       "7                    -0.258092                   -0.249146   \n",
       "8                    -0.258092                   -0.252510   \n",
       "9                    -0.258092                   -0.250294   \n",
       "10                   -0.258092                   -0.252940   \n",
       "11                   -0.211198                   -0.238317   \n",
       "12                    0.101746                    0.188911   \n",
       "13                   -0.211198                   -0.213421   \n",
       "14                   -0.258092                   -0.253356   \n",
       "15                   -0.211198                   -0.206590   \n",
       "16                   -0.258092                   -0.243838   \n",
       "17                   -0.211198                   -0.241299   \n",
       "18                   -0.258092                   -0.256782   \n",
       "19                   -0.211198                   -0.243278   \n",
       "20                   -0.211198                   -0.222943   \n",
       "21                   -0.211198                   -0.246154   \n",
       "22                   -0.211198                   -0.210467   \n",
       "23                   -0.258092                   -0.243130   \n",
       "24                   -0.258092                   -0.251262   \n",
       "25                   -0.258092                   -0.248109   \n",
       "26                   -0.211198                   -0.228112   \n",
       "27                   -0.211198                   -0.242083   \n",
       "28                   -0.211198                   -0.022264   \n",
       "29                   -0.211198                   -0.230754   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.258695   \n",
       "24333                -0.258092                   -0.251618   \n",
       "24334                -0.258092                   -0.246165   \n",
       "24335                -0.211198                   -0.247020   \n",
       "24336                -0.211198                   -0.208462   \n",
       "24337                -0.211198                   -0.238353   \n",
       "24338                 0.101746                    0.109552   \n",
       "24339                 0.606973                    0.670506   \n",
       "24340                -0.211198                   -0.245631   \n",
       "24341                -0.258092                   -0.252864   \n",
       "24342                -0.211198                   -0.186784   \n",
       "24343                -0.211198                   -0.014743   \n",
       "24344                -0.258092                   -0.266796   \n",
       "24345                -0.211198                   -0.240691   \n",
       "24346                -0.258092                   -0.235521   \n",
       "24347                -0.211198                   -0.246452   \n",
       "24348                -0.211198                   -0.236210   \n",
       "24349                -0.258092                   -0.255288   \n",
       "24350                -0.258092                   -0.244346   \n",
       "24351                 3.061487                    3.542372   \n",
       "24352                -0.211198                   -0.224865   \n",
       "24353                -0.211198                   -0.228264   \n",
       "24354                -0.258092                   -0.258274   \n",
       "24355                -0.196210                   -0.136560   \n",
       "24356                -0.211198                   -0.170112   \n",
       "24357                -0.258092                   -0.237196   \n",
       "24358                -0.211198                   -0.235953   \n",
       "24359                -0.258092                   -0.247844   \n",
       "24360                -0.258092                   -0.255098   \n",
       "24361                -0.258092                   -0.259772   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.032342                 0.179839  \n",
       "1                0.032342                 0.179839  \n",
       "2                0.032342                 0.179839  \n",
       "3                0.032342                 0.179839  \n",
       "4                0.032342                 0.179839  \n",
       "5                0.032342                 0.179839  \n",
       "6                0.032342                 0.179839  \n",
       "7                0.032342                 0.179839  \n",
       "8                0.032342                 0.179839  \n",
       "9                0.032342                 0.179839  \n",
       "10               0.032342                 0.179839  \n",
       "11               0.032342                 0.179839  \n",
       "12               0.032342                 0.179839  \n",
       "13               0.032342                 0.179839  \n",
       "14               0.032342                 0.179839  \n",
       "15               0.032342                 0.179839  \n",
       "16               0.032342                 0.179839  \n",
       "17               0.032342                 0.179839  \n",
       "18               0.032342                 0.179839  \n",
       "19               0.032342                 0.179839  \n",
       "20               0.032342                 0.179839  \n",
       "21               0.032342                 0.179839  \n",
       "22               0.032342                 0.179839  \n",
       "23               0.032342                 0.179839  \n",
       "24               0.032342                 0.179839  \n",
       "25               0.032342                 0.179839  \n",
       "26               0.032342                 0.179839  \n",
       "27               0.032342                 0.179839  \n",
       "28               0.032342                 0.179839  \n",
       "29               0.032342                 0.179839  \n",
       "...                   ...                      ...  \n",
       "24332            0.032342                 0.179839  \n",
       "24333            0.032342                 0.179839  \n",
       "24334            0.032342                 0.179839  \n",
       "24335            0.032342                 0.179839  \n",
       "24336            0.032342                 0.179839  \n",
       "24337            0.032342                 0.179839  \n",
       "24338            0.032342                 0.179839  \n",
       "24339            0.032342                 0.179839  \n",
       "24340            0.032342                 0.179839  \n",
       "24341            0.032342                 0.179839  \n",
       "24342            0.032342                 0.179839  \n",
       "24343            0.032342                 0.179839  \n",
       "24344            0.032342                 0.179839  \n",
       "24345            0.032342                 0.179839  \n",
       "24346            0.032342                 0.179839  \n",
       "24347            0.032342                 0.179839  \n",
       "24348            0.032342                 0.179839  \n",
       "24349            0.032342                 0.179839  \n",
       "24350            0.032342                 0.179839  \n",
       "24351            0.032342                 0.179839  \n",
       "24352            0.032342                 0.179839  \n",
       "24353            0.032342                 0.179839  \n",
       "24354            0.032342                 0.179839  \n",
       "24355            0.032342                 0.179839  \n",
       "24356            0.032342                 0.179839  \n",
       "24357            0.032342                 0.179839  \n",
       "24358            0.032342                 0.179839  \n",
       "24359            0.032342                 0.179839  \n",
       "24360            0.032342                 0.179839  \n",
       "24361            0.032342                 0.179839  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_1 = regressor_1.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_1 = y_pred_train_1.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_1 }\n",
    "y_compare_train_1 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_1['Mean Squared Error'] = (np.diff(y_compare_train_1.values) ** 2)\n",
    "y_compare_train_1['Mean Squared Error'] = np.mean(y_compare_train_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_1['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ANN is the second best. The first one in this notebook is the best so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now, we will train an ANN with a very high number of nodes. And comparitively more layers.\n",
    "\n",
    "7-50-100-200-100-50-20-1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 8s 320us/step - loss: 0.2134\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 8s 318us/step - loss: 0.5605\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 8s 308us/step - loss: 0.1411\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 7s 308us/step - loss: 0.2167\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 7s 304us/step - loss: 0.1027\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 8s 337us/step - loss: 0.2685\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 8s 311us/step - loss: 0.1820\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 8s 319us/step - loss: 0.2011\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 8s 317us/step - loss: 0.2315\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 8s 320us/step - loss: 0.2064\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 7s 303us/step - loss: 1.5174\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 8s 311us/step - loss: 0.2990\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 7s 306us/step - loss: 0.3139\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 8s 310us/step - loss: 0.3120\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 7s 302us/step - loss: 0.2782\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 7s 301us/step - loss: 0.2540\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 7s 293us/step - loss: 0.2044\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 7s 296us/step - loss: 0.2525\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 7s 296us/step - loss: 0.1980\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 7s 296us/step - loss: 0.1748\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 8s 312us/step - loss: 0.1340\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 8s 331us/step - loss: 0.1444\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 7s 291us/step - loss: 0.2603\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 7s 289us/step - loss: 0.2161\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 7s 291us/step - loss: 0.2470\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 7s 296us/step - loss: 0.2302\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 7s 289us/step - loss: 0.1293\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 7s 292us/step - loss: 0.1476\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 7s 291us/step - loss: 0.1906\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 7s 285us/step - loss: 0.3500\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 7s 298us/step - loss: 0.0755\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 7s 291us/step - loss: 0.1475\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 7s 291us/step - loss: 0.2036\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 7s 290us/step - loss: 0.1602\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 7s 294us/step - loss: 0.2357\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 7s 289us/step - loss: 0.0928\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 7s 296us/step - loss: 0.1560\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 7s 295us/step - loss: 0.1469\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 7s 299us/step - loss: 0.1211\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 7s 297us/step - loss: 0.2420\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 7s 298us/step - loss: 0.1866\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 7s 299us/step - loss: 0.1455\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 8s 319us/step - loss: 0.1322\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 9s 370us/step - loss: 0.1540\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 8s 339us/step - loss: 0.2275\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 8s 319us/step - loss: 0.0476\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 8s 321us/step - loss: 0.1808 0s - loss\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 9s 350us/step - loss: 0.1795\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 8s 340us/step - loss: 0.1185\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 8s 327us/step - loss: 0.1283\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 8s 321us/step - loss: 0.2450\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 7s 302us/step - loss: 29.7185\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 8s 314us/step - loss: 0.1787\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 8s 310us/step - loss: 0.1545\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 7s 308us/step - loss: 0.1042\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 7s 307us/step - loss: 23.1974\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 8s 319us/step - loss: 0.0581\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 8s 313us/step - loss: 0.0575\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 7s 305us/step - loss: 0.1113\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 7s 301us/step - loss: 0.9229\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 7s 293us/step - loss: 0.1416\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 7s 303us/step - loss: 0.1624\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 7s 307us/step - loss: 0.1356\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 7s 302us/step - loss: 0.5123\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 7s 302us/step - loss: 0.2426\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 8s 309us/step - loss: 0.2389\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 8s 317us/step - loss: 0.2091\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 8s 308us/step - loss: 0.2411\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 8s 315us/step - loss: 0.1906\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 8s 318us/step - loss: 0.1092\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 7s 307us/step - loss: 1.0692\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 7s 303us/step - loss: 0.1309\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 7s 307us/step - loss: 0.2070\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 7s 304us/step - loss: 0.6255\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 7s 307us/step - loss: 0.1719\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 8s 322us/step - loss: 0.4379\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 8s 323us/step - loss: 0.2244\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 8s 316us/step - loss: 0.1621\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 7s 296us/step - loss: 0.1359\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 7s 303us/step - loss: 0.3378\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 7s 306us/step - loss: 0.1406\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 7s 298us/step - loss: 0.1967\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 8s 310us/step - loss: 0.1769\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 8s 324us/step - loss: 0.1588\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 8s 320us/step - loss: 0.1644\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 8s 321us/step - loss: 0.2422\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 8s 316us/step - loss: 0.2233\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 8s 310us/step - loss: 0.2157\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 8s 313us/step - loss: 0.1611\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 8s 320us/step - loss: 0.1329\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 8s 328us/step - loss: 0.1719\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 7s 301us/step - loss: 0.1671\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 7s 307us/step - loss: 0.2480\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 8s 310us/step - loss: 0.2061\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 8s 315us/step - loss: 0.1672\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 8s 309us/step - loss: 0.1438\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 8s 317us/step - loss: 0.7243\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 8s 318us/step - loss: 0.2458\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 7s 307us/step - loss: 0.1709\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 8s 319us/step - loss: 0.1678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1360c7710>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a deep and wide ANN with high number of nodes \"\"\"\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "regressor_2 = Sequential()\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal',input_dim = 7))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(200, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(20, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_2.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.209429</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219773</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251528</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.173415</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217526</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.309311</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207300</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.206587</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227348</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256143</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212372</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.119941</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201796</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209598</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259842</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222351</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214430</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.946555</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.199806</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220372</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.269090</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>2.107028</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.237179</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227821</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221704</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218955</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222808</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.126996</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259277</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217007</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.233952</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>15.151163</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215166</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.394597</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.239176</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222131</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251556</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.245409</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.203469</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246392</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201367</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215343</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216478</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.085208</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220350</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.087921</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259045</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248661</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.241152</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211192</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211907</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204529</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.196163</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.245442</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217087</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209441</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.258057</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208314</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.179464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.209429            0.032207   \n",
       "1         -0.211198         -0.219773            0.032207   \n",
       "2         -0.258092         -0.251528            0.032207   \n",
       "3         -0.196210         -0.173415            0.032207   \n",
       "4         -0.211198         -0.217526            0.032207   \n",
       "5          1.425145          1.309311            0.032207   \n",
       "6         -0.211198         -0.207300            0.032207   \n",
       "7         -0.235881         -0.206587            0.032207   \n",
       "8         -0.211198         -0.227348            0.032207   \n",
       "9         -0.258092         -0.256143            0.032207   \n",
       "10        -0.211198         -0.212372            0.032207   \n",
       "11         3.879658          2.119941            0.032207   \n",
       "12        -0.211198         -0.201796            0.032207   \n",
       "13        -0.211198         -0.209598            0.032207   \n",
       "14        -0.258092         -0.259842            0.032207   \n",
       "15        -0.211198         -0.222351            0.032207   \n",
       "16        -0.211198         -0.214430            0.032207   \n",
       "17         2.243316          1.946555            0.032207   \n",
       "18        -0.211198         -0.199806            0.032207   \n",
       "19        -0.211198         -0.220372            0.032207   \n",
       "20        -0.258092         -0.269090            0.032207   \n",
       "21         2.243316          2.107028            0.032207   \n",
       "22        -0.258092         -0.237179            0.032207   \n",
       "23        -0.211198         -0.227821            0.032207   \n",
       "24        -0.211198         -0.221704            0.032207   \n",
       "25        -0.211198         -0.218955            0.032207   \n",
       "26        -0.211198         -0.222808            0.032207   \n",
       "27         0.821420          0.832354            0.032207   \n",
       "28         0.101746          0.126996            0.032207   \n",
       "29        -0.258092         -0.259277            0.032207   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.217007            0.032207   \n",
       "6062      -0.258092         -0.233952            0.032207   \n",
       "6063      16.152226         15.151163            0.032207   \n",
       "6064      -0.211198         -0.215166            0.032207   \n",
       "6065       0.461583          0.394597            0.032207   \n",
       "6066      -0.258092         -0.239176            0.032207   \n",
       "6067      -0.211198         -0.222131            0.032207   \n",
       "6068      -0.258092         -0.251556            0.032207   \n",
       "6069      -0.258092         -0.245409            0.032207   \n",
       "6070      -0.211198         -0.203469            0.032207   \n",
       "6071      -0.258092         -0.246392            0.032207   \n",
       "6072      -0.211198         -0.201367            0.032207   \n",
       "6073      -0.211198         -0.215343            0.032207   \n",
       "6074      -0.211198         -0.216478            0.032207   \n",
       "6075       3.061487          2.085208            0.032207   \n",
       "6076      -0.211198         -0.220350            0.032207   \n",
       "6077      -0.211198         -0.207203            0.032207   \n",
       "6078       0.101746          0.087921            0.032207   \n",
       "6079      -0.258092         -0.259045            0.032207   \n",
       "6080      -0.258092         -0.248661            0.032207   \n",
       "6081      -0.258092         -0.241152            0.032207   \n",
       "6082      -0.211198         -0.211192            0.032207   \n",
       "6083      -0.211198         -0.211907            0.032207   \n",
       "6084      -0.211198         -0.204529            0.032207   \n",
       "6085      -0.211198         -0.196163            0.032207   \n",
       "6086      -0.258092         -0.245442            0.032207   \n",
       "6087      -0.211198         -0.217087            0.032207   \n",
       "6088      -0.211198         -0.209441            0.032207   \n",
       "6089      -0.258092         -0.258057            0.032207   \n",
       "6090      -0.211198         -0.208314            0.032207   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.179464  \n",
       "1                    0.179464  \n",
       "2                    0.179464  \n",
       "3                    0.179464  \n",
       "4                    0.179464  \n",
       "5                    0.179464  \n",
       "6                    0.179464  \n",
       "7                    0.179464  \n",
       "8                    0.179464  \n",
       "9                    0.179464  \n",
       "10                   0.179464  \n",
       "11                   0.179464  \n",
       "12                   0.179464  \n",
       "13                   0.179464  \n",
       "14                   0.179464  \n",
       "15                   0.179464  \n",
       "16                   0.179464  \n",
       "17                   0.179464  \n",
       "18                   0.179464  \n",
       "19                   0.179464  \n",
       "20                   0.179464  \n",
       "21                   0.179464  \n",
       "22                   0.179464  \n",
       "23                   0.179464  \n",
       "24                   0.179464  \n",
       "25                   0.179464  \n",
       "26                   0.179464  \n",
       "27                   0.179464  \n",
       "28                   0.179464  \n",
       "29                   0.179464  \n",
       "...                       ...  \n",
       "6061                 0.179464  \n",
       "6062                 0.179464  \n",
       "6063                 0.179464  \n",
       "6064                 0.179464  \n",
       "6065                 0.179464  \n",
       "6066                 0.179464  \n",
       "6067                 0.179464  \n",
       "6068                 0.179464  \n",
       "6069                 0.179464  \n",
       "6070                 0.179464  \n",
       "6071                 0.179464  \n",
       "6072                 0.179464  \n",
       "6073                 0.179464  \n",
       "6074                 0.179464  \n",
       "6075                 0.179464  \n",
       "6076                 0.179464  \n",
       "6077                 0.179464  \n",
       "6078                 0.179464  \n",
       "6079                 0.179464  \n",
       "6080                 0.179464  \n",
       "6081                 0.179464  \n",
       "6082                 0.179464  \n",
       "6083                 0.179464  \n",
       "6084                 0.179464  \n",
       "6085                 0.179464  \n",
       "6086                 0.179464  \n",
       "6087                 0.179464  \n",
       "6088                 0.179464  \n",
       "6089                 0.179464  \n",
       "6090                 0.179464  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_2 = regressor_2.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_2 = y_pred_2.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare_2 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_2['Mean Squared Error'] = (np.diff(y_compare_2.values) ** 2)\n",
    "y_compare_2['Mean Squared Error'] = np.mean(y_compare_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_2['Root Mean Squared Error'] = y_compare_2['Mean Squared Error']**0.5\n",
    "y_compare_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.299639</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.284359</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.386803</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259441</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.260129</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.238740</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.115175</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.156327</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.250711</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.277975</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.269342</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.212740</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211263</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.261702</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.278502</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.315006</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.155887</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.097656</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.109308</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.095339</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.253800</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.261232</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.260394</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.205717</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.183155</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.252009</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.311592</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.263064</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.147783</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.263110</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.229020</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.219030</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.165684</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.292648</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.292674</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.102299</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.514114</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224515</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.157452</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.241857</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.174369</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.120099</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.181276</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221307</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.120895</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.310721</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.269261</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.291598</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.446151</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.159621</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.095377</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.101993</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.254433</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.113953</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.208115</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205300</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248477</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.117335</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.149870</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.179839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.145833   \n",
       "1                    -0.211198                   -0.299639   \n",
       "2                    -0.258092                   -0.284359   \n",
       "3                    -0.211198                   -0.386803   \n",
       "4                    -0.258092                   -0.259441   \n",
       "5                    -0.258092                   -0.260129   \n",
       "6                    -0.211198                   -0.238740   \n",
       "7                    -0.258092                   -0.115175   \n",
       "8                    -0.258092                   -0.156327   \n",
       "9                    -0.258092                   -0.250711   \n",
       "10                   -0.258092                   -0.277975   \n",
       "11                   -0.211198                   -0.269342   \n",
       "12                    0.101746                    0.212740   \n",
       "13                   -0.211198                   -0.211263   \n",
       "14                   -0.258092                   -0.261702   \n",
       "15                   -0.211198                   -0.278502   \n",
       "16                   -0.258092                   -0.315006   \n",
       "17                   -0.211198                   -0.155887   \n",
       "18                   -0.258092                   -0.097656   \n",
       "19                   -0.211198                   -0.109308   \n",
       "20                   -0.211198                   -0.095339   \n",
       "21                   -0.211198                   -0.253800   \n",
       "22                   -0.211198                   -0.261232   \n",
       "23                   -0.258092                   -0.260394   \n",
       "24                   -0.258092                   -0.205717   \n",
       "25                   -0.258092                   -0.183155   \n",
       "26                   -0.211198                   -0.252009   \n",
       "27                   -0.211198                   -0.311592   \n",
       "28                   -0.211198                   -0.263064   \n",
       "29                   -0.211198                   -0.147783   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.263110   \n",
       "24333                -0.258092                   -0.229020   \n",
       "24334                -0.258092                   -0.219030   \n",
       "24335                -0.211198                   -0.165684   \n",
       "24336                -0.211198                   -0.292648   \n",
       "24337                -0.211198                   -0.292674   \n",
       "24338                 0.101746                    0.102299   \n",
       "24339                 0.606973                    0.514114   \n",
       "24340                -0.211198                   -0.224515   \n",
       "24341                -0.258092                   -0.157452   \n",
       "24342                -0.211198                   -0.241857   \n",
       "24343                -0.211198                   -0.174369   \n",
       "24344                -0.258092                   -0.120099   \n",
       "24345                -0.211198                   -0.181276   \n",
       "24346                -0.258092                   -0.221307   \n",
       "24347                -0.211198                   -0.120895   \n",
       "24348                -0.211198                   -0.310721   \n",
       "24349                -0.258092                   -0.269261   \n",
       "24350                -0.258092                   -0.291598   \n",
       "24351                 3.061487                    2.446151   \n",
       "24352                -0.211198                   -0.159621   \n",
       "24353                -0.211198                   -0.095377   \n",
       "24354                -0.258092                   -0.101993   \n",
       "24355                -0.196210                   -0.254433   \n",
       "24356                -0.211198                   -0.113953   \n",
       "24357                -0.258092                   -0.208115   \n",
       "24358                -0.211198                   -0.205300   \n",
       "24359                -0.258092                   -0.248477   \n",
       "24360                -0.258092                   -0.117335   \n",
       "24361                -0.258092                   -0.149870   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.146911                 0.179839  \n",
       "1                0.146911                 0.179839  \n",
       "2                0.146911                 0.179839  \n",
       "3                0.146911                 0.179839  \n",
       "4                0.146911                 0.179839  \n",
       "5                0.146911                 0.179839  \n",
       "6                0.146911                 0.179839  \n",
       "7                0.146911                 0.179839  \n",
       "8                0.146911                 0.179839  \n",
       "9                0.146911                 0.179839  \n",
       "10               0.146911                 0.179839  \n",
       "11               0.146911                 0.179839  \n",
       "12               0.146911                 0.179839  \n",
       "13               0.146911                 0.179839  \n",
       "14               0.146911                 0.179839  \n",
       "15               0.146911                 0.179839  \n",
       "16               0.146911                 0.179839  \n",
       "17               0.146911                 0.179839  \n",
       "18               0.146911                 0.179839  \n",
       "19               0.146911                 0.179839  \n",
       "20               0.146911                 0.179839  \n",
       "21               0.146911                 0.179839  \n",
       "22               0.146911                 0.179839  \n",
       "23               0.146911                 0.179839  \n",
       "24               0.146911                 0.179839  \n",
       "25               0.146911                 0.179839  \n",
       "26               0.146911                 0.179839  \n",
       "27               0.146911                 0.179839  \n",
       "28               0.146911                 0.179839  \n",
       "29               0.146911                 0.179839  \n",
       "...                   ...                      ...  \n",
       "24332            0.146911                 0.179839  \n",
       "24333            0.146911                 0.179839  \n",
       "24334            0.146911                 0.179839  \n",
       "24335            0.146911                 0.179839  \n",
       "24336            0.146911                 0.179839  \n",
       "24337            0.146911                 0.179839  \n",
       "24338            0.146911                 0.179839  \n",
       "24339            0.146911                 0.179839  \n",
       "24340            0.146911                 0.179839  \n",
       "24341            0.146911                 0.179839  \n",
       "24342            0.146911                 0.179839  \n",
       "24343            0.146911                 0.179839  \n",
       "24344            0.146911                 0.179839  \n",
       "24345            0.146911                 0.179839  \n",
       "24346            0.146911                 0.179839  \n",
       "24347            0.146911                 0.179839  \n",
       "24348            0.146911                 0.179839  \n",
       "24349            0.146911                 0.179839  \n",
       "24350            0.146911                 0.179839  \n",
       "24351            0.146911                 0.179839  \n",
       "24352            0.146911                 0.179839  \n",
       "24353            0.146911                 0.179839  \n",
       "24354            0.146911                 0.179839  \n",
       "24355            0.146911                 0.179839  \n",
       "24356            0.146911                 0.179839  \n",
       "24357            0.146911                 0.179839  \n",
       "24358            0.146911                 0.179839  \n",
       "24359            0.146911                 0.179839  \n",
       "24360            0.146911                 0.179839  \n",
       "24361            0.146911                 0.179839  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_2 = regressor_2.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_2 = y_pred_train_2.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_2 }\n",
    "y_compare_train_2 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_2['Mean Squared Error'] = (np.diff(y_compare_train_2.values) ** 2)\n",
    "y_compare_train_2['Mean Squared Error'] = np.mean(y_compare_train_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_2['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
