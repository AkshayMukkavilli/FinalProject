{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the same Artificial Neural Networks as in ANN(Deep and Wide with High Nodes Vs Low Nodes) but we will scale the dataset using StandardScaler from sklearn and also use the dataset with Z_Scores of Words and Helpful Votes\n",
    "\n",
    "TARGET LABEL: Z_Score_HelpfulVotes\n",
    "\n",
    "SCALER: STANDARD SCALER\n",
    "\n",
    "ANN'S : Combination 1:  7-100-100-1\n",
    "\n",
    "        Combination 2:  7-4-4-1\n",
    "        \n",
    "        Combination 3:  7-50-100-200-100-50-20-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Stars', 'Helpful Votes', 'Z_Score_HelpfulVotes', 'Words',\n",
      "       'Z_Score_Words', 'Paragraphs', 'No.break tags', 'Percentage_Upper_Case',\n",
      "       'Percentage_Lower_Case', 'Avg_len_paragraph_per_review'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Z_Score_Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Z_Score_HelpfulVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2.548167</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>202.555556</td>\n",
       "      <td>5.103923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.066097</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>-0.271598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.721210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>-0.271598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.034114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>862.000000</td>\n",
       "      <td>-0.271598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.489055</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>280.500000</td>\n",
       "      <td>0.400342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Z_Score_Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0      5       2.548167           9             11                      4   \n",
       "1      3      -0.066097           1              0                     11   \n",
       "2      5       0.721210           1              0                      1   \n",
       "3      5       1.034114           1              0                      4   \n",
       "4      5       0.489055           2              1                      5   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  Z_Score_HelpfulVotes  \n",
       "0                     89                    202.555556              5.103923  \n",
       "1                     79                    284.000000             -0.271598  \n",
       "2                     96                    701.000000             -0.271598  \n",
       "3                     92                    862.000000             -0.271598  \n",
       "4                     89                    280.500000              0.400342  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'../FinalFeatures_latest.csv')\n",
    "\n",
    "# The below line of code is to keep the z-scores of helpful votes and words and remove the actual values.\n",
    "\n",
    "print(dataset.columns)\n",
    "dataset = dataset[['Stars','Z_Score_Words', 'Paragraphs','No.break tags','Percentage_Upper_Case','Percentage_Lower_Case','Avg_len_paragraph_per_review','Z_Score_HelpfulVotes']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the independant variables from the dependant variable which is \"Helpful Votes\" in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting the data into training data and testing data\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "\"\"\"Scaling the data using StandardScaler from sklearn package\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing keras and other required functions\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/WorkingCopy/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/WorkingCopy/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.1001\n",
      "Epoch 2/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0680\n",
      "Epoch 3/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0536\n",
      "Epoch 4/100\n",
      "80711/80711 [==============================] - 14s 176us/step - loss: 0.0526\n",
      "Epoch 5/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0449\n",
      "Epoch 6/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0572\n",
      "Epoch 7/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0480\n",
      "Epoch 8/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0492\n",
      "Epoch 9/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0431\n",
      "Epoch 10/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0407\n",
      "Epoch 11/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0388\n",
      "Epoch 12/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0395\n",
      "Epoch 13/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0405\n",
      "Epoch 14/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0399\n",
      "Epoch 15/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0363\n",
      "Epoch 16/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0382\n",
      "Epoch 17/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0399\n",
      "Epoch 18/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0373\n",
      "Epoch 19/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0366\n",
      "Epoch 20/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0365\n",
      "Epoch 21/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0350\n",
      "Epoch 22/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0351\n",
      "Epoch 23/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0340\n",
      "Epoch 24/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0338\n",
      "Epoch 25/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0353\n",
      "Epoch 26/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0335\n",
      "Epoch 27/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0312\n",
      "Epoch 28/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0353\n",
      "Epoch 29/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0325\n",
      "Epoch 30/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0358\n",
      "Epoch 31/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0320\n",
      "Epoch 32/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0319\n",
      "Epoch 33/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0320\n",
      "Epoch 34/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0326\n",
      "Epoch 35/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0325\n",
      "Epoch 36/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0330\n",
      "Epoch 37/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0334\n",
      "Epoch 38/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0325\n",
      "Epoch 39/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0313\n",
      "Epoch 40/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0343\n",
      "Epoch 41/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0347\n",
      "Epoch 42/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0299\n",
      "Epoch 43/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0345\n",
      "Epoch 44/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0316\n",
      "Epoch 45/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0330\n",
      "Epoch 46/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0280\n",
      "Epoch 47/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0307\n",
      "Epoch 48/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0325\n",
      "Epoch 49/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0310\n",
      "Epoch 50/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0308\n",
      "Epoch 51/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0338\n",
      "Epoch 52/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0313\n",
      "Epoch 53/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0309\n",
      "Epoch 54/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0300\n",
      "Epoch 55/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0299\n",
      "Epoch 56/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0280\n",
      "Epoch 57/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0299\n",
      "Epoch 58/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0308\n",
      "Epoch 59/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0310\n",
      "Epoch 60/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0290\n",
      "Epoch 61/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0324\n",
      "Epoch 62/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0283\n",
      "Epoch 63/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0298\n",
      "Epoch 64/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0388\n",
      "Epoch 65/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0307\n",
      "Epoch 66/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0292\n",
      "Epoch 67/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0300\n",
      "Epoch 68/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0319\n",
      "Epoch 69/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0314\n",
      "Epoch 70/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0331\n",
      "Epoch 71/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0341\n",
      "Epoch 72/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0316\n",
      "Epoch 73/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0290\n",
      "Epoch 74/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0295\n",
      "Epoch 75/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0290\n",
      "Epoch 76/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0301\n",
      "Epoch 77/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0321\n",
      "Epoch 78/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0301\n",
      "Epoch 79/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0273\n",
      "Epoch 80/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0304\n",
      "Epoch 81/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0290\n",
      "Epoch 82/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0348\n",
      "Epoch 83/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0275\n",
      "Epoch 84/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0310\n",
      "Epoch 85/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0294\n",
      "Epoch 86/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0282\n",
      "Epoch 87/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0284\n",
      "Epoch 88/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0286\n",
      "Epoch 89/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0295\n",
      "Epoch 90/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0311\n",
      "Epoch 91/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0296\n",
      "Epoch 92/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0287\n",
      "Epoch 93/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0288\n",
      "Epoch 94/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0267\n",
      "Epoch 95/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0305\n",
      "Epoch 96/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0281\n",
      "Epoch 97/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0270\n",
      "Epoch 98/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0287\n",
      "Epoch 99/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0316\n",
      "Epoch 100/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1318d6128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with high number of nodes \"\"\"\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.345960</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508167</td>\n",
       "      <td>1.521016</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.279556</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.287331</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610709</td>\n",
       "      <td>1.620239</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.286180</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.327976</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.290851</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.208127</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.278054</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.331151</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.236116</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.427985</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.261976</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.207191</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.234179</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.285639</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.222529</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.408553</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.362141</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.271100</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.337313</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.269193</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.324284</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.417803</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.278446</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.294735</td>\n",
       "      <td>1.367243</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.285493</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.338727</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20148</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.384149</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20149</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.276834</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.286037</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.427769</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20152</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.210227</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.274089</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>0.295361</td>\n",
       "      <td>0.298848</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.336358</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.254143</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.273884</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.285444</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.287160</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.410680</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.335792</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.422821</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.224597</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20164</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.380356</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20165</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.224711</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20166</th>\n",
       "      <td>1.881052</td>\n",
       "      <td>1.580523</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20167</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.260103</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.291492</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20169</th>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.786176</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.259818</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.225312</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20172</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.271258</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.277201</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20174</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.290308</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>2.497956</td>\n",
       "      <td>2.583906</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.275175</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20177</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.268798</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20178 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.297970         -0.345960            0.032871   \n",
       "1           1.508167          1.521016            0.032871   \n",
       "2          -0.271598         -0.279556            0.032871   \n",
       "3          -0.243275         -0.287331            0.032871   \n",
       "4           1.610709          1.620239            0.032871   \n",
       "5          -0.243275         -0.286180            0.032871   \n",
       "6          -0.298449         -0.327976            0.032871   \n",
       "7          -0.271598         -0.290851            0.032871   \n",
       "8          -0.198263         -0.208127            0.032871   \n",
       "9          -0.271598         -0.278054            0.032871   \n",
       "10         -0.297406         -0.331151            0.032871   \n",
       "11         -0.243275         -0.236116            0.032871   \n",
       "12         -0.450526         -0.427985            0.032871   \n",
       "13         -0.243275         -0.261976            0.032871   \n",
       "14         -0.174593         -0.207191            0.032871   \n",
       "15         -0.160953         -0.234179            0.032871   \n",
       "16         -0.271598         -0.285639            0.032871   \n",
       "17         -0.237216         -0.222529            0.032871   \n",
       "18         -0.384433         -0.408553            0.032871   \n",
       "19         -0.298449         -0.362141            0.032871   \n",
       "20         -0.271598         -0.271100            0.032871   \n",
       "21         -0.298449         -0.337313            0.032871   \n",
       "22         -0.236879         -0.269193            0.032871   \n",
       "23         -0.298449         -0.324284            0.032871   \n",
       "24          0.016268          0.009330            0.032871   \n",
       "25         -0.434616         -0.417803            0.032871   \n",
       "26         -0.271598         -0.278446            0.032871   \n",
       "27          1.294735          1.367243            0.032871   \n",
       "28         -0.297406         -0.285493            0.032871   \n",
       "29         -0.297970         -0.338727            0.032871   \n",
       "...              ...               ...                 ...   \n",
       "20148       0.400342          0.384149            0.032871   \n",
       "20149      -0.243275         -0.276834            0.032871   \n",
       "20150      -0.243275         -0.286037            0.032871   \n",
       "20151       0.400342          0.427769            0.032871   \n",
       "20152      -0.235617         -0.210227            0.032871   \n",
       "20153      -0.271598         -0.274089            0.032871   \n",
       "20154       0.295361          0.298848            0.032871   \n",
       "20155      -0.298449         -0.336358            0.032871   \n",
       "20156      -0.235617         -0.254143            0.032871   \n",
       "20157      -0.271598         -0.273884            0.032871   \n",
       "20158      -0.298449         -0.285444            0.032871   \n",
       "20159      -0.298449         -0.287160            0.032871   \n",
       "20160      -0.384433         -0.410680            0.032871   \n",
       "20161      -0.297970         -0.335792            0.032871   \n",
       "20162      -0.450526         -0.422821            0.032871   \n",
       "20163      -0.237216         -0.224597            0.032871   \n",
       "20164      -0.450526         -0.380356            0.032871   \n",
       "20165      -0.190985         -0.224711            0.032871   \n",
       "20166       1.881052          1.580523            0.032871   \n",
       "20167      -0.174593         -0.260103            0.032871   \n",
       "20168      -0.271598         -0.291492            0.032871   \n",
       "20169       0.928402          0.786176            0.032871   \n",
       "20170      -0.297970         -0.259818            0.032871   \n",
       "20171      -0.235617         -0.225312            0.032871   \n",
       "20172      -0.198263         -0.271258            0.032871   \n",
       "20173      -0.190985         -0.277201            0.032871   \n",
       "20174      -0.191298         -0.290308            0.032871   \n",
       "20175       2.497956          2.583906            0.032871   \n",
       "20176      -0.271598         -0.275175            0.032871   \n",
       "20177      -0.243275         -0.268798            0.032871   \n",
       "\n",
       "       Root Mean Squared Error  \n",
       "0                     0.181305  \n",
       "1                     0.181305  \n",
       "2                     0.181305  \n",
       "3                     0.181305  \n",
       "4                     0.181305  \n",
       "5                     0.181305  \n",
       "6                     0.181305  \n",
       "7                     0.181305  \n",
       "8                     0.181305  \n",
       "9                     0.181305  \n",
       "10                    0.181305  \n",
       "11                    0.181305  \n",
       "12                    0.181305  \n",
       "13                    0.181305  \n",
       "14                    0.181305  \n",
       "15                    0.181305  \n",
       "16                    0.181305  \n",
       "17                    0.181305  \n",
       "18                    0.181305  \n",
       "19                    0.181305  \n",
       "20                    0.181305  \n",
       "21                    0.181305  \n",
       "22                    0.181305  \n",
       "23                    0.181305  \n",
       "24                    0.181305  \n",
       "25                    0.181305  \n",
       "26                    0.181305  \n",
       "27                    0.181305  \n",
       "28                    0.181305  \n",
       "29                    0.181305  \n",
       "...                        ...  \n",
       "20148                 0.181305  \n",
       "20149                 0.181305  \n",
       "20150                 0.181305  \n",
       "20151                 0.181305  \n",
       "20152                 0.181305  \n",
       "20153                 0.181305  \n",
       "20154                 0.181305  \n",
       "20155                 0.181305  \n",
       "20156                 0.181305  \n",
       "20157                 0.181305  \n",
       "20158                 0.181305  \n",
       "20159                 0.181305  \n",
       "20160                 0.181305  \n",
       "20161                 0.181305  \n",
       "20162                 0.181305  \n",
       "20163                 0.181305  \n",
       "20164                 0.181305  \n",
       "20165                 0.181305  \n",
       "20166                 0.181305  \n",
       "20167                 0.181305  \n",
       "20168                 0.181305  \n",
       "20169                 0.181305  \n",
       "20170                 0.181305  \n",
       "20171                 0.181305  \n",
       "20172                 0.181305  \n",
       "20173                 0.181305  \n",
       "20174                 0.181305  \n",
       "20175                 0.181305  \n",
       "20176                 0.181305  \n",
       "20177                 0.181305  \n",
       "\n",
       "[20178 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred = y_pred.reshape(20178,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare['Mean Squared Error'] = (np.diff(y_compare.values) ** 2)\n",
    "y_compare['Mean Squared Error'] = np.mean(y_compare['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare['Root Mean Squared Error'] = y_compare['Mean Squared Error']**0.5\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262716</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.619072</td>\n",
       "      <td>1.608788</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.285821</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.253673</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.228699</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.342183</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.338095</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.799391</td>\n",
       "      <td>0.662096</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.290681</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.273715</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.431575</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.260237</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.249449</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.708209</td>\n",
       "      <td>2.799664</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.251075</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.157567</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.281480</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.236309</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.268252</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.275613</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.320410</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.248428</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.256918</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.214175</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.960844</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.222273</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.216042</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.248574</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.322602</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.258607</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80681</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262158</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80682</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.228987</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80683</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.293633</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80684</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.220014</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80685</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.242525</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80686</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.204623</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80687</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.214378</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80688</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.307067</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80689</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.335968</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80690</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.198115</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80691</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.456990</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80692</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.250804</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80693</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.210116</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80694</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.281592</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80695</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.266244</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80696</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.338206</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80697</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.228646</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80698</th>\n",
       "      <td>5.228654</td>\n",
       "      <td>3.012377</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80699</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.299059</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80700</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.243821</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80701</th>\n",
       "      <td>-0.239534</td>\n",
       "      <td>-0.206937</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80702</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.473922</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80703</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.412488</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80704</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.238267</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80705</th>\n",
       "      <td>6.252968</td>\n",
       "      <td>7.085105</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.257575</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80707</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.212760</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80708</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.382215</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80709</th>\n",
       "      <td>1.218371</td>\n",
       "      <td>1.392550</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80710</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.219685</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.167709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80711 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.271598                   -0.262716   \n",
       "1                     1.619072                    1.608788   \n",
       "2                    -0.297406                   -0.285821   \n",
       "3                    -0.237216                   -0.253673   \n",
       "4                    -0.237216                   -0.228699   \n",
       "5                    -0.198263                   -0.342183   \n",
       "6                     0.016268                    0.338095   \n",
       "7                     0.799391                    0.662096   \n",
       "8                    -0.243275                   -0.290681   \n",
       "9                    -0.298449                   -0.273715   \n",
       "10                   -0.450526                   -0.431575   \n",
       "11                   -0.191298                   -0.260237   \n",
       "12                   -0.190985                   -0.249449   \n",
       "13                    2.708209                    2.799664   \n",
       "14                   -0.237216                   -0.251075   \n",
       "15                   -0.174593                   -0.157567   \n",
       "16                   -0.298449                   -0.281480   \n",
       "17                   -0.160953                   -0.236309   \n",
       "18                   -0.191298                   -0.268252   \n",
       "19                   -0.243275                   -0.275613   \n",
       "20                   -0.450526                   -0.320410   \n",
       "21                   -0.271598                   -0.248428   \n",
       "22                   -0.271598                   -0.256918   \n",
       "23                   -0.160953                   -0.214175   \n",
       "24                    0.960844                    0.938776   \n",
       "25                   -0.198263                   -0.222273   \n",
       "26                   -0.160953                   -0.216042   \n",
       "27                   -0.271598                   -0.248574   \n",
       "28                   -0.297406                   -0.322602   \n",
       "29                   -0.271598                   -0.258607   \n",
       "...                        ...                         ...   \n",
       "80681                -0.271598                   -0.262158   \n",
       "80682                -0.160953                   -0.228987   \n",
       "80683                -0.298449                   -0.293633   \n",
       "80684                -0.237216                   -0.220014   \n",
       "80685                -0.235617                   -0.242525   \n",
       "80686                -0.190985                   -0.204623   \n",
       "80687                -0.237216                   -0.214378   \n",
       "80688                -0.298449                   -0.307067   \n",
       "80689                -0.297406                   -0.335968   \n",
       "80690                -0.160953                   -0.198115   \n",
       "80691                -0.434616                   -0.456990   \n",
       "80692                -0.271598                   -0.250804   \n",
       "80693                -0.298449                   -0.210116   \n",
       "80694                -0.271598                   -0.281592   \n",
       "80695                -0.191298                   -0.266244   \n",
       "80696                -0.297970                   -0.338206   \n",
       "80697                -0.237216                   -0.228646   \n",
       "80698                 5.228654                    3.012377   \n",
       "80699                -0.191298                   -0.299059   \n",
       "80700                -0.191298                   -0.243821   \n",
       "80701                -0.239534                   -0.206937   \n",
       "80702                -0.434616                   -0.473922   \n",
       "80703                -0.384433                   -0.412488   \n",
       "80704                -0.236879                   -0.238267   \n",
       "80705                 6.252968                    7.085105   \n",
       "80706                -0.271598                   -0.257575   \n",
       "80707                -0.198263                   -0.212760   \n",
       "80708                -0.384433                   -0.382215   \n",
       "80709                 1.218371                    1.392550   \n",
       "80710                -0.190985                   -0.219685   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.028126                 0.167709  \n",
       "1                0.028126                 0.167709  \n",
       "2                0.028126                 0.167709  \n",
       "3                0.028126                 0.167709  \n",
       "4                0.028126                 0.167709  \n",
       "5                0.028126                 0.167709  \n",
       "6                0.028126                 0.167709  \n",
       "7                0.028126                 0.167709  \n",
       "8                0.028126                 0.167709  \n",
       "9                0.028126                 0.167709  \n",
       "10               0.028126                 0.167709  \n",
       "11               0.028126                 0.167709  \n",
       "12               0.028126                 0.167709  \n",
       "13               0.028126                 0.167709  \n",
       "14               0.028126                 0.167709  \n",
       "15               0.028126                 0.167709  \n",
       "16               0.028126                 0.167709  \n",
       "17               0.028126                 0.167709  \n",
       "18               0.028126                 0.167709  \n",
       "19               0.028126                 0.167709  \n",
       "20               0.028126                 0.167709  \n",
       "21               0.028126                 0.167709  \n",
       "22               0.028126                 0.167709  \n",
       "23               0.028126                 0.167709  \n",
       "24               0.028126                 0.167709  \n",
       "25               0.028126                 0.167709  \n",
       "26               0.028126                 0.167709  \n",
       "27               0.028126                 0.167709  \n",
       "28               0.028126                 0.167709  \n",
       "29               0.028126                 0.167709  \n",
       "...                   ...                      ...  \n",
       "80681            0.028126                 0.167709  \n",
       "80682            0.028126                 0.167709  \n",
       "80683            0.028126                 0.167709  \n",
       "80684            0.028126                 0.167709  \n",
       "80685            0.028126                 0.167709  \n",
       "80686            0.028126                 0.167709  \n",
       "80687            0.028126                 0.167709  \n",
       "80688            0.028126                 0.167709  \n",
       "80689            0.028126                 0.167709  \n",
       "80690            0.028126                 0.167709  \n",
       "80691            0.028126                 0.167709  \n",
       "80692            0.028126                 0.167709  \n",
       "80693            0.028126                 0.167709  \n",
       "80694            0.028126                 0.167709  \n",
       "80695            0.028126                 0.167709  \n",
       "80696            0.028126                 0.167709  \n",
       "80697            0.028126                 0.167709  \n",
       "80698            0.028126                 0.167709  \n",
       "80699            0.028126                 0.167709  \n",
       "80700            0.028126                 0.167709  \n",
       "80701            0.028126                 0.167709  \n",
       "80702            0.028126                 0.167709  \n",
       "80703            0.028126                 0.167709  \n",
       "80704            0.028126                 0.167709  \n",
       "80705            0.028126                 0.167709  \n",
       "80706            0.028126                 0.167709  \n",
       "80707            0.028126                 0.167709  \n",
       "80708            0.028126                 0.167709  \n",
       "80709            0.028126                 0.167709  \n",
       "80710            0.028126                 0.167709  \n",
       "\n",
       "[80711 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train = y_pred_train.reshape(80711,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train }\n",
    "y_compare_train = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train['Mean Squared Error'] = (np.diff(y_compare_train.values) ** 2)\n",
    "y_compare_train['Mean Squared Error'] = np.mean(y_compare_train['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train['Root Mean Squared Error'] = y_compare_train['Mean Squared Error']**0.5\n",
    "y_compare_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now we will be training a different ANN with lower number of nodes\n",
    "\n",
    "7-4-4-1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.1253\n",
      "Epoch 2/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0752\n",
      "Epoch 3/100\n",
      "80711/80711 [==============================] - 14s 176us/step - loss: 0.0644\n",
      "Epoch 4/100\n",
      "80711/80711 [==============================] - 15s 182us/step - loss: 0.0583\n",
      "Epoch 5/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0572\n",
      "Epoch 6/100\n",
      "80711/80711 [==============================] - 14s 176us/step - loss: 0.0549\n",
      "Epoch 7/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0525\n",
      "Epoch 8/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0509\n",
      "Epoch 9/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0499\n",
      "Epoch 10/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0473\n",
      "Epoch 11/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0510\n",
      "Epoch 12/100\n",
      "80711/80711 [==============================] - 14s 176us/step - loss: 0.0469\n",
      "Epoch 13/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0475\n",
      "Epoch 14/100\n",
      "80711/80711 [==============================] - 14s 176us/step - loss: 0.0483\n",
      "Epoch 15/100\n",
      "80711/80711 [==============================] - 14s 178us/step - loss: 0.0461\n",
      "Epoch 16/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0456\n",
      "Epoch 17/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0480\n",
      "Epoch 18/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0465\n",
      "Epoch 19/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0452\n",
      "Epoch 20/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0473\n",
      "Epoch 21/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0446\n",
      "Epoch 22/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0464\n",
      "Epoch 23/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0447\n",
      "Epoch 24/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0449\n",
      "Epoch 25/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0473\n",
      "Epoch 26/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0451\n",
      "Epoch 27/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0441\n",
      "Epoch 28/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0448\n",
      "Epoch 29/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0444\n",
      "Epoch 30/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0478\n",
      "Epoch 31/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0483\n",
      "Epoch 32/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0456\n",
      "Epoch 33/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0448\n",
      "Epoch 34/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0439\n",
      "Epoch 35/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0449\n",
      "Epoch 36/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0445\n",
      "Epoch 37/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0426\n",
      "Epoch 38/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0433\n",
      "Epoch 39/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0443\n",
      "Epoch 40/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0444\n",
      "Epoch 41/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0431\n",
      "Epoch 42/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0426\n",
      "Epoch 43/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0449\n",
      "Epoch 44/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0439\n",
      "Epoch 45/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0429\n",
      "Epoch 46/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0420\n",
      "Epoch 47/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0441\n",
      "Epoch 48/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0436\n",
      "Epoch 49/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0432\n",
      "Epoch 50/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0439\n",
      "Epoch 51/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0431\n",
      "Epoch 52/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0409\n",
      "Epoch 53/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0428\n",
      "Epoch 54/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0439\n",
      "Epoch 55/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0426\n",
      "Epoch 56/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0417\n",
      "Epoch 57/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0435\n",
      "Epoch 58/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0452\n",
      "Epoch 59/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0434\n",
      "Epoch 60/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0420\n",
      "Epoch 61/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0438\n",
      "Epoch 62/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0435\n",
      "Epoch 63/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0423\n",
      "Epoch 64/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0433\n",
      "Epoch 65/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0423\n",
      "Epoch 66/100\n",
      "80711/80711 [==============================] - 14s 179us/step - loss: 0.0443\n",
      "Epoch 67/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0451\n",
      "Epoch 68/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0467\n",
      "Epoch 69/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0437\n",
      "Epoch 70/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0453\n",
      "Epoch 71/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0434\n",
      "Epoch 72/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0416\n",
      "Epoch 73/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0446\n",
      "Epoch 74/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0426\n",
      "Epoch 75/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0418\n",
      "Epoch 76/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0425\n",
      "Epoch 77/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0442\n",
      "Epoch 78/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0436\n",
      "Epoch 79/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0455\n",
      "Epoch 80/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0452\n",
      "Epoch 81/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0437\n",
      "Epoch 82/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0443\n",
      "Epoch 83/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0433\n",
      "Epoch 84/100\n",
      "80711/80711 [==============================] - 15s 184us/step - loss: 0.0429\n",
      "Epoch 85/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0427\n",
      "Epoch 86/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0439\n",
      "Epoch 87/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0431\n",
      "Epoch 88/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0456\n",
      "Epoch 89/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0419\n",
      "Epoch 90/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0427\n",
      "Epoch 91/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0445\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0426\n",
      "Epoch 93/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0413\n",
      "Epoch 94/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0422\n",
      "Epoch 95/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0425\n",
      "Epoch 96/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0416\n",
      "Epoch 97/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0413\n",
      "Epoch 98/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0429\n",
      "Epoch 99/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0430\n",
      "Epoch 100/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131e5fa90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with less number of nodes \"\"\"\n",
    "\n",
    "regressor_1 = Sequential()\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_1.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_1.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.345960</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508167</td>\n",
       "      <td>1.521016</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.279556</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.287331</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610709</td>\n",
       "      <td>1.620239</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.286180</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.327976</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.290851</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.208127</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.278054</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.331151</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.236116</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.427985</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.261976</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.207191</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.234179</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.285639</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.222529</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.408553</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.362141</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.271100</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.337313</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.269193</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.324284</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.417803</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.278446</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.294735</td>\n",
       "      <td>1.367243</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.285493</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.338727</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20148</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.384149</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20149</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.276834</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.286037</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.427769</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20152</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.210227</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.274089</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>0.295361</td>\n",
       "      <td>0.298848</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.336358</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.254143</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.273884</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.285444</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.287160</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.410680</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.335792</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.422821</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.224597</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20164</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.380356</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20165</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.224711</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20166</th>\n",
       "      <td>1.881052</td>\n",
       "      <td>1.580523</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20167</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.260103</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.291492</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20169</th>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.786176</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.259818</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.225312</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20172</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.271258</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.277201</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20174</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.290308</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>2.497956</td>\n",
       "      <td>2.583906</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.275175</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20177</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.268798</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20178 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.297970         -0.345960            0.032871   \n",
       "1           1.508167          1.521016            0.032871   \n",
       "2          -0.271598         -0.279556            0.032871   \n",
       "3          -0.243275         -0.287331            0.032871   \n",
       "4           1.610709          1.620239            0.032871   \n",
       "5          -0.243275         -0.286180            0.032871   \n",
       "6          -0.298449         -0.327976            0.032871   \n",
       "7          -0.271598         -0.290851            0.032871   \n",
       "8          -0.198263         -0.208127            0.032871   \n",
       "9          -0.271598         -0.278054            0.032871   \n",
       "10         -0.297406         -0.331151            0.032871   \n",
       "11         -0.243275         -0.236116            0.032871   \n",
       "12         -0.450526         -0.427985            0.032871   \n",
       "13         -0.243275         -0.261976            0.032871   \n",
       "14         -0.174593         -0.207191            0.032871   \n",
       "15         -0.160953         -0.234179            0.032871   \n",
       "16         -0.271598         -0.285639            0.032871   \n",
       "17         -0.237216         -0.222529            0.032871   \n",
       "18         -0.384433         -0.408553            0.032871   \n",
       "19         -0.298449         -0.362141            0.032871   \n",
       "20         -0.271598         -0.271100            0.032871   \n",
       "21         -0.298449         -0.337313            0.032871   \n",
       "22         -0.236879         -0.269193            0.032871   \n",
       "23         -0.298449         -0.324284            0.032871   \n",
       "24          0.016268          0.009330            0.032871   \n",
       "25         -0.434616         -0.417803            0.032871   \n",
       "26         -0.271598         -0.278446            0.032871   \n",
       "27          1.294735          1.367243            0.032871   \n",
       "28         -0.297406         -0.285493            0.032871   \n",
       "29         -0.297970         -0.338727            0.032871   \n",
       "...              ...               ...                 ...   \n",
       "20148       0.400342          0.384149            0.032871   \n",
       "20149      -0.243275         -0.276834            0.032871   \n",
       "20150      -0.243275         -0.286037            0.032871   \n",
       "20151       0.400342          0.427769            0.032871   \n",
       "20152      -0.235617         -0.210227            0.032871   \n",
       "20153      -0.271598         -0.274089            0.032871   \n",
       "20154       0.295361          0.298848            0.032871   \n",
       "20155      -0.298449         -0.336358            0.032871   \n",
       "20156      -0.235617         -0.254143            0.032871   \n",
       "20157      -0.271598         -0.273884            0.032871   \n",
       "20158      -0.298449         -0.285444            0.032871   \n",
       "20159      -0.298449         -0.287160            0.032871   \n",
       "20160      -0.384433         -0.410680            0.032871   \n",
       "20161      -0.297970         -0.335792            0.032871   \n",
       "20162      -0.450526         -0.422821            0.032871   \n",
       "20163      -0.237216         -0.224597            0.032871   \n",
       "20164      -0.450526         -0.380356            0.032871   \n",
       "20165      -0.190985         -0.224711            0.032871   \n",
       "20166       1.881052          1.580523            0.032871   \n",
       "20167      -0.174593         -0.260103            0.032871   \n",
       "20168      -0.271598         -0.291492            0.032871   \n",
       "20169       0.928402          0.786176            0.032871   \n",
       "20170      -0.297970         -0.259818            0.032871   \n",
       "20171      -0.235617         -0.225312            0.032871   \n",
       "20172      -0.198263         -0.271258            0.032871   \n",
       "20173      -0.190985         -0.277201            0.032871   \n",
       "20174      -0.191298         -0.290308            0.032871   \n",
       "20175       2.497956          2.583906            0.032871   \n",
       "20176      -0.271598         -0.275175            0.032871   \n",
       "20177      -0.243275         -0.268798            0.032871   \n",
       "\n",
       "       Root Mean Squared Error  \n",
       "0                     0.181305  \n",
       "1                     0.181305  \n",
       "2                     0.181305  \n",
       "3                     0.181305  \n",
       "4                     0.181305  \n",
       "5                     0.181305  \n",
       "6                     0.181305  \n",
       "7                     0.181305  \n",
       "8                     0.181305  \n",
       "9                     0.181305  \n",
       "10                    0.181305  \n",
       "11                    0.181305  \n",
       "12                    0.181305  \n",
       "13                    0.181305  \n",
       "14                    0.181305  \n",
       "15                    0.181305  \n",
       "16                    0.181305  \n",
       "17                    0.181305  \n",
       "18                    0.181305  \n",
       "19                    0.181305  \n",
       "20                    0.181305  \n",
       "21                    0.181305  \n",
       "22                    0.181305  \n",
       "23                    0.181305  \n",
       "24                    0.181305  \n",
       "25                    0.181305  \n",
       "26                    0.181305  \n",
       "27                    0.181305  \n",
       "28                    0.181305  \n",
       "29                    0.181305  \n",
       "...                        ...  \n",
       "20148                 0.181305  \n",
       "20149                 0.181305  \n",
       "20150                 0.181305  \n",
       "20151                 0.181305  \n",
       "20152                 0.181305  \n",
       "20153                 0.181305  \n",
       "20154                 0.181305  \n",
       "20155                 0.181305  \n",
       "20156                 0.181305  \n",
       "20157                 0.181305  \n",
       "20158                 0.181305  \n",
       "20159                 0.181305  \n",
       "20160                 0.181305  \n",
       "20161                 0.181305  \n",
       "20162                 0.181305  \n",
       "20163                 0.181305  \n",
       "20164                 0.181305  \n",
       "20165                 0.181305  \n",
       "20166                 0.181305  \n",
       "20167                 0.181305  \n",
       "20168                 0.181305  \n",
       "20169                 0.181305  \n",
       "20170                 0.181305  \n",
       "20171                 0.181305  \n",
       "20172                 0.181305  \n",
       "20173                 0.181305  \n",
       "20174                 0.181305  \n",
       "20175                 0.181305  \n",
       "20176                 0.181305  \n",
       "20177                 0.181305  \n",
       "\n",
       "[20178 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_1 = regressor_1.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_1 = y_pred_1.reshape(20178,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare_1 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_1['Mean Squared Error'] = (np.diff(y_compare_1.values) ** 2)\n",
    "y_compare_1['Mean Squared Error'] = np.mean(y_compare_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_1['Root Mean Squared Error'] = y_compare_1['Mean Squared Error']**0.5\n",
    "y_compare_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.619072</td>\n",
       "      <td>1.439618</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.411272</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.799391</td>\n",
       "      <td>0.895109</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.708209</td>\n",
       "      <td>2.917171</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.960844</td>\n",
       "      <td>0.908676</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80681</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80682</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80683</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80684</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80685</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80686</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80687</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80688</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80689</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80690</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80691</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80692</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80693</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80694</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80695</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80696</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80697</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80698</th>\n",
       "      <td>5.228654</td>\n",
       "      <td>1.842697</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80699</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80700</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80701</th>\n",
       "      <td>-0.239534</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80702</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80703</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80704</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80705</th>\n",
       "      <td>6.252968</td>\n",
       "      <td>6.783779</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80707</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80708</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80709</th>\n",
       "      <td>1.218371</td>\n",
       "      <td>1.389923</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80710</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80711 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.271598                   -0.262487   \n",
       "1                     1.619072                    1.439618   \n",
       "2                    -0.297406                   -0.262487   \n",
       "3                    -0.237216                   -0.262487   \n",
       "4                    -0.237216                   -0.262487   \n",
       "5                    -0.198263                   -0.262487   \n",
       "6                     0.016268                    0.411272   \n",
       "7                     0.799391                    0.895109   \n",
       "8                    -0.243275                   -0.262487   \n",
       "9                    -0.298449                   -0.262487   \n",
       "10                   -0.450526                   -0.262487   \n",
       "11                   -0.191298                   -0.262487   \n",
       "12                   -0.190985                   -0.262487   \n",
       "13                    2.708209                    2.917171   \n",
       "14                   -0.237216                   -0.262487   \n",
       "15                   -0.174593                   -0.262487   \n",
       "16                   -0.298449                   -0.262487   \n",
       "17                   -0.160953                   -0.262487   \n",
       "18                   -0.191298                   -0.262487   \n",
       "19                   -0.243275                   -0.262487   \n",
       "20                   -0.450526                   -0.262487   \n",
       "21                   -0.271598                   -0.262487   \n",
       "22                   -0.271598                   -0.262487   \n",
       "23                   -0.160953                   -0.262487   \n",
       "24                    0.960844                    0.908676   \n",
       "25                   -0.198263                   -0.262487   \n",
       "26                   -0.160953                   -0.262487   \n",
       "27                   -0.271598                   -0.262487   \n",
       "28                   -0.297406                   -0.262487   \n",
       "29                   -0.271598                   -0.262487   \n",
       "...                        ...                         ...   \n",
       "80681                -0.271598                   -0.262487   \n",
       "80682                -0.160953                   -0.262487   \n",
       "80683                -0.298449                   -0.262487   \n",
       "80684                -0.237216                   -0.262487   \n",
       "80685                -0.235617                   -0.262487   \n",
       "80686                -0.190985                   -0.262487   \n",
       "80687                -0.237216                   -0.262487   \n",
       "80688                -0.298449                   -0.262487   \n",
       "80689                -0.297406                   -0.262487   \n",
       "80690                -0.160953                   -0.262487   \n",
       "80691                -0.434616                   -0.262487   \n",
       "80692                -0.271598                   -0.262487   \n",
       "80693                -0.298449                   -0.262487   \n",
       "80694                -0.271598                   -0.262487   \n",
       "80695                -0.191298                   -0.262487   \n",
       "80696                -0.297970                   -0.262487   \n",
       "80697                -0.237216                   -0.262487   \n",
       "80698                 5.228654                    1.842697   \n",
       "80699                -0.191298                   -0.262487   \n",
       "80700                -0.191298                   -0.262487   \n",
       "80701                -0.239534                   -0.262487   \n",
       "80702                -0.434616                   -0.262487   \n",
       "80703                -0.384433                   -0.262487   \n",
       "80704                -0.236879                   -0.262487   \n",
       "80705                 6.252968                    6.783779   \n",
       "80706                -0.271598                   -0.262487   \n",
       "80707                -0.198263                   -0.262487   \n",
       "80708                -0.384433                   -0.262487   \n",
       "80709                 1.218371                    1.389923   \n",
       "80710                -0.190985                   -0.262487   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.042262                 0.205576  \n",
       "1                0.042262                 0.205576  \n",
       "2                0.042262                 0.205576  \n",
       "3                0.042262                 0.205576  \n",
       "4                0.042262                 0.205576  \n",
       "5                0.042262                 0.205576  \n",
       "6                0.042262                 0.205576  \n",
       "7                0.042262                 0.205576  \n",
       "8                0.042262                 0.205576  \n",
       "9                0.042262                 0.205576  \n",
       "10               0.042262                 0.205576  \n",
       "11               0.042262                 0.205576  \n",
       "12               0.042262                 0.205576  \n",
       "13               0.042262                 0.205576  \n",
       "14               0.042262                 0.205576  \n",
       "15               0.042262                 0.205576  \n",
       "16               0.042262                 0.205576  \n",
       "17               0.042262                 0.205576  \n",
       "18               0.042262                 0.205576  \n",
       "19               0.042262                 0.205576  \n",
       "20               0.042262                 0.205576  \n",
       "21               0.042262                 0.205576  \n",
       "22               0.042262                 0.205576  \n",
       "23               0.042262                 0.205576  \n",
       "24               0.042262                 0.205576  \n",
       "25               0.042262                 0.205576  \n",
       "26               0.042262                 0.205576  \n",
       "27               0.042262                 0.205576  \n",
       "28               0.042262                 0.205576  \n",
       "29               0.042262                 0.205576  \n",
       "...                   ...                      ...  \n",
       "80681            0.042262                 0.205576  \n",
       "80682            0.042262                 0.205576  \n",
       "80683            0.042262                 0.205576  \n",
       "80684            0.042262                 0.205576  \n",
       "80685            0.042262                 0.205576  \n",
       "80686            0.042262                 0.205576  \n",
       "80687            0.042262                 0.205576  \n",
       "80688            0.042262                 0.205576  \n",
       "80689            0.042262                 0.205576  \n",
       "80690            0.042262                 0.205576  \n",
       "80691            0.042262                 0.205576  \n",
       "80692            0.042262                 0.205576  \n",
       "80693            0.042262                 0.205576  \n",
       "80694            0.042262                 0.205576  \n",
       "80695            0.042262                 0.205576  \n",
       "80696            0.042262                 0.205576  \n",
       "80697            0.042262                 0.205576  \n",
       "80698            0.042262                 0.205576  \n",
       "80699            0.042262                 0.205576  \n",
       "80700            0.042262                 0.205576  \n",
       "80701            0.042262                 0.205576  \n",
       "80702            0.042262                 0.205576  \n",
       "80703            0.042262                 0.205576  \n",
       "80704            0.042262                 0.205576  \n",
       "80705            0.042262                 0.205576  \n",
       "80706            0.042262                 0.205576  \n",
       "80707            0.042262                 0.205576  \n",
       "80708            0.042262                 0.205576  \n",
       "80709            0.042262                 0.205576  \n",
       "80710            0.042262                 0.205576  \n",
       "\n",
       "[80711 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_1 = regressor_1.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_1 = y_pred_train_1.reshape(80711,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_1 }\n",
    "y_compare_train_1 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_1['Mean Squared Error'] = (np.diff(y_compare_train_1.values) ** 2)\n",
    "y_compare_train_1['Mean Squared Error'] = np.mean(y_compare_train_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_1['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nNow, we will train an ANN with a very high number of nodes. And comparitively more layers.\\n\\n7-50-100-200-100-50-20-1\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now, we will train an ANN with a very high number of nodes. And comparitively more layers.\n",
    "\n",
    "7-50-100-200-100-50-20-1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.1990\n",
      "Epoch 2/100\n",
      "80711/80711 [==============================] - 23s 282us/step - loss: 0.1465\n",
      "Epoch 3/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.1434\n",
      "Epoch 4/100\n",
      "80711/80711 [==============================] - 22s 273us/step - loss: 0.1452\n",
      "Epoch 5/100\n",
      "80711/80711 [==============================] - 22s 272us/step - loss: 0.1339\n",
      "Epoch 6/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.1102\n",
      "Epoch 7/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.1288\n",
      "Epoch 8/100\n",
      "80711/80711 [==============================] - 23s 288us/step - loss: 0.1246\n",
      "Epoch 9/100\n",
      "80711/80711 [==============================] - 23s 282us/step - loss: 0.1103\n",
      "Epoch 10/100\n",
      "80711/80711 [==============================] - 22s 274us/step - loss: 0.1058\n",
      "Epoch 11/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.1282\n",
      "Epoch 12/100\n",
      "80711/80711 [==============================] - 22s 274us/step - loss: 0.1041\n",
      "Epoch 13/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.0999\n",
      "Epoch 14/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.1068\n",
      "Epoch 15/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.1315\n",
      "Epoch 16/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.1541\n",
      "Epoch 17/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0964\n",
      "Epoch 18/100\n",
      "80711/80711 [==============================] - 22s 279us/step - loss: 0.0990\n",
      "Epoch 19/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.1007\n",
      "Epoch 20/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.1133\n",
      "Epoch 21/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0875\n",
      "Epoch 22/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.9698\n",
      "Epoch 23/100\n",
      "80711/80711 [==============================] - 23s 282us/step - loss: 0.1037\n",
      "Epoch 24/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0695\n",
      "Epoch 25/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0786\n",
      "Epoch 26/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.0826\n",
      "Epoch 27/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0770\n",
      "Epoch 28/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.4373\n",
      "Epoch 29/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.1098\n",
      "Epoch 30/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0785\n",
      "Epoch 31/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.1208\n",
      "Epoch 32/100\n",
      "80711/80711 [==============================] - 24s 295us/step - loss: 0.0734\n",
      "Epoch 33/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 0.0783\n",
      "Epoch 34/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.0963\n",
      "Epoch 35/100\n",
      "80711/80711 [==============================] - 22s 274us/step - loss: 0.1329\n",
      "Epoch 36/100\n",
      "80711/80711 [==============================] - 23s 289us/step - loss: 0.1395\n",
      "Epoch 37/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.0738\n",
      "Epoch 38/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0618\n",
      "Epoch 39/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 0.0626\n",
      "Epoch 40/100\n",
      "80711/80711 [==============================] - 24s 297us/step - loss: 0.0551\n",
      "Epoch 41/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0949\n",
      "Epoch 42/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.0533\n",
      "Epoch 43/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0647\n",
      "Epoch 44/100\n",
      "80711/80711 [==============================] - 22s 279us/step - loss: 0.5045\n",
      "Epoch 45/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.0492\n",
      "Epoch 46/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 0.0562\n",
      "Epoch 47/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0569\n",
      "Epoch 48/100\n",
      "80711/80711 [==============================] - 23s 287us/step - loss: 0.0679\n",
      "Epoch 49/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 4.7586\n",
      "Epoch 50/100\n",
      "80711/80711 [==============================] - 23s 282us/step - loss: 0.0535\n",
      "Epoch 51/100\n",
      "80711/80711 [==============================] - 23s 285us/step - loss: 0.0497\n",
      "Epoch 52/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 0.0792\n",
      "Epoch 53/100\n",
      "80711/80711 [==============================] - 23s 282us/step - loss: 0.0534\n",
      "Epoch 54/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 0.0518\n",
      "Epoch 55/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.0910\n",
      "Epoch 56/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 0.0561\n",
      "Epoch 57/100\n",
      "80711/80711 [==============================] - 23s 282us/step - loss: 0.0472\n",
      "Epoch 58/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0454\n",
      "Epoch 59/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0409\n",
      "Epoch 60/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.1147\n",
      "Epoch 61/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 0.0523\n",
      "Epoch 62/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.0403\n",
      "Epoch 63/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 0.0459\n",
      "Epoch 64/100\n",
      "80711/80711 [==============================] - 22s 279us/step - loss: 0.0564\n",
      "Epoch 65/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0592\n",
      "Epoch 66/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 0.0662\n",
      "Epoch 67/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0614\n",
      "Epoch 68/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0414\n",
      "Epoch 69/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0564\n",
      "Epoch 70/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0886\n",
      "Epoch 71/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.1095\n",
      "Epoch 72/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.1026\n",
      "Epoch 73/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0544\n",
      "Epoch 74/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0574\n",
      "Epoch 75/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0813\n",
      "Epoch 76/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0455\n",
      "Epoch 77/100\n",
      "80711/80711 [==============================] - 23s 285us/step - loss: 0.0623\n",
      "Epoch 78/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0539\n",
      "Epoch 79/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0528\n",
      "Epoch 80/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.0414\n",
      "Epoch 81/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0489\n",
      "Epoch 82/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.0842\n",
      "Epoch 83/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0436\n",
      "Epoch 84/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.0394\n",
      "Epoch 85/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0421\n",
      "Epoch 86/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0542\n",
      "Epoch 87/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.2241\n",
      "Epoch 88/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0408\n",
      "Epoch 89/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0559\n",
      "Epoch 90/100\n",
      "80711/80711 [==============================] - 23s 283us/step - loss: 0.0786\n",
      "Epoch 91/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0514\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.0484\n",
      "Epoch 93/100\n",
      "80711/80711 [==============================] - 22s 272us/step - loss: 0.0610\n",
      "Epoch 94/100\n",
      "80711/80711 [==============================] - 22s 273us/step - loss: 1.0145\n",
      "Epoch 95/100\n",
      "80711/80711 [==============================] - 22s 273us/step - loss: 0.0522\n",
      "Epoch 96/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0437\n",
      "Epoch 97/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0575\n",
      "Epoch 98/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0453\n",
      "Epoch 99/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0447\n",
      "Epoch 100/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x132306b00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a deep and wide ANN with high number of nodes \"\"\"\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "regressor_2 = Sequential()\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal',input_dim = 7))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(200, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(20, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_2.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.345960</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508167</td>\n",
       "      <td>1.521016</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.279556</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.287331</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610709</td>\n",
       "      <td>1.620239</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.286180</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.327976</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.290851</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.208127</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.278054</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.331151</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.236116</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.427985</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.261976</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.207191</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.234179</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.285639</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.222529</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.408553</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.362141</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.271100</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.337313</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.269193</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.324284</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.417803</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.278446</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.294735</td>\n",
       "      <td>1.367243</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.285493</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.338727</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20148</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.384149</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20149</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.276834</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.286037</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.427769</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20152</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.210227</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.274089</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>0.295361</td>\n",
       "      <td>0.298848</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.336358</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.254143</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.273884</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.285444</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.287160</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.410680</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.335792</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.422821</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.224597</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20164</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.380356</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20165</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.224711</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20166</th>\n",
       "      <td>1.881052</td>\n",
       "      <td>1.580523</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20167</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.260103</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.291492</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20169</th>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.786176</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.259818</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.225312</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20172</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.271258</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.277201</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20174</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.290308</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>2.497956</td>\n",
       "      <td>2.583906</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.275175</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20177</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.268798</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20178 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.297970         -0.345960            0.032871   \n",
       "1           1.508167          1.521016            0.032871   \n",
       "2          -0.271598         -0.279556            0.032871   \n",
       "3          -0.243275         -0.287331            0.032871   \n",
       "4           1.610709          1.620239            0.032871   \n",
       "5          -0.243275         -0.286180            0.032871   \n",
       "6          -0.298449         -0.327976            0.032871   \n",
       "7          -0.271598         -0.290851            0.032871   \n",
       "8          -0.198263         -0.208127            0.032871   \n",
       "9          -0.271598         -0.278054            0.032871   \n",
       "10         -0.297406         -0.331151            0.032871   \n",
       "11         -0.243275         -0.236116            0.032871   \n",
       "12         -0.450526         -0.427985            0.032871   \n",
       "13         -0.243275         -0.261976            0.032871   \n",
       "14         -0.174593         -0.207191            0.032871   \n",
       "15         -0.160953         -0.234179            0.032871   \n",
       "16         -0.271598         -0.285639            0.032871   \n",
       "17         -0.237216         -0.222529            0.032871   \n",
       "18         -0.384433         -0.408553            0.032871   \n",
       "19         -0.298449         -0.362141            0.032871   \n",
       "20         -0.271598         -0.271100            0.032871   \n",
       "21         -0.298449         -0.337313            0.032871   \n",
       "22         -0.236879         -0.269193            0.032871   \n",
       "23         -0.298449         -0.324284            0.032871   \n",
       "24          0.016268          0.009330            0.032871   \n",
       "25         -0.434616         -0.417803            0.032871   \n",
       "26         -0.271598         -0.278446            0.032871   \n",
       "27          1.294735          1.367243            0.032871   \n",
       "28         -0.297406         -0.285493            0.032871   \n",
       "29         -0.297970         -0.338727            0.032871   \n",
       "...              ...               ...                 ...   \n",
       "20148       0.400342          0.384149            0.032871   \n",
       "20149      -0.243275         -0.276834            0.032871   \n",
       "20150      -0.243275         -0.286037            0.032871   \n",
       "20151       0.400342          0.427769            0.032871   \n",
       "20152      -0.235617         -0.210227            0.032871   \n",
       "20153      -0.271598         -0.274089            0.032871   \n",
       "20154       0.295361          0.298848            0.032871   \n",
       "20155      -0.298449         -0.336358            0.032871   \n",
       "20156      -0.235617         -0.254143            0.032871   \n",
       "20157      -0.271598         -0.273884            0.032871   \n",
       "20158      -0.298449         -0.285444            0.032871   \n",
       "20159      -0.298449         -0.287160            0.032871   \n",
       "20160      -0.384433         -0.410680            0.032871   \n",
       "20161      -0.297970         -0.335792            0.032871   \n",
       "20162      -0.450526         -0.422821            0.032871   \n",
       "20163      -0.237216         -0.224597            0.032871   \n",
       "20164      -0.450526         -0.380356            0.032871   \n",
       "20165      -0.190985         -0.224711            0.032871   \n",
       "20166       1.881052          1.580523            0.032871   \n",
       "20167      -0.174593         -0.260103            0.032871   \n",
       "20168      -0.271598         -0.291492            0.032871   \n",
       "20169       0.928402          0.786176            0.032871   \n",
       "20170      -0.297970         -0.259818            0.032871   \n",
       "20171      -0.235617         -0.225312            0.032871   \n",
       "20172      -0.198263         -0.271258            0.032871   \n",
       "20173      -0.190985         -0.277201            0.032871   \n",
       "20174      -0.191298         -0.290308            0.032871   \n",
       "20175       2.497956          2.583906            0.032871   \n",
       "20176      -0.271598         -0.275175            0.032871   \n",
       "20177      -0.243275         -0.268798            0.032871   \n",
       "\n",
       "       Root Mean Squared Error  \n",
       "0                     0.181305  \n",
       "1                     0.181305  \n",
       "2                     0.181305  \n",
       "3                     0.181305  \n",
       "4                     0.181305  \n",
       "5                     0.181305  \n",
       "6                     0.181305  \n",
       "7                     0.181305  \n",
       "8                     0.181305  \n",
       "9                     0.181305  \n",
       "10                    0.181305  \n",
       "11                    0.181305  \n",
       "12                    0.181305  \n",
       "13                    0.181305  \n",
       "14                    0.181305  \n",
       "15                    0.181305  \n",
       "16                    0.181305  \n",
       "17                    0.181305  \n",
       "18                    0.181305  \n",
       "19                    0.181305  \n",
       "20                    0.181305  \n",
       "21                    0.181305  \n",
       "22                    0.181305  \n",
       "23                    0.181305  \n",
       "24                    0.181305  \n",
       "25                    0.181305  \n",
       "26                    0.181305  \n",
       "27                    0.181305  \n",
       "28                    0.181305  \n",
       "29                    0.181305  \n",
       "...                        ...  \n",
       "20148                 0.181305  \n",
       "20149                 0.181305  \n",
       "20150                 0.181305  \n",
       "20151                 0.181305  \n",
       "20152                 0.181305  \n",
       "20153                 0.181305  \n",
       "20154                 0.181305  \n",
       "20155                 0.181305  \n",
       "20156                 0.181305  \n",
       "20157                 0.181305  \n",
       "20158                 0.181305  \n",
       "20159                 0.181305  \n",
       "20160                 0.181305  \n",
       "20161                 0.181305  \n",
       "20162                 0.181305  \n",
       "20163                 0.181305  \n",
       "20164                 0.181305  \n",
       "20165                 0.181305  \n",
       "20166                 0.181305  \n",
       "20167                 0.181305  \n",
       "20168                 0.181305  \n",
       "20169                 0.181305  \n",
       "20170                 0.181305  \n",
       "20171                 0.181305  \n",
       "20172                 0.181305  \n",
       "20173                 0.181305  \n",
       "20174                 0.181305  \n",
       "20175                 0.181305  \n",
       "20176                 0.181305  \n",
       "20177                 0.181305  \n",
       "\n",
       "[20178 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_2 = regressor_2.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_2 = y_pred_2.reshape(20178,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare_2 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_2['Mean Squared Error'] = (np.diff(y_compare_2.values) ** 2)\n",
    "y_compare_2['Mean Squared Error'] = np.mean(y_compare_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_2['Root Mean Squared Error'] = y_compare_2['Mean Squared Error']**0.5\n",
    "y_compare_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.288828</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.619072</td>\n",
       "      <td>1.773905</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.325977</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.279876</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.226852</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.389412</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.252685</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.799391</td>\n",
       "      <td>0.803270</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.309864</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.297476</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.430048</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.297218</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.260769</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.708209</td>\n",
       "      <td>2.767602</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.263613</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.270657</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.318912</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.279511</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.281811</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.298935</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.335512</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.284913</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.280267</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.237957</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.960844</td>\n",
       "      <td>0.856663</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.231307</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.218964</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.274932</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.353276</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.287727</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80681</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.297595</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80682</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.248379</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80683</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.283701</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80684</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.291116</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80685</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.269547</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80686</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.220730</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80687</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.250268</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80688</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.316249</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80689</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.355079</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80690</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.245648</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80691</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.496871</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80692</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.277016</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80693</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.294849</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80694</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.295758</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80695</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.316854</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80696</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.401726</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80697</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.307545</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80698</th>\n",
       "      <td>5.228654</td>\n",
       "      <td>3.197642</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80699</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.316538</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80700</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.272816</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80701</th>\n",
       "      <td>-0.239534</td>\n",
       "      <td>-0.292430</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80702</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.477648</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80703</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.418468</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80704</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.314522</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80705</th>\n",
       "      <td>6.252968</td>\n",
       "      <td>5.911989</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.283774</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80707</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.210531</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80708</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.393783</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80709</th>\n",
       "      <td>1.218371</td>\n",
       "      <td>1.349400</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80710</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.269570</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.205576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80711 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.271598                   -0.288828   \n",
       "1                     1.619072                    1.773905   \n",
       "2                    -0.297406                   -0.325977   \n",
       "3                    -0.237216                   -0.279876   \n",
       "4                    -0.237216                   -0.226852   \n",
       "5                    -0.198263                   -0.389412   \n",
       "6                     0.016268                    0.252685   \n",
       "7                     0.799391                    0.803270   \n",
       "8                    -0.243275                   -0.309864   \n",
       "9                    -0.298449                   -0.297476   \n",
       "10                   -0.450526                   -0.430048   \n",
       "11                   -0.191298                   -0.297218   \n",
       "12                   -0.190985                   -0.260769   \n",
       "13                    2.708209                    2.767602   \n",
       "14                   -0.237216                   -0.263613   \n",
       "15                   -0.174593                   -0.270657   \n",
       "16                   -0.298449                   -0.318912   \n",
       "17                   -0.160953                   -0.279511   \n",
       "18                   -0.191298                   -0.281811   \n",
       "19                   -0.243275                   -0.298935   \n",
       "20                   -0.450526                   -0.335512   \n",
       "21                   -0.271598                   -0.284913   \n",
       "22                   -0.271598                   -0.280267   \n",
       "23                   -0.160953                   -0.237957   \n",
       "24                    0.960844                    0.856663   \n",
       "25                   -0.198263                   -0.231307   \n",
       "26                   -0.160953                   -0.218964   \n",
       "27                   -0.271598                   -0.274932   \n",
       "28                   -0.297406                   -0.353276   \n",
       "29                   -0.271598                   -0.287727   \n",
       "...                        ...                         ...   \n",
       "80681                -0.271598                   -0.297595   \n",
       "80682                -0.160953                   -0.248379   \n",
       "80683                -0.298449                   -0.283701   \n",
       "80684                -0.237216                   -0.291116   \n",
       "80685                -0.235617                   -0.269547   \n",
       "80686                -0.190985                   -0.220730   \n",
       "80687                -0.237216                   -0.250268   \n",
       "80688                -0.298449                   -0.316249   \n",
       "80689                -0.297406                   -0.355079   \n",
       "80690                -0.160953                   -0.245648   \n",
       "80691                -0.434616                   -0.496871   \n",
       "80692                -0.271598                   -0.277016   \n",
       "80693                -0.298449                   -0.294849   \n",
       "80694                -0.271598                   -0.295758   \n",
       "80695                -0.191298                   -0.316854   \n",
       "80696                -0.297970                   -0.401726   \n",
       "80697                -0.237216                   -0.307545   \n",
       "80698                 5.228654                    3.197642   \n",
       "80699                -0.191298                   -0.316538   \n",
       "80700                -0.191298                   -0.272816   \n",
       "80701                -0.239534                   -0.292430   \n",
       "80702                -0.434616                   -0.477648   \n",
       "80703                -0.384433                   -0.418468   \n",
       "80704                -0.236879                   -0.314522   \n",
       "80705                 6.252968                    5.911989   \n",
       "80706                -0.271598                   -0.283774   \n",
       "80707                -0.198263                   -0.210531   \n",
       "80708                -0.384433                   -0.393783   \n",
       "80709                 1.218371                    1.349400   \n",
       "80710                -0.190985                   -0.269570   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.027841                 0.205576  \n",
       "1                0.027841                 0.205576  \n",
       "2                0.027841                 0.205576  \n",
       "3                0.027841                 0.205576  \n",
       "4                0.027841                 0.205576  \n",
       "5                0.027841                 0.205576  \n",
       "6                0.027841                 0.205576  \n",
       "7                0.027841                 0.205576  \n",
       "8                0.027841                 0.205576  \n",
       "9                0.027841                 0.205576  \n",
       "10               0.027841                 0.205576  \n",
       "11               0.027841                 0.205576  \n",
       "12               0.027841                 0.205576  \n",
       "13               0.027841                 0.205576  \n",
       "14               0.027841                 0.205576  \n",
       "15               0.027841                 0.205576  \n",
       "16               0.027841                 0.205576  \n",
       "17               0.027841                 0.205576  \n",
       "18               0.027841                 0.205576  \n",
       "19               0.027841                 0.205576  \n",
       "20               0.027841                 0.205576  \n",
       "21               0.027841                 0.205576  \n",
       "22               0.027841                 0.205576  \n",
       "23               0.027841                 0.205576  \n",
       "24               0.027841                 0.205576  \n",
       "25               0.027841                 0.205576  \n",
       "26               0.027841                 0.205576  \n",
       "27               0.027841                 0.205576  \n",
       "28               0.027841                 0.205576  \n",
       "29               0.027841                 0.205576  \n",
       "...                   ...                      ...  \n",
       "80681            0.027841                 0.205576  \n",
       "80682            0.027841                 0.205576  \n",
       "80683            0.027841                 0.205576  \n",
       "80684            0.027841                 0.205576  \n",
       "80685            0.027841                 0.205576  \n",
       "80686            0.027841                 0.205576  \n",
       "80687            0.027841                 0.205576  \n",
       "80688            0.027841                 0.205576  \n",
       "80689            0.027841                 0.205576  \n",
       "80690            0.027841                 0.205576  \n",
       "80691            0.027841                 0.205576  \n",
       "80692            0.027841                 0.205576  \n",
       "80693            0.027841                 0.205576  \n",
       "80694            0.027841                 0.205576  \n",
       "80695            0.027841                 0.205576  \n",
       "80696            0.027841                 0.205576  \n",
       "80697            0.027841                 0.205576  \n",
       "80698            0.027841                 0.205576  \n",
       "80699            0.027841                 0.205576  \n",
       "80700            0.027841                 0.205576  \n",
       "80701            0.027841                 0.205576  \n",
       "80702            0.027841                 0.205576  \n",
       "80703            0.027841                 0.205576  \n",
       "80704            0.027841                 0.205576  \n",
       "80705            0.027841                 0.205576  \n",
       "80706            0.027841                 0.205576  \n",
       "80707            0.027841                 0.205576  \n",
       "80708            0.027841                 0.205576  \n",
       "80709            0.027841                 0.205576  \n",
       "80710            0.027841                 0.205576  \n",
       "\n",
       "[80711 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_2 = regressor_2.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_2 = y_pred_train_2.reshape(80711,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_2 }\n",
    "y_compare_train_2 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_2['Mean Squared Error'] = (np.diff(y_compare_train_2.values) ** 2)\n",
    "y_compare_train_2['Mean Squared Error'] = np.mean(y_compare_train_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_2['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
