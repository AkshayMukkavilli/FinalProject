{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TARGET LABEL: Z_Score_HelpfulVotes\n",
    "SCALER: STANDARD SCALER\n",
    "ANN'S : \n",
    "    Combination 1: 7-100-100-1\n",
    "    \n",
    "    Combination 2:  7-4-4-1\n",
    "\n",
    "    Combination 3:  7-50-100-200-100-50-20-1\n",
    "\n",
    "    Combination 4: 7-50-50-11\n",
    "\n",
    "    Combination 5: 7-20-20-11\n",
    "    \n",
    "Here we will use the absolute value of (Sentiment - Mean of Sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Absolute(Sentiment-Mean)</th>\n",
       "      <th>Z_Score_HelpfulVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>166.125000</td>\n",
       "      <td>0.118601</td>\n",
       "      <td>6.515421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>352.500000</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>3.557805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>0.173722</td>\n",
       "      <td>3.557805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>188.666667</td>\n",
       "      <td>0.125016</td>\n",
       "      <td>70.014530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>0.431510</td>\n",
       "      <td>2.347872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0      4    268           8             14                      3   \n",
       "1      1    130           2              2                      2   \n",
       "2      1    110           1              0                      3   \n",
       "3      5    110           3              4                      3   \n",
       "4      1     39           1              0                      3   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  \\\n",
       "0                     90                    166.125000   \n",
       "1                     94                    352.500000   \n",
       "2                     90                    556.000000   \n",
       "3                     92                    188.666667   \n",
       "4                     96                    216.000000   \n",
       "\n",
       "   Absolute(Sentiment-Mean)  Z_Score_HelpfulVotes  \n",
       "0                  0.118601              6.515421  \n",
       "1                  0.140716              3.557805  \n",
       "2                  0.173722              3.557805  \n",
       "3                  0.125016             70.014530  \n",
       "4                  0.431510              2.347872  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r\"/Users/t_velpac/mission/WorkingCopy/final_csv_files/Abs_Sentiment-Mean.csv\")\n",
    "dataset = dataset.drop(columns=['Date', 'Helpful_Votes', 'Z_Score_Words', 'Z_Score_Paragraphs', 'Sentiment_Polarity'])\n",
    "cols = (list(dataset.columns))\n",
    "cols.remove('Z_Score_HelpfulVotes')\n",
    "cols.append('Z_Score_HelpfulVotes')\n",
    "dataset = dataset[cols]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Splitting the independent variables from the dependent variable \"\"\"\n",
    "X = dataset.iloc[:,0:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting the data into training data and testing data\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "\"\"\"Scaling the data using StandardScaler from sklearn package\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/WorkingCopy/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/WorkingCopy/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.0328\n",
      "Epoch 2/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.0305 - ETA: 0s - loss: 1.\n",
      "Epoch 3/100\n",
      "156392/156392 [==============================] - 33s 214us/step - loss: 1.0304\n",
      "Epoch 4/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0299\n",
      "Epoch 5/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.0262\n",
      "Epoch 6/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0251\n",
      "Epoch 7/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.0273\n",
      "Epoch 8/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0264 \n",
      "Epoch 9/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.02700s - loss: 1\n",
      "Epoch 10/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.0255\n",
      "Epoch 11/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0252\n",
      "Epoch 12/100\n",
      "156392/156392 [==============================] - 32s 207us/step - loss: 1.0261\n",
      "Epoch 13/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0257\n",
      "Epoch 14/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0268\n",
      "Epoch 15/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0280\n",
      "Epoch 16/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.02601s -  - ETA: 1s - lo - ETA: 0\n",
      "Epoch 17/100\n",
      "156392/156392 [==============================] - 32s 205us/step - loss: 1.0262\n",
      "Epoch 18/100\n",
      "156392/156392 [==============================] - 32s 203us/step - loss: 1.0258\n",
      "Epoch 19/100\n",
      "156392/156392 [==============================] - 32s 203us/step - loss: 1.0264\n",
      "Epoch 20/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0269\n",
      "Epoch 21/100\n",
      "156392/156392 [==============================] - 32s 207us/step - loss: 1.0265\n",
      "Epoch 22/100\n",
      "156392/156392 [==============================] - 32s 205us/step - loss: 1.0270\n",
      "Epoch 23/100\n",
      "156392/156392 [==============================] - 32s 207us/step - loss: 1.02681s - \n",
      "Epoch 24/100\n",
      "156392/156392 [==============================] - 32s 205us/step - loss: 1.02640s - l\n",
      "Epoch 25/100\n",
      "156392/156392 [==============================] - 32s 203us/step - loss: 1.0277\n",
      "Epoch 26/100\n",
      "156392/156392 [==============================] - 33s 208us/step - loss: 1.0273\n",
      "Epoch 27/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.02607s - loss: 1. - ET - E\n",
      "Epoch 28/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0297\n",
      "Epoch 29/100\n",
      "156392/156392 [==============================] - 32s 205us/step - loss: 1.0287\n",
      "Epoch 30/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.0300\n",
      "Epoch 31/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0295\n",
      "Epoch 32/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.0292\n",
      "Epoch 33/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.02940s - loss: 1.023 - ETA: 0s - loss\n",
      "Epoch 34/100\n",
      "156392/156392 [==============================] - 32s 207us/step - loss: 1.0289\n",
      "Epoch 35/100\n",
      "156392/156392 [==============================] - 32s 208us/step - loss: 1.0301\n",
      "Epoch 36/100\n",
      "156392/156392 [==============================] - 32s 203us/step - loss: 1.0291\n",
      "Epoch 37/100\n",
      "156392/156392 [==============================] - 32s 205us/step - loss: 1.03120s - loss: \n",
      "Epoch 38/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.0316 \n",
      "Epoch 39/100\n",
      "156392/156392 [==============================] - 31s 201us/step - loss: 1.0304\n",
      "Epoch 40/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0284\n",
      "Epoch 41/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0274\n",
      "Epoch 42/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.02870s - l\n",
      "Epoch 43/100\n",
      "156392/156392 [==============================] - 32s 207us/step - loss: 1.02690s - lo\n",
      "Epoch 44/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0275ETA: 0s - loss\n",
      "Epoch 45/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.03201s - l\n",
      "Epoch 46/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.0278A: 1s - - ETA: 1s - loss: 1. - ETA:\n",
      "Epoch 47/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0290\n",
      "Epoch 48/100\n",
      "156392/156392 [==============================] - 32s 208us/step - loss: 1.0305\n",
      "Epoch 49/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.03024s - loss: 1.0 -  - ETA: 2s -  - ETA: 1s - loss: 1.05 - ETA:  - ETA: 0s - \n",
      "Epoch 50/100\n",
      "156392/156392 [==============================] - 32s 205us/step - loss: 1.0302A: 0s - loss: 1.03\n",
      "Epoch 51/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.02661s - loss: 1.051 - ETA: 1s - - ETA: 0s - loss: 1.032 - ETA: 0s - loss:\n",
      "Epoch 52/100\n",
      "156392/156392 [==============================] - 32s 205us/step - loss: 1.02833s - loss: 1.0 - ETA: 3s \n",
      "Epoch 53/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0268\n",
      "Epoch 54/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0236\n",
      "Epoch 55/100\n",
      "156392/156392 [==============================] - 32s 203us/step - loss: 1.0291\n",
      "Epoch 56/100\n",
      "156392/156392 [==============================] - 32s 207us/step - loss: 1.0320\n",
      "Epoch 57/100\n",
      "156392/156392 [==============================] - 33s 208us/step - loss: 1.0288\n",
      "Epoch 58/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.02931s - l\n",
      "Epoch 59/100\n",
      "156392/156392 [==============================] - 32s 206us/step - loss: 1.0292\n",
      "Epoch 60/100\n",
      "156392/156392 [==============================] - 32s 208us/step - loss: 1.02910s - l\n",
      "Epoch 61/100\n",
      "156392/156392 [==============================] - 32s 204us/step - loss: 1.0291\n",
      "Epoch 62/100\n",
      "156392/156392 [==============================] - 33s 208us/step - loss: 1.0296\n",
      "Epoch 63/100\n",
      "156392/156392 [==============================] - 32s 208us/step - loss: 1.0353\n",
      "Epoch 64/100\n",
      "156392/156392 [==============================] - 32s 208us/step - loss: 1.02790s - \n",
      "Epoch 65/100\n",
      "156392/156392 [==============================] - 34s 220us/step - loss: 1.03090s - loss: 1.038 - ETA: 0s - loss:\n",
      "Epoch 66/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0346\n",
      "Epoch 67/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0290\n",
      "Epoch 68/100\n",
      "156392/156392 [==============================] - 35s 227us/step - loss: 1.0285\n",
      "Epoch 69/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0300\n",
      "Epoch 70/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0301\n",
      "Epoch 71/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0299\n",
      "Epoch 72/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0281\n",
      "Epoch 73/100\n",
      "156392/156392 [==============================] - 34s 216us/step - loss: 1.0352\n",
      "Epoch 74/100\n",
      "156392/156392 [==============================] - 33s 214us/step - loss: 1.0312\n",
      "Epoch 75/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.03100s - loss: 1. - ETA: 0s - loss: 1.\n",
      "Epoch 76/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.02663s - l - ETA - ETA: 1 - ETA:\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0291\n",
      "Epoch 78/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.0325\n",
      "Epoch 79/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.0291\n",
      "Epoch 80/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.02950s - loss: 1.02 - ETA: 0s - los\n",
      "Epoch 81/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0296\n",
      "Epoch 82/100\n",
      "156392/156392 [==============================] - 34s 218us/step - loss: 1.03090s - loss: 1\n",
      "Epoch 83/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0297\n",
      "Epoch 84/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.0291\n",
      "Epoch 85/100\n",
      "156392/156392 [==============================] - 35s 225us/step - loss: 1.0301\n",
      "Epoch 86/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.0301\n",
      "Epoch 87/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0284\n",
      "Epoch 88/100\n",
      "156392/156392 [==============================] - 34s 216us/step - loss: 1.02982s - lo - ETA: 2s - los - ETA: 1s - \n",
      "Epoch 89/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.0317\n",
      "Epoch 90/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.02950s - loss: - ETA: 0s - loss: 1.0\n",
      "Epoch 91/100\n",
      "156392/156392 [==============================] - 33s 214us/step - loss: 1.0290\n",
      "Epoch 92/100\n",
      "156392/156392 [==============================] - 33s 214us/step - loss: 1.0338\n",
      "Epoch 93/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0301\n",
      "Epoch 94/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0313\n",
      "Epoch 95/100\n",
      "156392/156392 [==============================] - 35s 221us/step - loss: 1.0285\n",
      "Epoch 96/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0310\n",
      "Epoch 97/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0310\n",
      "Epoch 98/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0323\n",
      "Epoch 99/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0322\n",
      "Epoch 100/100\n",
      "156392/156392 [==============================] - 35s 223us/step - loss: 1.0322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c208198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with high number of nodes \"\"\"\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal',activation = 'relu',input_dim = 8))\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Abs. Error</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>0.085131</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.032077</td>\n",
       "      <td>-0.064950</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.047652</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051497</td>\n",
       "      <td>-0.048188</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.061395</td>\n",
       "      <td>-0.062344</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.026445</td>\n",
       "      <td>0.150848</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.497499</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.090490</td>\n",
       "      <td>-0.072232</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.015826</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.050199</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.034817</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.379656</td>\n",
       "      <td>-0.038568</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.045836</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.059755</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.059533</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.098246</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.035768</td>\n",
       "      <td>-0.067906</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.080795</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.036986</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.028425</td>\n",
       "      <td>-0.026610</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.080863</td>\n",
       "      <td>-0.030437</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.086241</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.112014</td>\n",
       "      <td>-0.090343</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.061373</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.058271</td>\n",
       "      <td>-0.053147</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.017801</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.053417</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.077574</td>\n",
       "      <td>-0.059811</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39069</th>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.042109</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39070</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.042170</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39071</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39072</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.039122</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39073</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.060735</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39074</th>\n",
       "      <td>0.011187</td>\n",
       "      <td>0.460337</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39075</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39076</th>\n",
       "      <td>-0.162813</td>\n",
       "      <td>-0.003909</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39077</th>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.234240</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39078</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.063920</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39079</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.062544</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39080</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39081</th>\n",
       "      <td>-0.061395</td>\n",
       "      <td>-0.072223</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39082</th>\n",
       "      <td>0.068953</td>\n",
       "      <td>-0.032213</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39083</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.050180</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39084</th>\n",
       "      <td>-0.184994</td>\n",
       "      <td>-0.084582</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39085</th>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39086</th>\n",
       "      <td>0.122851</td>\n",
       "      <td>-0.048626</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39087</th>\n",
       "      <td>-0.040846</td>\n",
       "      <td>-0.030721</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39088</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.270598</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39089</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.057533</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39090</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-0.037108</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39091</th>\n",
       "      <td>-0.003969</td>\n",
       "      <td>-0.033619</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39092</th>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.106282</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39093</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.053605</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39094</th>\n",
       "      <td>0.313097</td>\n",
       "      <td>0.039815</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39095</th>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.065754</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.034460</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39097</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.020189</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39098</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.052066</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.89277</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>0.018846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39099 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.027183          0.085131            0.797038   \n",
       "1          -0.032077         -0.064950            0.797038   \n",
       "2          -0.031418         -0.047652            0.797038   \n",
       "3          -0.051497         -0.048188            0.797038   \n",
       "4          -0.029573          0.006704            0.797038   \n",
       "5          -0.061395         -0.062344            0.797038   \n",
       "6          -0.026445          0.150848            0.797038   \n",
       "7           0.497499          0.002593            0.797038   \n",
       "8          -0.090490         -0.072232            0.797038   \n",
       "9          -0.031418         -0.015826            0.797038   \n",
       "10         -0.033595         -0.050199            0.797038   \n",
       "11         -0.033817         -0.034817            0.797038   \n",
       "12         -0.379656         -0.038568            0.797038   \n",
       "13         -0.026282         -0.045836            0.797038   \n",
       "14         -0.033817         -0.059755            0.797038   \n",
       "15         -0.029573         -0.059533            0.797038   \n",
       "16         -0.033595         -0.098246            0.797038   \n",
       "17         -0.035768         -0.067906            0.797038   \n",
       "18         -0.033595         -0.080795            0.797038   \n",
       "19         -0.031418         -0.036986            0.797038   \n",
       "20         -0.026282          0.009077            0.797038   \n",
       "21         -0.028425         -0.026610            0.797038   \n",
       "22         -0.080863         -0.030437            0.797038   \n",
       "23         -0.026317          0.086241            0.797038   \n",
       "24         -0.112014         -0.090343            0.797038   \n",
       "25         -0.029573         -0.061373            0.797038   \n",
       "26         -0.058271         -0.053147            0.797038   \n",
       "27         -0.033595         -0.017801            0.797038   \n",
       "28         -0.026282         -0.053417            0.797038   \n",
       "29         -0.077574         -0.059811            0.797038   \n",
       "...              ...               ...                 ...   \n",
       "39069       0.187202         -0.042109            0.797038   \n",
       "39070      -0.031418         -0.042170            0.797038   \n",
       "39071      -0.033595          0.019585            0.797038   \n",
       "39072      -0.026282         -0.039122            0.797038   \n",
       "39073      -0.078543         -0.060735            0.797038   \n",
       "39074       0.011187          0.460337            0.797038   \n",
       "39075      -0.090653          0.082828            0.797038   \n",
       "39076      -0.162813         -0.003909            0.797038   \n",
       "39077       0.323026          0.234240            0.797038   \n",
       "39078      -0.031418         -0.063920            0.797038   \n",
       "39079      -0.188500         -0.062544            0.797038   \n",
       "39080      -0.188500         -0.049013            0.797038   \n",
       "39081      -0.061395         -0.072223            0.797038   \n",
       "39082       0.068953         -0.032213            0.797038   \n",
       "39083      -0.026282         -0.050180            0.797038   \n",
       "39084      -0.184994         -0.084582            0.797038   \n",
       "39085      -0.008194         -0.008295            0.797038   \n",
       "39086       0.122851         -0.048626            0.797038   \n",
       "39087      -0.040846         -0.030721            0.797038   \n",
       "39088      -0.026282         -0.270598            0.797038   \n",
       "39089      -0.078543         -0.057533            0.797038   \n",
       "39090      -0.027183         -0.037108            0.797038   \n",
       "39091      -0.003969         -0.033619            0.797038   \n",
       "39092       0.017207          0.106282            0.797038   \n",
       "39093      -0.033595         -0.053605            0.797038   \n",
       "39094       0.313097          0.039815            0.797038   \n",
       "39095      -0.057291         -0.065754            0.797038   \n",
       "39096      -0.031418         -0.034460            0.797038   \n",
       "39097      -0.188500         -0.020189            0.797038   \n",
       "39098      -0.033817         -0.052066            0.797038   \n",
       "\n",
       "       Root Mean Squared Error  Mean Abs. Error  R_Squared  \n",
       "0                      0.89277         0.106397   0.018846  \n",
       "1                      0.89277         0.106397   0.018846  \n",
       "2                      0.89277         0.106397   0.018846  \n",
       "3                      0.89277         0.106397   0.018846  \n",
       "4                      0.89277         0.106397   0.018846  \n",
       "5                      0.89277         0.106397   0.018846  \n",
       "6                      0.89277         0.106397   0.018846  \n",
       "7                      0.89277         0.106397   0.018846  \n",
       "8                      0.89277         0.106397   0.018846  \n",
       "9                      0.89277         0.106397   0.018846  \n",
       "10                     0.89277         0.106397   0.018846  \n",
       "11                     0.89277         0.106397   0.018846  \n",
       "12                     0.89277         0.106397   0.018846  \n",
       "13                     0.89277         0.106397   0.018846  \n",
       "14                     0.89277         0.106397   0.018846  \n",
       "15                     0.89277         0.106397   0.018846  \n",
       "16                     0.89277         0.106397   0.018846  \n",
       "17                     0.89277         0.106397   0.018846  \n",
       "18                     0.89277         0.106397   0.018846  \n",
       "19                     0.89277         0.106397   0.018846  \n",
       "20                     0.89277         0.106397   0.018846  \n",
       "21                     0.89277         0.106397   0.018846  \n",
       "22                     0.89277         0.106397   0.018846  \n",
       "23                     0.89277         0.106397   0.018846  \n",
       "24                     0.89277         0.106397   0.018846  \n",
       "25                     0.89277         0.106397   0.018846  \n",
       "26                     0.89277         0.106397   0.018846  \n",
       "27                     0.89277         0.106397   0.018846  \n",
       "28                     0.89277         0.106397   0.018846  \n",
       "29                     0.89277         0.106397   0.018846  \n",
       "...                        ...              ...        ...  \n",
       "39069                  0.89277         0.106397   0.018846  \n",
       "39070                  0.89277         0.106397   0.018846  \n",
       "39071                  0.89277         0.106397   0.018846  \n",
       "39072                  0.89277         0.106397   0.018846  \n",
       "39073                  0.89277         0.106397   0.018846  \n",
       "39074                  0.89277         0.106397   0.018846  \n",
       "39075                  0.89277         0.106397   0.018846  \n",
       "39076                  0.89277         0.106397   0.018846  \n",
       "39077                  0.89277         0.106397   0.018846  \n",
       "39078                  0.89277         0.106397   0.018846  \n",
       "39079                  0.89277         0.106397   0.018846  \n",
       "39080                  0.89277         0.106397   0.018846  \n",
       "39081                  0.89277         0.106397   0.018846  \n",
       "39082                  0.89277         0.106397   0.018846  \n",
       "39083                  0.89277         0.106397   0.018846  \n",
       "39084                  0.89277         0.106397   0.018846  \n",
       "39085                  0.89277         0.106397   0.018846  \n",
       "39086                  0.89277         0.106397   0.018846  \n",
       "39087                  0.89277         0.106397   0.018846  \n",
       "39088                  0.89277         0.106397   0.018846  \n",
       "39089                  0.89277         0.106397   0.018846  \n",
       "39090                  0.89277         0.106397   0.018846  \n",
       "39091                  0.89277         0.106397   0.018846  \n",
       "39092                  0.89277         0.106397   0.018846  \n",
       "39093                  0.89277         0.106397   0.018846  \n",
       "39094                  0.89277         0.106397   0.018846  \n",
       "39095                  0.89277         0.106397   0.018846  \n",
       "39096                  0.89277         0.106397   0.018846  \n",
       "39097                  0.89277         0.106397   0.018846  \n",
       "39098                  0.89277         0.106397   0.018846  \n",
       "\n",
       "[39099 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred = y_pred.reshape(39099,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare['Mean Squared Error'] = (np.diff(y_compare.values) ** 2)\n",
    "y_compare['Mean Squared Error'] = np.mean(y_compare['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare['Root Mean Squared Error'] = y_compare['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare['Mean Abs. Error'] = np.mean(abs(y_compare['Actual Values'] - y_compare['Predicted Values']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare['R_Squared'] = r2_score(y_test, y_pred)\n",
    "\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Abs. Error</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.084480</td>\n",
       "      <td>-0.024107</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.072782</td>\n",
       "      <td>0.903971</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112014</td>\n",
       "      <td>-0.048100</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059294</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.046479</td>\n",
       "      <td>-0.052191</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009217</td>\n",
       "      <td>-0.032304</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.013043</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-0.046464</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.058181</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>-0.012801</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.072782</td>\n",
       "      <td>-0.048577</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.058205</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.068953</td>\n",
       "      <td>-0.086756</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.067829</td>\n",
       "      <td>-0.046947</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.026166</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.056119</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.071856</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.035623</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.064184</td>\n",
       "      <td>0.242164</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.020759</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>0.055321</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.023780</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.080906</td>\n",
       "      <td>-0.005495</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.099322</td>\n",
       "      <td>-0.027735</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.013408</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.036384</td>\n",
       "      <td>-0.276806</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.067829</td>\n",
       "      <td>-0.039123</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.042021</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.045703</td>\n",
       "      <td>0.227059</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.066602</td>\n",
       "      <td>-0.059823</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156362</th>\n",
       "      <td>-0.040846</td>\n",
       "      <td>-0.064658</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156363</th>\n",
       "      <td>-0.016099</td>\n",
       "      <td>-0.073781</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156364</th>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.062149</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156365</th>\n",
       "      <td>-0.143639</td>\n",
       "      <td>-0.030146</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156366</th>\n",
       "      <td>-0.035768</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156367</th>\n",
       "      <td>-0.028425</td>\n",
       "      <td>-0.049244</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156368</th>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.045091</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156369</th>\n",
       "      <td>-0.162813</td>\n",
       "      <td>-0.043260</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156370</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.048996</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156371</th>\n",
       "      <td>0.202220</td>\n",
       "      <td>-0.031803</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156372</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.049192</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156373</th>\n",
       "      <td>-0.078494</td>\n",
       "      <td>-0.116976</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156374</th>\n",
       "      <td>-0.046517</td>\n",
       "      <td>-0.036304</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156375</th>\n",
       "      <td>-0.051497</td>\n",
       "      <td>-0.030411</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156376</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.027641</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156377</th>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.024491</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156378</th>\n",
       "      <td>-0.184994</td>\n",
       "      <td>-0.067586</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156379</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>-0.080645</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156380</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.043896</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156381</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>0.014228</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156382</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.030549</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156383</th>\n",
       "      <td>-0.379656</td>\n",
       "      <td>-0.030181</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156384</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>-0.000886</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156385</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.074191</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156386</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.071379</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156387</th>\n",
       "      <td>-0.078494</td>\n",
       "      <td>-0.056794</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156388</th>\n",
       "      <td>-0.080863</td>\n",
       "      <td>-0.055219</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156389</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.068935</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156390</th>\n",
       "      <td>-0.104989</td>\n",
       "      <td>0.052096</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156391</th>\n",
       "      <td>-0.000773</td>\n",
       "      <td>-0.038909</td>\n",
       "      <td>1.022265</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156392 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                     -0.084480                   -0.024107   \n",
       "1                     -0.072782                    0.903971   \n",
       "2                     -0.112014                   -0.048100   \n",
       "3                     -0.059294                   -0.042276   \n",
       "4                     -0.046479                   -0.052191   \n",
       "5                      0.009217                   -0.032304   \n",
       "6                     -0.008194                   -0.013043   \n",
       "7                     -0.027183                   -0.046464   \n",
       "8                     -0.033595                   -0.058181   \n",
       "9                     -0.090653                   -0.012801   \n",
       "10                    -0.072782                   -0.048577   \n",
       "11                    -0.048927                   -0.058205   \n",
       "12                     0.068953                   -0.086756   \n",
       "13                    -0.067829                   -0.046947   \n",
       "14                     0.006270                    0.026166   \n",
       "15                    -0.026282                   -0.056119   \n",
       "16                    -0.091704                   -0.071856   \n",
       "17                    -0.050341                   -0.035623   \n",
       "18                     0.064184                    0.242164   \n",
       "19                    -0.029573                   -0.020759   \n",
       "20                    -0.033817                    0.055321   \n",
       "21                    -0.033817                   -0.023780   \n",
       "22                    -0.080906                   -0.005495   \n",
       "23                    -0.099322                   -0.027735   \n",
       "24                    -0.078543                   -0.013408   \n",
       "25                    -0.036384                   -0.276806   \n",
       "26                    -0.067829                   -0.039123   \n",
       "27                    -0.091704                   -0.042021   \n",
       "28                    -0.045703                    0.227059   \n",
       "29                    -0.066602                   -0.059823   \n",
       "...                         ...                         ...   \n",
       "156362                -0.040846                   -0.064658   \n",
       "156363                -0.016099                   -0.073781   \n",
       "156364                -0.050341                   -0.062149   \n",
       "156365                -0.143639                   -0.030146   \n",
       "156366                -0.035768                    0.012366   \n",
       "156367                -0.028425                   -0.049244   \n",
       "156368                 0.187202                   -0.045091   \n",
       "156369                -0.162813                   -0.043260   \n",
       "156370                -0.026282                   -0.048996   \n",
       "156371                 0.202220                   -0.031803   \n",
       "156372                -0.033595                   -0.049192   \n",
       "156373                -0.078494                   -0.116976   \n",
       "156374                -0.046517                   -0.036304   \n",
       "156375                -0.051497                   -0.030411   \n",
       "156376                -0.026282                   -0.027641   \n",
       "156377                -0.048927                   -0.024491   \n",
       "156378                -0.184994                   -0.067586   \n",
       "156379                 0.001314                   -0.080645   \n",
       "156380                -0.033595                   -0.043896   \n",
       "156381                -0.188500                    0.014228   \n",
       "156382                -0.031418                   -0.030549   \n",
       "156383                -0.379656                   -0.030181   \n",
       "156384                -0.090653                   -0.000886   \n",
       "156385                -0.033595                   -0.074191   \n",
       "156386                -0.033595                   -0.071379   \n",
       "156387                -0.078494                   -0.056794   \n",
       "156388                -0.080863                   -0.055219   \n",
       "156389                -0.033595                   -0.068935   \n",
       "156390                -0.104989                    0.052096   \n",
       "156391                -0.000773                   -0.038909   \n",
       "\n",
       "        Mean Squared Error  Root Mean Squared Error  Mean Abs. Error  \\\n",
       "0                 1.022265                 1.011071         0.112606   \n",
       "1                 1.022265                 1.011071         0.112606   \n",
       "2                 1.022265                 1.011071         0.112606   \n",
       "3                 1.022265                 1.011071         0.112606   \n",
       "4                 1.022265                 1.011071         0.112606   \n",
       "5                 1.022265                 1.011071         0.112606   \n",
       "6                 1.022265                 1.011071         0.112606   \n",
       "7                 1.022265                 1.011071         0.112606   \n",
       "8                 1.022265                 1.011071         0.112606   \n",
       "9                 1.022265                 1.011071         0.112606   \n",
       "10                1.022265                 1.011071         0.112606   \n",
       "11                1.022265                 1.011071         0.112606   \n",
       "12                1.022265                 1.011071         0.112606   \n",
       "13                1.022265                 1.011071         0.112606   \n",
       "14                1.022265                 1.011071         0.112606   \n",
       "15                1.022265                 1.011071         0.112606   \n",
       "16                1.022265                 1.011071         0.112606   \n",
       "17                1.022265                 1.011071         0.112606   \n",
       "18                1.022265                 1.011071         0.112606   \n",
       "19                1.022265                 1.011071         0.112606   \n",
       "20                1.022265                 1.011071         0.112606   \n",
       "21                1.022265                 1.011071         0.112606   \n",
       "22                1.022265                 1.011071         0.112606   \n",
       "23                1.022265                 1.011071         0.112606   \n",
       "24                1.022265                 1.011071         0.112606   \n",
       "25                1.022265                 1.011071         0.112606   \n",
       "26                1.022265                 1.011071         0.112606   \n",
       "27                1.022265                 1.011071         0.112606   \n",
       "28                1.022265                 1.011071         0.112606   \n",
       "29                1.022265                 1.011071         0.112606   \n",
       "...                    ...                      ...              ...   \n",
       "156362            1.022265                 1.011071         0.112606   \n",
       "156363            1.022265                 1.011071         0.112606   \n",
       "156364            1.022265                 1.011071         0.112606   \n",
       "156365            1.022265                 1.011071         0.112606   \n",
       "156366            1.022265                 1.011071         0.112606   \n",
       "156367            1.022265                 1.011071         0.112606   \n",
       "156368            1.022265                 1.011071         0.112606   \n",
       "156369            1.022265                 1.011071         0.112606   \n",
       "156370            1.022265                 1.011071         0.112606   \n",
       "156371            1.022265                 1.011071         0.112606   \n",
       "156372            1.022265                 1.011071         0.112606   \n",
       "156373            1.022265                 1.011071         0.112606   \n",
       "156374            1.022265                 1.011071         0.112606   \n",
       "156375            1.022265                 1.011071         0.112606   \n",
       "156376            1.022265                 1.011071         0.112606   \n",
       "156377            1.022265                 1.011071         0.112606   \n",
       "156378            1.022265                 1.011071         0.112606   \n",
       "156379            1.022265                 1.011071         0.112606   \n",
       "156380            1.022265                 1.011071         0.112606   \n",
       "156381            1.022265                 1.011071         0.112606   \n",
       "156382            1.022265                 1.011071         0.112606   \n",
       "156383            1.022265                 1.011071         0.112606   \n",
       "156384            1.022265                 1.011071         0.112606   \n",
       "156385            1.022265                 1.011071         0.112606   \n",
       "156386            1.022265                 1.011071         0.112606   \n",
       "156387            1.022265                 1.011071         0.112606   \n",
       "156388            1.022265                 1.011071         0.112606   \n",
       "156389            1.022265                 1.011071         0.112606   \n",
       "156390            1.022265                 1.011071         0.112606   \n",
       "156391            1.022265                 1.011071         0.112606   \n",
       "\n",
       "        R_Squared  \n",
       "0        0.023537  \n",
       "1        0.023537  \n",
       "2        0.023537  \n",
       "3        0.023537  \n",
       "4        0.023537  \n",
       "5        0.023537  \n",
       "6        0.023537  \n",
       "7        0.023537  \n",
       "8        0.023537  \n",
       "9        0.023537  \n",
       "10       0.023537  \n",
       "11       0.023537  \n",
       "12       0.023537  \n",
       "13       0.023537  \n",
       "14       0.023537  \n",
       "15       0.023537  \n",
       "16       0.023537  \n",
       "17       0.023537  \n",
       "18       0.023537  \n",
       "19       0.023537  \n",
       "20       0.023537  \n",
       "21       0.023537  \n",
       "22       0.023537  \n",
       "23       0.023537  \n",
       "24       0.023537  \n",
       "25       0.023537  \n",
       "26       0.023537  \n",
       "27       0.023537  \n",
       "28       0.023537  \n",
       "29       0.023537  \n",
       "...           ...  \n",
       "156362   0.023537  \n",
       "156363   0.023537  \n",
       "156364   0.023537  \n",
       "156365   0.023537  \n",
       "156366   0.023537  \n",
       "156367   0.023537  \n",
       "156368   0.023537  \n",
       "156369   0.023537  \n",
       "156370   0.023537  \n",
       "156371   0.023537  \n",
       "156372   0.023537  \n",
       "156373   0.023537  \n",
       "156374   0.023537  \n",
       "156375   0.023537  \n",
       "156376   0.023537  \n",
       "156377   0.023537  \n",
       "156378   0.023537  \n",
       "156379   0.023537  \n",
       "156380   0.023537  \n",
       "156381   0.023537  \n",
       "156382   0.023537  \n",
       "156383   0.023537  \n",
       "156384   0.023537  \n",
       "156385   0.023537  \n",
       "156386   0.023537  \n",
       "156387   0.023537  \n",
       "156388   0.023537  \n",
       "156389   0.023537  \n",
       "156390   0.023537  \n",
       "156391   0.023537  \n",
       "\n",
       "[156392 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train = y_pred_train.reshape(156392,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train }\n",
    "y_compare_train = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train['Mean Squared Error'] = (np.diff(y_compare_train.values) ** 2)\n",
    "y_compare_train['Mean Squared Error'] = np.mean(y_compare_train['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train['Root Mean Squared Error'] = y_compare_train['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_train['Mean Abs. Error'] = np.mean(abs(y_compare_train['Actual Values(Training)'] - y_compare_train['Predicted Values(Training)']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_train['R_Squared'] = r2_score(y_train, y_pred_train)\n",
    "\n",
    "y_compare_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156392/156392 [==============================] - 36s 230us/step - loss: 1.0263\n",
      "Epoch 2/100\n",
      "156392/156392 [==============================] - 35s 221us/step - loss: 1.02460s - loss: 1. - ETA: 0s - \n",
      "Epoch 3/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0248\n",
      "Epoch 4/100\n",
      "156392/156392 [==============================] - 34s 218us/step - loss: 1.0236\n",
      "Epoch 5/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0237\n",
      "Epoch 6/100\n",
      "156392/156392 [==============================] - 34s 218us/step - loss: 1.0229\n",
      "Epoch 7/100\n",
      "156392/156392 [==============================] - 34s 218us/step - loss: 1.0262\n",
      "Epoch 8/100\n",
      "156392/156392 [==============================] - 34s 216us/step - loss: 1.0240\n",
      "Epoch 9/100\n",
      "156392/156392 [==============================] - 34s 216us/step - loss: 1.0255\n",
      "Epoch 10/100\n",
      "156392/156392 [==============================] - 34s 216us/step - loss: 1.0241 ETA: \n",
      "Epoch 11/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0246\n",
      "Epoch 12/100\n",
      "156392/156392 [==============================] - 35s 221us/step - loss: 1.0262\n",
      "Epoch 13/100\n",
      "156392/156392 [==============================] - 33s 214us/step - loss: 1.0246\n",
      "Epoch 14/100\n",
      "156392/156392 [==============================] - 36s 228us/step - loss: 1.02540s - loss: 1.0\n",
      "Epoch 15/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.0241\n",
      "Epoch 16/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0252\n",
      "Epoch 17/100\n",
      "156392/156392 [==============================] - 34s 220us/step - loss: 1.0238\n",
      "Epoch 18/100\n",
      "156392/156392 [==============================] - 36s 230us/step - loss: 1.02433s - loss - ET -\n",
      "Epoch 19/100\n",
      "156392/156392 [==============================] - 35s 225us/step - loss: 1.02410s - loss: \n",
      "Epoch 20/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.02370s - loss: 1\n",
      "Epoch 21/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0225\n",
      "Epoch 22/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.0225\n",
      "Epoch 23/100\n",
      "156392/156392 [==============================] - 35s 221us/step - loss: 1.0228\n",
      "Epoch 24/100\n",
      "156392/156392 [==============================] - 34s 218us/step - loss: 1.02640s - loss:\n",
      "Epoch 25/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0255\n",
      "Epoch 26/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.0245\n",
      "Epoch 27/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0258\n",
      "Epoch 28/100\n",
      "156392/156392 [==============================] - 34s 216us/step - loss: 1.02630s - loss: 1.\n",
      "Epoch 29/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0266\n",
      "Epoch 30/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0262\n",
      "Epoch 31/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0266\n",
      "Epoch 32/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0257\n",
      "Epoch 33/100\n",
      "156392/156392 [==============================] - 35s 226us/step - loss: 1.0276\n",
      "Epoch 34/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.0272\n",
      "Epoch 35/100\n",
      "156392/156392 [==============================] - 37s 234us/step - loss: 1.0261\n",
      "Epoch 36/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0256\n",
      "Epoch 37/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0281\n",
      "Epoch 38/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0276\n",
      "Epoch 39/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0295\n",
      "Epoch 40/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0289\n",
      "Epoch 41/100\n",
      "156392/156392 [==============================] - 36s 228us/step - loss: 1.0284\n",
      "Epoch 42/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.02790s - loss: 1.0\n",
      "Epoch 43/100\n",
      "156392/156392 [==============================] - 34s 218us/step - loss: 1.0277 0\n",
      "Epoch 44/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0293\n",
      "Epoch 45/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0276\n",
      "Epoch 46/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.0286\n",
      "Epoch 47/100\n",
      "156392/156392 [==============================] - 34s 220us/step - loss: 1.0278\n",
      "Epoch 48/100\n",
      "156392/156392 [==============================] - 35s 222us/step - loss: 1.0269\n",
      "Epoch 49/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0254\n",
      "Epoch 50/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.02670s - los\n",
      "Epoch 51/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.0289\n",
      "Epoch 52/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0268\n",
      "Epoch 53/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.02670s - loss: 1.026\n",
      "Epoch 54/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0258\n",
      "Epoch 55/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0259\n",
      "Epoch 56/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0259\n",
      "Epoch 57/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.0247\n",
      "Epoch 58/100\n",
      "156392/156392 [==============================] - 33s 214us/step - loss: 1.02540s - \n",
      "Epoch 59/100\n",
      "156392/156392 [==============================] - 34s 217us/step - loss: 1.0268\n",
      "Epoch 60/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.02632s - loss: 1.0 - ETA: - ETA: - ETA: 0s - loss: 1 - ETA: 0s - loss: 1.0 - ETA: 0s - loss: 1\n",
      "Epoch 61/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0252\n",
      "Epoch 62/100\n",
      "156392/156392 [==============================] - 34s 215us/step - loss: 1.0263\n",
      "Epoch 63/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.0257\n",
      "Epoch 64/100\n",
      "156392/156392 [==============================] - 34s 216us/step - loss: 1.0256\n",
      "Epoch 65/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0254\n",
      "Epoch 66/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.0255- ETA: 0s - lo\n",
      "Epoch 67/100\n",
      "156392/156392 [==============================] - 33s 213us/step - loss: 1.0252\n",
      "Epoch 68/100\n",
      "156392/156392 [==============================] - 32s 208us/step - loss: 1.0253\n",
      "Epoch 69/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.02553s -  - ETA: 2s - loss: 0.\n",
      "Epoch 70/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0238\n",
      "Epoch 71/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0247\n",
      "Epoch 72/100\n",
      "156392/156392 [==============================] - 35s 223us/step - loss: 1.0230\n",
      "Epoch 73/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0241\n",
      "Epoch 74/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.0242\n",
      "Epoch 75/100\n",
      "156392/156392 [==============================] - 33s 212us/step - loss: 1.0238\n",
      "Epoch 76/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0243\n",
      "Epoch 77/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.0234\n",
      "Epoch 78/100\n",
      "156392/156392 [==============================] - 33s 211us/step - loss: 1.0234\n",
      "Epoch 79/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0228\n",
      "Epoch 80/100\n",
      "156392/156392 [==============================] - 33s 209us/step - loss: 1.0237\n",
      "Epoch 81/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.02390s - loss:  - ETA: 0s - lo - ETA: 0s - loss: 1\n",
      "Epoch 82/100\n",
      "156392/156392 [==============================] - 33s 210us/step - loss: 1.0232\n",
      "Epoch 83/100\n",
      "156392/156392 [==============================] - 34s 219us/step - loss: 1.0240\n",
      "Epoch 84/100\n",
      "156392/156392 [==============================] - 40s 254us/step - loss: 1.0240\n",
      "Epoch 85/100\n",
      "156392/156392 [==============================] - 35s 227us/step - loss: 1.0228\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156392/156392 [==============================] - 34s 220us/step - loss: 1.02222s - loss: 1.0 - ETA: 2s - loss:  \n",
      "Epoch 87/100\n",
      "156392/156392 [==============================] - 35s 227us/step - loss: 1.0231\n",
      "Epoch 88/100\n",
      "156392/156392 [==============================] - 36s 231us/step - loss: 1.0238\n",
      "Epoch 89/100\n",
      "156392/156392 [==============================] - 36s 232us/step - loss: 1.0235A: 9s - lo - ETA: 9s - l - ETA: 8s - loss: 1 - ETA: 8s - loss: 0.994 - ETA: 8s - loss: 0.99 - ETA: 8s - l\n",
      "Epoch 90/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.02228s  - ETA: 8s - E - ET - ETA: 4s - loss: 1.06 - ETA: 4s - lo - ETA: \n",
      "Epoch 91/100\n",
      "156392/156392 [==============================] - 36s 229us/step - loss: 1.0240A: 7s - loss: 1.09 - ET\n",
      "Epoch 92/100\n",
      "156392/156392 [==============================] - 36s 229us/step - loss: 1.0228\n",
      "Epoch 93/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0232\n",
      "Epoch 94/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.02295s - -  - ET - ETA: 0s - loss\n",
      "Epoch 95/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.02310s - loss\n",
      "Epoch 96/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0230\n",
      "Epoch 97/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.0229\n",
      "Epoch 98/100\n",
      "156392/156392 [==============================] - 35s 227us/step - loss: 1.02241s - l - ETA: 1s - loss: 1.0 - E\n",
      "Epoch 99/100\n",
      "156392/156392 [==============================] - 36s 229us/step - loss: 1.02243s - loss: - ETA: 1s - loss: 1.017 -  - ETA: 0s - loss: 1.0 - ETA: 0s - loss: 1.0 - ETA: 0s - loss: 1.02\n",
      "Epoch 100/100\n",
      "156392/156392 [==============================] - 35s 226us/step - loss: 1.0220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141492eb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with 2 layers of 4 nodes \"\"\"\n",
    "\n",
    "regressor_1 = Sequential()\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal',activation = 'relu',input_dim = 8))\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_1.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_1.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Abs. Error</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>0.057887</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.032077</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051497</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.043771</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.061395</td>\n",
       "      <td>-0.050927</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.026445</td>\n",
       "      <td>0.122591</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.497499</td>\n",
       "      <td>-0.009599</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.090490</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.040142</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.049244</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.052314</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.379656</td>\n",
       "      <td>-0.051022</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.050631</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.053521</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.051811</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.035768</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.043266</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.028425</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.080863</td>\n",
       "      <td>-0.045650</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.235816</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.112014</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.058271</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.050589</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.077574</td>\n",
       "      <td>-0.053120</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39069</th>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.041543</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39070</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.047569</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39071</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.035695</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39072</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39073</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.050297</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39074</th>\n",
       "      <td>0.011187</td>\n",
       "      <td>0.640189</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39075</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>0.045435</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39076</th>\n",
       "      <td>-0.162813</td>\n",
       "      <td>-0.048005</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39077</th>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.157102</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39078</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39079</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.049491</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39080</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.052446</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39081</th>\n",
       "      <td>-0.061395</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39082</th>\n",
       "      <td>0.068953</td>\n",
       "      <td>-0.044914</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39083</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.046637</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39084</th>\n",
       "      <td>-0.184994</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39085</th>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.036205</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39086</th>\n",
       "      <td>0.122851</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39087</th>\n",
       "      <td>-0.040846</td>\n",
       "      <td>-0.052680</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39088</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.084915</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39089</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39090</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-0.047777</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39091</th>\n",
       "      <td>-0.003969</td>\n",
       "      <td>-0.050229</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39092</th>\n",
       "      <td>0.017207</td>\n",
       "      <td>-0.002370</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39093</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.051811</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39094</th>\n",
       "      <td>0.313097</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39095</th>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.043418</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39097</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.036589</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39098</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.796335</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39099 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.027183          0.057887            0.796335   \n",
       "1          -0.032077         -0.053901            0.796335   \n",
       "2          -0.031418         -0.053901            0.796335   \n",
       "3          -0.051497         -0.053901            0.796335   \n",
       "4          -0.029573         -0.043771            0.796335   \n",
       "5          -0.061395         -0.050927            0.796335   \n",
       "6          -0.026445          0.122591            0.796335   \n",
       "7           0.497499         -0.009599            0.796335   \n",
       "8          -0.090490         -0.053901            0.796335   \n",
       "9          -0.031418         -0.040142            0.796335   \n",
       "10         -0.033595         -0.049244            0.796335   \n",
       "11         -0.033817         -0.052314            0.796335   \n",
       "12         -0.379656         -0.051022            0.796335   \n",
       "13         -0.026282         -0.050631            0.796335   \n",
       "14         -0.033817         -0.053521            0.796335   \n",
       "15         -0.029573         -0.051811            0.796335   \n",
       "16         -0.033595         -0.053901            0.796335   \n",
       "17         -0.035768         -0.053901            0.796335   \n",
       "18         -0.033595         -0.053901            0.796335   \n",
       "19         -0.031418         -0.053901            0.796335   \n",
       "20         -0.026282         -0.043266            0.796335   \n",
       "21         -0.028425         -0.053901            0.796335   \n",
       "22         -0.080863         -0.045650            0.796335   \n",
       "23         -0.026317          0.235816            0.796335   \n",
       "24         -0.112014         -0.053901            0.796335   \n",
       "25         -0.029573         -0.053901            0.796335   \n",
       "26         -0.058271         -0.053901            0.796335   \n",
       "27         -0.033595         -0.050589            0.796335   \n",
       "28         -0.026282         -0.053901            0.796335   \n",
       "29         -0.077574         -0.053120            0.796335   \n",
       "...              ...               ...                 ...   \n",
       "39069       0.187202         -0.041543            0.796335   \n",
       "39070      -0.031418         -0.047569            0.796335   \n",
       "39071      -0.033595         -0.035695            0.796335   \n",
       "39072      -0.026282         -0.053901            0.796335   \n",
       "39073      -0.078543         -0.050297            0.796335   \n",
       "39074       0.011187          0.640189            0.796335   \n",
       "39075      -0.090653          0.045435            0.796335   \n",
       "39076      -0.162813         -0.048005            0.796335   \n",
       "39077       0.323026          0.157102            0.796335   \n",
       "39078      -0.031418         -0.053901            0.796335   \n",
       "39079      -0.188500         -0.049491            0.796335   \n",
       "39080      -0.188500         -0.052446            0.796335   \n",
       "39081      -0.061395         -0.053901            0.796335   \n",
       "39082       0.068953         -0.044914            0.796335   \n",
       "39083      -0.026282         -0.046637            0.796335   \n",
       "39084      -0.184994         -0.053901            0.796335   \n",
       "39085      -0.008194         -0.036205            0.796335   \n",
       "39086       0.122851         -0.053901            0.796335   \n",
       "39087      -0.040846         -0.052680            0.796335   \n",
       "39088      -0.026282         -0.084915            0.796335   \n",
       "39089      -0.078543         -0.053901            0.796335   \n",
       "39090      -0.027183         -0.047777            0.796335   \n",
       "39091      -0.003969         -0.050229            0.796335   \n",
       "39092       0.017207         -0.002370            0.796335   \n",
       "39093      -0.033595         -0.051811            0.796335   \n",
       "39094       0.313097         -0.031639            0.796335   \n",
       "39095      -0.057291         -0.053901            0.796335   \n",
       "39096      -0.031418         -0.043418            0.796335   \n",
       "39097      -0.188500         -0.036589            0.796335   \n",
       "39098      -0.033817         -0.053901            0.796335   \n",
       "\n",
       "       Root Mean Squared Error  Mean Abs. Error  R_Squared  \n",
       "0                     0.892376         0.105453   0.019711  \n",
       "1                     0.892376         0.105453   0.019711  \n",
       "2                     0.892376         0.105453   0.019711  \n",
       "3                     0.892376         0.105453   0.019711  \n",
       "4                     0.892376         0.105453   0.019711  \n",
       "5                     0.892376         0.105453   0.019711  \n",
       "6                     0.892376         0.105453   0.019711  \n",
       "7                     0.892376         0.105453   0.019711  \n",
       "8                     0.892376         0.105453   0.019711  \n",
       "9                     0.892376         0.105453   0.019711  \n",
       "10                    0.892376         0.105453   0.019711  \n",
       "11                    0.892376         0.105453   0.019711  \n",
       "12                    0.892376         0.105453   0.019711  \n",
       "13                    0.892376         0.105453   0.019711  \n",
       "14                    0.892376         0.105453   0.019711  \n",
       "15                    0.892376         0.105453   0.019711  \n",
       "16                    0.892376         0.105453   0.019711  \n",
       "17                    0.892376         0.105453   0.019711  \n",
       "18                    0.892376         0.105453   0.019711  \n",
       "19                    0.892376         0.105453   0.019711  \n",
       "20                    0.892376         0.105453   0.019711  \n",
       "21                    0.892376         0.105453   0.019711  \n",
       "22                    0.892376         0.105453   0.019711  \n",
       "23                    0.892376         0.105453   0.019711  \n",
       "24                    0.892376         0.105453   0.019711  \n",
       "25                    0.892376         0.105453   0.019711  \n",
       "26                    0.892376         0.105453   0.019711  \n",
       "27                    0.892376         0.105453   0.019711  \n",
       "28                    0.892376         0.105453   0.019711  \n",
       "29                    0.892376         0.105453   0.019711  \n",
       "...                        ...              ...        ...  \n",
       "39069                 0.892376         0.105453   0.019711  \n",
       "39070                 0.892376         0.105453   0.019711  \n",
       "39071                 0.892376         0.105453   0.019711  \n",
       "39072                 0.892376         0.105453   0.019711  \n",
       "39073                 0.892376         0.105453   0.019711  \n",
       "39074                 0.892376         0.105453   0.019711  \n",
       "39075                 0.892376         0.105453   0.019711  \n",
       "39076                 0.892376         0.105453   0.019711  \n",
       "39077                 0.892376         0.105453   0.019711  \n",
       "39078                 0.892376         0.105453   0.019711  \n",
       "39079                 0.892376         0.105453   0.019711  \n",
       "39080                 0.892376         0.105453   0.019711  \n",
       "39081                 0.892376         0.105453   0.019711  \n",
       "39082                 0.892376         0.105453   0.019711  \n",
       "39083                 0.892376         0.105453   0.019711  \n",
       "39084                 0.892376         0.105453   0.019711  \n",
       "39085                 0.892376         0.105453   0.019711  \n",
       "39086                 0.892376         0.105453   0.019711  \n",
       "39087                 0.892376         0.105453   0.019711  \n",
       "39088                 0.892376         0.105453   0.019711  \n",
       "39089                 0.892376         0.105453   0.019711  \n",
       "39090                 0.892376         0.105453   0.019711  \n",
       "39091                 0.892376         0.105453   0.019711  \n",
       "39092                 0.892376         0.105453   0.019711  \n",
       "39093                 0.892376         0.105453   0.019711  \n",
       "39094                 0.892376         0.105453   0.019711  \n",
       "39095                 0.892376         0.105453   0.019711  \n",
       "39096                 0.892376         0.105453   0.019711  \n",
       "39097                 0.892376         0.105453   0.019711  \n",
       "39098                 0.892376         0.105453   0.019711  \n",
       "\n",
       "[39099 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_1 = regressor_1.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_1 = y_pred_1.reshape(39099,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_1}\n",
    "y_compare_1 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_1['Mean Squared Error'] = (np.diff(y_compare_1.values) ** 2)\n",
    "y_compare_1['Mean Squared Error'] = np.mean(y_compare_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_1['Root Mean Squared Error'] = y_compare_1['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_1['Mean Abs. Error'] = np.mean(abs(y_compare_1['Actual Values'] - y_compare_1['Predicted Values']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_1['R_Squared'] = r2_score(y_test, y_pred_1)\n",
    "\n",
    "y_compare_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Abs. Error</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.084480</td>\n",
       "      <td>-0.049161</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.072782</td>\n",
       "      <td>0.587157</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112014</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059294</td>\n",
       "      <td>-0.046305</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.046479</td>\n",
       "      <td>-0.049931</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009217</td>\n",
       "      <td>-0.038858</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.048977</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>-0.042259</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.072782</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.052019</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.068953</td>\n",
       "      <td>0.069934</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.067829</td>\n",
       "      <td>-0.042605</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006270</td>\n",
       "      <td>-0.041082</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.053885</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.064184</td>\n",
       "      <td>0.249206</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.049730</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>0.029896</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.047691</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.080906</td>\n",
       "      <td>-0.034134</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.099322</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.039399</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.036384</td>\n",
       "      <td>0.526901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.067829</td>\n",
       "      <td>-0.051697</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.045703</td>\n",
       "      <td>0.154518</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.066602</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156362</th>\n",
       "      <td>-0.040846</td>\n",
       "      <td>-0.053510</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156363</th>\n",
       "      <td>-0.016099</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156364</th>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156365</th>\n",
       "      <td>-0.143639</td>\n",
       "      <td>0.070918</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156366</th>\n",
       "      <td>-0.035768</td>\n",
       "      <td>-0.027152</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156367</th>\n",
       "      <td>-0.028425</td>\n",
       "      <td>-0.052165</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156368</th>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.049287</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156369</th>\n",
       "      <td>-0.162813</td>\n",
       "      <td>0.229042</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156370</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156371</th>\n",
       "      <td>0.202220</td>\n",
       "      <td>-0.048028</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156372</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.044461</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156373</th>\n",
       "      <td>-0.078494</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156374</th>\n",
       "      <td>-0.046517</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156375</th>\n",
       "      <td>-0.051497</td>\n",
       "      <td>-0.041218</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156376</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.039681</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156377</th>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.039284</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156378</th>\n",
       "      <td>-0.184994</td>\n",
       "      <td>-0.051975</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156379</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156380</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.050515</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156381</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.037117</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156382</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156383</th>\n",
       "      <td>-0.379656</td>\n",
       "      <td>0.087185</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156384</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>-0.051211</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156385</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156386</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156387</th>\n",
       "      <td>-0.078494</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156388</th>\n",
       "      <td>-0.080863</td>\n",
       "      <td>-0.046507</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156389</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156390</th>\n",
       "      <td>-0.104989</td>\n",
       "      <td>0.093458</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156391</th>\n",
       "      <td>-0.000773</td>\n",
       "      <td>-0.053684</td>\n",
       "      <td>1.024425</td>\n",
       "      <td>1.012139</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156392 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                     -0.084480                   -0.049161   \n",
       "1                     -0.072782                    0.587157   \n",
       "2                     -0.112014                   -0.053901   \n",
       "3                     -0.059294                   -0.046305   \n",
       "4                     -0.046479                   -0.049931   \n",
       "5                      0.009217                   -0.038858   \n",
       "6                     -0.008194                   -0.048977   \n",
       "7                     -0.027183                   -0.053901   \n",
       "8                     -0.033595                   -0.053901   \n",
       "9                     -0.090653                   -0.042259   \n",
       "10                    -0.072782                   -0.053901   \n",
       "11                    -0.048927                   -0.052019   \n",
       "12                     0.068953                    0.069934   \n",
       "13                    -0.067829                   -0.042605   \n",
       "14                     0.006270                   -0.041082   \n",
       "15                    -0.026282                   -0.053885   \n",
       "16                    -0.091704                   -0.053901   \n",
       "17                    -0.050341                   -0.053901   \n",
       "18                     0.064184                    0.249206   \n",
       "19                    -0.029573                   -0.049730   \n",
       "20                    -0.033817                    0.029896   \n",
       "21                    -0.033817                   -0.047691   \n",
       "22                    -0.080906                   -0.034134   \n",
       "23                    -0.099322                   -0.053901   \n",
       "24                    -0.078543                   -0.039399   \n",
       "25                    -0.036384                    0.526901   \n",
       "26                    -0.067829                   -0.051697   \n",
       "27                    -0.091704                   -0.053901   \n",
       "28                    -0.045703                    0.154518   \n",
       "29                    -0.066602                   -0.053901   \n",
       "...                         ...                         ...   \n",
       "156362                -0.040846                   -0.053510   \n",
       "156363                -0.016099                   -0.053901   \n",
       "156364                -0.050341                   -0.053901   \n",
       "156365                -0.143639                    0.070918   \n",
       "156366                -0.035768                   -0.027152   \n",
       "156367                -0.028425                   -0.052165   \n",
       "156368                 0.187202                   -0.049287   \n",
       "156369                -0.162813                    0.229042   \n",
       "156370                -0.026282                   -0.053901   \n",
       "156371                 0.202220                   -0.048028   \n",
       "156372                -0.033595                   -0.044461   \n",
       "156373                -0.078494                   -0.053901   \n",
       "156374                -0.046517                   -0.053901   \n",
       "156375                -0.051497                   -0.041218   \n",
       "156376                -0.026282                   -0.039681   \n",
       "156377                -0.048927                   -0.039284   \n",
       "156378                -0.184994                   -0.051975   \n",
       "156379                 0.001314                   -0.053901   \n",
       "156380                -0.033595                   -0.050515   \n",
       "156381                -0.188500                   -0.037117   \n",
       "156382                -0.031418                   -0.053901   \n",
       "156383                -0.379656                    0.087185   \n",
       "156384                -0.090653                   -0.051211   \n",
       "156385                -0.033595                   -0.053901   \n",
       "156386                -0.033595                   -0.053901   \n",
       "156387                -0.078494                   -0.053901   \n",
       "156388                -0.080863                   -0.046507   \n",
       "156389                -0.033595                   -0.053901   \n",
       "156390                -0.104989                    0.093458   \n",
       "156391                -0.000773                   -0.053684   \n",
       "\n",
       "        Mean Squared Error  Root Mean Squared Error  Mean Abs. Error  \\\n",
       "0                 1.024425                 1.012139         0.111477   \n",
       "1                 1.024425                 1.012139         0.111477   \n",
       "2                 1.024425                 1.012139         0.111477   \n",
       "3                 1.024425                 1.012139         0.111477   \n",
       "4                 1.024425                 1.012139         0.111477   \n",
       "5                 1.024425                 1.012139         0.111477   \n",
       "6                 1.024425                 1.012139         0.111477   \n",
       "7                 1.024425                 1.012139         0.111477   \n",
       "8                 1.024425                 1.012139         0.111477   \n",
       "9                 1.024425                 1.012139         0.111477   \n",
       "10                1.024425                 1.012139         0.111477   \n",
       "11                1.024425                 1.012139         0.111477   \n",
       "12                1.024425                 1.012139         0.111477   \n",
       "13                1.024425                 1.012139         0.111477   \n",
       "14                1.024425                 1.012139         0.111477   \n",
       "15                1.024425                 1.012139         0.111477   \n",
       "16                1.024425                 1.012139         0.111477   \n",
       "17                1.024425                 1.012139         0.111477   \n",
       "18                1.024425                 1.012139         0.111477   \n",
       "19                1.024425                 1.012139         0.111477   \n",
       "20                1.024425                 1.012139         0.111477   \n",
       "21                1.024425                 1.012139         0.111477   \n",
       "22                1.024425                 1.012139         0.111477   \n",
       "23                1.024425                 1.012139         0.111477   \n",
       "24                1.024425                 1.012139         0.111477   \n",
       "25                1.024425                 1.012139         0.111477   \n",
       "26                1.024425                 1.012139         0.111477   \n",
       "27                1.024425                 1.012139         0.111477   \n",
       "28                1.024425                 1.012139         0.111477   \n",
       "29                1.024425                 1.012139         0.111477   \n",
       "...                    ...                      ...              ...   \n",
       "156362            1.024425                 1.012139         0.111477   \n",
       "156363            1.024425                 1.012139         0.111477   \n",
       "156364            1.024425                 1.012139         0.111477   \n",
       "156365            1.024425                 1.012139         0.111477   \n",
       "156366            1.024425                 1.012139         0.111477   \n",
       "156367            1.024425                 1.012139         0.111477   \n",
       "156368            1.024425                 1.012139         0.111477   \n",
       "156369            1.024425                 1.012139         0.111477   \n",
       "156370            1.024425                 1.012139         0.111477   \n",
       "156371            1.024425                 1.012139         0.111477   \n",
       "156372            1.024425                 1.012139         0.111477   \n",
       "156373            1.024425                 1.012139         0.111477   \n",
       "156374            1.024425                 1.012139         0.111477   \n",
       "156375            1.024425                 1.012139         0.111477   \n",
       "156376            1.024425                 1.012139         0.111477   \n",
       "156377            1.024425                 1.012139         0.111477   \n",
       "156378            1.024425                 1.012139         0.111477   \n",
       "156379            1.024425                 1.012139         0.111477   \n",
       "156380            1.024425                 1.012139         0.111477   \n",
       "156381            1.024425                 1.012139         0.111477   \n",
       "156382            1.024425                 1.012139         0.111477   \n",
       "156383            1.024425                 1.012139         0.111477   \n",
       "156384            1.024425                 1.012139         0.111477   \n",
       "156385            1.024425                 1.012139         0.111477   \n",
       "156386            1.024425                 1.012139         0.111477   \n",
       "156387            1.024425                 1.012139         0.111477   \n",
       "156388            1.024425                 1.012139         0.111477   \n",
       "156389            1.024425                 1.012139         0.111477   \n",
       "156390            1.024425                 1.012139         0.111477   \n",
       "156391            1.024425                 1.012139         0.111477   \n",
       "\n",
       "        R_Squared  \n",
       "0        0.021474  \n",
       "1        0.021474  \n",
       "2        0.021474  \n",
       "3        0.021474  \n",
       "4        0.021474  \n",
       "5        0.021474  \n",
       "6        0.021474  \n",
       "7        0.021474  \n",
       "8        0.021474  \n",
       "9        0.021474  \n",
       "10       0.021474  \n",
       "11       0.021474  \n",
       "12       0.021474  \n",
       "13       0.021474  \n",
       "14       0.021474  \n",
       "15       0.021474  \n",
       "16       0.021474  \n",
       "17       0.021474  \n",
       "18       0.021474  \n",
       "19       0.021474  \n",
       "20       0.021474  \n",
       "21       0.021474  \n",
       "22       0.021474  \n",
       "23       0.021474  \n",
       "24       0.021474  \n",
       "25       0.021474  \n",
       "26       0.021474  \n",
       "27       0.021474  \n",
       "28       0.021474  \n",
       "29       0.021474  \n",
       "...           ...  \n",
       "156362   0.021474  \n",
       "156363   0.021474  \n",
       "156364   0.021474  \n",
       "156365   0.021474  \n",
       "156366   0.021474  \n",
       "156367   0.021474  \n",
       "156368   0.021474  \n",
       "156369   0.021474  \n",
       "156370   0.021474  \n",
       "156371   0.021474  \n",
       "156372   0.021474  \n",
       "156373   0.021474  \n",
       "156374   0.021474  \n",
       "156375   0.021474  \n",
       "156376   0.021474  \n",
       "156377   0.021474  \n",
       "156378   0.021474  \n",
       "156379   0.021474  \n",
       "156380   0.021474  \n",
       "156381   0.021474  \n",
       "156382   0.021474  \n",
       "156383   0.021474  \n",
       "156384   0.021474  \n",
       "156385   0.021474  \n",
       "156386   0.021474  \n",
       "156387   0.021474  \n",
       "156388   0.021474  \n",
       "156389   0.021474  \n",
       "156390   0.021474  \n",
       "156391   0.021474  \n",
       "\n",
       "[156392 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_1 = regressor_1.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_1 = y_pred_train_1.reshape(156392,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_1 }\n",
    "y_compare_train_1 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_1['Mean Squared Error'] = (np.diff(y_compare_train_1.values) ** 2)\n",
    "y_compare_train_1['Mean Squared Error'] = np.mean(y_compare_train_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_1['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_train_1['Mean Abs. Error'] = np.mean(abs(y_compare_train_1['Actual Values(Training)'] - y_compare_train_1['Predicted Values(Training)']))\n",
    "\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_train_1['R_Squared'] = r2_score(y_train, y_pred_train_1)\n",
    "\n",
    "y_compare_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nNow, we will train an ANN with a very high number of nodes. And comparitively more layers.\\n\\n8-50-100-200-100-50-20-1\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now, we will train an ANN with a very high number of nodes. And comparitively more layers.\n",
    "\n",
    "8-50-100-200-100-50-20-1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156392/156392 [==============================] - 56s 360us/step - loss: 1.0353\n",
      "Epoch 2/100\n",
      "156392/156392 [==============================] - 55s 355us/step - loss: 1.03274s - loss: 1.029 - ETA: 4s - loss: 1 - - ETA: 1s - loss: 1 - ETA: 1s - l - ETA: 0s \n",
      "Epoch 3/100\n",
      "156392/156392 [==============================] - 55s 354us/step - loss: 1.0327\n",
      "Epoch 4/100\n",
      "156392/156392 [==============================] - 56s 356us/step - loss: 1.0325\n",
      "Epoch 5/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.0316\n",
      "Epoch 6/100\n",
      "156392/156392 [==============================] - 55s 353us/step - loss: 1.0316\n",
      "Epoch 7/100\n",
      "156392/156392 [==============================] - 56s 356us/step - loss: 1.03350s - loss: - ETA: 0s - los\n",
      "Epoch 8/100\n",
      "156392/156392 [==============================] - 57s 362us/step - loss: 1.03231s - - \n",
      "Epoch 9/100\n",
      "156392/156392 [==============================] - 56s 359us/step - loss: 1.0334\n",
      "Epoch 10/100\n",
      "156392/156392 [==============================] - 56s 355us/step - loss: 1.0313\n",
      "Epoch 11/100\n",
      "156392/156392 [==============================] - 55s 350us/step - loss: 1.03279 - ETA: 8s  - ETA: 7s - los - ETA: 6s - l - ETA: 3 - ETA: 1s - loss - ETA: 1s - ETA: 0s \n",
      "Epoch 12/100\n",
      "156392/156392 [==============================] - 56s 356us/step - loss: 1.0318\n",
      "Epoch 13/100\n",
      "156392/156392 [==============================] - 55s 351us/step - loss: 1.0305\n",
      "Epoch 14/100\n",
      "156392/156392 [==============================] - 55s 354us/step - loss: 1.03090s - loss: \n",
      "Epoch 15/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.03367s - loss - ETA: 5s -  - ETA: 0s - loss\n",
      "Epoch 16/100\n",
      "156392/156392 [==============================] - 55s 353us/step - loss: 1.04900s - loss\n",
      "Epoch 17/100\n",
      "156392/156392 [==============================] - 55s 349us/step - loss: 1.0325\n",
      "Epoch 18/100\n",
      "156392/156392 [==============================] - 55s 354us/step - loss: 1.0355\n",
      "Epoch 19/100\n",
      "156392/156392 [==============================] - 55s 350us/step - loss: 1.03040s - loss: 0.\n",
      "Epoch 20/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.0319\n",
      "Epoch 21/100\n",
      "156392/156392 [==============================] - 58s 373us/step - loss: 1.0338\n",
      "Epoch 22/100\n",
      "156392/156392 [==============================] - 59s 380us/step - loss: 1.0396\n",
      "Epoch 23/100\n",
      "156392/156392 [==============================] - 60s 386us/step - loss: 1.0476\n",
      "Epoch 24/100\n",
      "156392/156392 [==============================] - 57s 364us/step - loss: 1.03610s - loss: 1. - ETA: 0s - loss:\n",
      "Epoch 25/100\n",
      "156392/156392 [==============================] - 59s 376us/step - loss: 1.0326\n",
      "Epoch 26/100\n",
      "156392/156392 [==============================] - 61s 388us/step - loss: 1.0298\n",
      "Epoch 27/100\n",
      "156392/156392 [==============================] - 58s 369us/step - loss: 1.0319\n",
      "Epoch 28/100\n",
      "156392/156392 [==============================] - 57s 367us/step - loss: 1.0302\n",
      "Epoch 29/100\n",
      "156392/156392 [==============================] - 69s 442us/step - loss: 1.0339\n",
      "Epoch 30/100\n",
      "156392/156392 [==============================] - 70s 448us/step - loss: 1.0341\n",
      "Epoch 31/100\n",
      "156392/156392 [==============================] - 59s 376us/step - loss: 1.0344\n",
      "Epoch 32/100\n",
      "156392/156392 [==============================] - 58s 373us/step - loss: 1.0322\n",
      "Epoch 33/100\n",
      "156392/156392 [==============================] - 57s 362us/step - loss: 1.0354\n",
      "Epoch 34/100\n",
      "156392/156392 [==============================] - 56s 360us/step - loss: 1.0373\n",
      "Epoch 35/100\n",
      "156392/156392 [==============================] - 57s 363us/step - loss: 1.0325\n",
      "Epoch 36/100\n",
      "156392/156392 [==============================] - 56s 359us/step - loss: 1.0341\n",
      "Epoch 37/100\n",
      "156392/156392 [==============================] - 56s 355us/step - loss: 1.03600s - \n",
      "Epoch 38/100\n",
      "156392/156392 [==============================] - 56s 357us/step - loss: 1.03180s - loss: 1\n",
      "Epoch 39/100\n",
      "156392/156392 [==============================] - 57s 364us/step - loss: 1.0342\n",
      "Epoch 40/100\n",
      "156392/156392 [==============================] - 56s 355us/step - loss: 1.0358\n",
      "Epoch 41/100\n",
      "156392/156392 [==============================] - 56s 361us/step - loss: 1.0320\n",
      "Epoch 42/100\n",
      "156392/156392 [==============================] - 57s 362us/step - loss: 1.1067: 0s - loss: 1\n",
      "Epoch 43/100\n",
      "156392/156392 [==============================] - 55s 355us/step - loss: 1.0380\n",
      "Epoch 44/100\n",
      "156392/156392 [==============================] - 57s 362us/step - loss: 1.0343\n",
      "Epoch 45/100\n",
      "156392/156392 [==============================] - 56s 358us/step - loss: 1.03160s - loss: 1.\n",
      "Epoch 46/100\n",
      "156392/156392 [==============================] - 55s 349us/step - loss: 1.0317\n",
      "Epoch 47/100\n",
      "156392/156392 [==============================] - 59s 377us/step - loss: 1.0312\n",
      "Epoch 48/100\n",
      "156392/156392 [==============================] - 61s 390us/step - loss: 1.0351\n",
      "Epoch 49/100\n",
      "156392/156392 [==============================] - 59s 379us/step - loss: 1.03601s - loss:  \n",
      "Epoch 50/100\n",
      "156392/156392 [==============================] - 58s 370us/step - loss: 1.0412\n",
      "Epoch 51/100\n",
      "156392/156392 [==============================] - 58s 369us/step - loss: 1.03411s - loss: 1. - ETA: 1s - ETA:\n",
      "Epoch 52/100\n",
      "156392/156392 [==============================] - 59s 376us/step - loss: 1.03460s -\n",
      "Epoch 53/100\n",
      "156392/156392 [==============================] - 57s 367us/step - loss: 1.0358\n",
      "Epoch 54/100\n",
      "156392/156392 [==============================] - 60s 382us/step - loss: 1.0329\n",
      "Epoch 55/100\n",
      "156392/156392 [==============================] - 57s 364us/step - loss: 1.0337\n",
      "Epoch 56/100\n",
      "156392/156392 [==============================] - 56s 357us/step - loss: 1.0307\n",
      "Epoch 57/100\n",
      "156392/156392 [==============================] - 59s 379us/step - loss: 1.0344\n",
      "Epoch 58/100\n",
      "156392/156392 [==============================] - 56s 355us/step - loss: 1.0318\n",
      "Epoch 59/100\n",
      "156392/156392 [==============================] - 56s 356us/step - loss: 1.03330s - l\n",
      "Epoch 60/100\n",
      "156392/156392 [==============================] - 56s 361us/step - loss: 1.0415\n",
      "Epoch 61/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.03290s - l\n",
      "Epoch 62/100\n",
      "156392/156392 [==============================] - 55s 355us/step - loss: 1.04821s - lo - ETA: 0s - l - ETA: 0s - loss: 1.048\n",
      "Epoch 63/100\n",
      "156392/156392 [==============================] - 56s 358us/step - loss: 1.0320\n",
      "Epoch 64/100\n",
      "156392/156392 [==============================] - 55s 353us/step - loss: 1.03310\n",
      "Epoch 65/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.1974- ETA: 0s - loss: 1.\n",
      "Epoch 66/100\n",
      "156392/156392 [==============================] - 55s 355us/step - loss: 1.0355\n",
      "Epoch 67/100\n",
      "156392/156392 [==============================] - 55s 353us/step - loss: 1.0392- ETA: 1s - lo\n",
      "Epoch 68/100\n",
      "156392/156392 [==============================] - 55s 354us/step - loss: 1.2536TA: 2s - loss: 1 - ETA: 1s - ETA: 0s - loss: - ETA: 0s - loss: 1.2\n",
      "Epoch 69/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.03270s - l - ETA: 0s - loss: 1.0\n",
      "Epoch 70/100\n",
      "156392/156392 [==============================] - 55s 351us/step - loss: 1.0364\n",
      "Epoch 71/100\n",
      "156392/156392 [==============================] - 55s 351us/step - loss: 1.0342\n",
      "Epoch 72/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.03681s - loss -\n",
      "Epoch 73/100\n",
      "156392/156392 [==============================] - 56s 356us/step - loss: 1.0408\n",
      "Epoch 74/100\n",
      "156392/156392 [==============================] - 56s 357us/step - loss: 1.0363\n",
      "Epoch 75/100\n",
      "156392/156392 [==============================] - 56s 359us/step - loss: 1.03730s - l\n",
      "Epoch 76/100\n",
      "156392/156392 [==============================] - 55s 354us/step - loss: 1.0381 - ETA: 0s - los\n",
      "Epoch 77/100\n",
      "156392/156392 [==============================] - 56s 356us/step - loss: 1.03954s - lo - ETA: 3s -  - ETA: 2s -  - \n",
      "Epoch 78/100\n",
      "156392/156392 [==============================] - 55s 352us/step - loss: 1.0346\n",
      "Epoch 79/100\n",
      "156392/156392 [==============================] - 55s 350us/step - loss: 1.03440s - lo - ETA: 0s - loss: 1.\n",
      "Epoch 80/100\n",
      "156392/156392 [==============================] - 54s 347us/step - loss: 1.03300s -  - ETA: 0s - loss: 1\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156392/156392 [==============================] - 54s 345us/step - loss: 1.0412\n",
      "Epoch 82/100\n",
      "156392/156392 [==============================] - 54s 346us/step - loss: 1.0336\n",
      "Epoch 83/100\n",
      "156392/156392 [==============================] - 54s 343us/step - loss: 1.03752\n",
      "Epoch 84/100\n",
      "156392/156392 [==============================] - 55s 349us/step - loss: 109.46151s - l - ETA: 0s  - ETA: 0s - loss: 109.490\n",
      "Epoch 85/100\n",
      "156392/156392 [==============================] - 54s 345us/step - loss: 1.0367\n",
      "Epoch 86/100\n",
      "156392/156392 [==============================] - 54s 348us/step - loss: 1.1149\n",
      "Epoch 87/100\n",
      "156392/156392 [==============================] - 54s 346us/step - loss: 5013.2901s - loss: 5 - - E - ETA: 0s - loss: 5\n",
      "Epoch 88/100\n",
      "156392/156392 [==============================] - 55s 350us/step - loss: 1572.6310\n",
      "Epoch 89/100\n",
      "156392/156392 [==============================] - 55s 349us/step - loss: 1.8803\n",
      "Epoch 90/100\n",
      "156392/156392 [==============================] - 54s 347us/step - loss: 1.8423\n",
      "Epoch 91/100\n",
      "156392/156392 [==============================] - 54s 347us/step - loss: 28283.0719\n",
      "Epoch 92/100\n",
      "156392/156392 [==============================] - 55s 349us/step - loss: 1.0509\n",
      "Epoch 93/100\n",
      "156392/156392 [==============================] - 53s 342us/step - loss: 2512.4352s - loss: - ETA: 0s - loss: 251\n",
      "Epoch 94/100\n",
      "156392/156392 [==============================] - 52s 329us/step - loss: 1.03691s - loss: 1.041 - \n",
      "Epoch 95/100\n",
      "156392/156392 [==============================] - 52s 330us/step - loss: 30485.0384\n",
      "Epoch 96/100\n",
      "156392/156392 [==============================] - 51s 328us/step - loss: 1.04260s - loss: \n",
      "Epoch 97/100\n",
      "156392/156392 [==============================] - 52s 334us/step - loss: 3673.9603\n",
      "Epoch 98/100\n",
      "156392/156392 [==============================] - 51s 329us/step - loss: 9.67111s - l\n",
      "Epoch 99/100\n",
      "156392/156392 [==============================] - 53s 339us/step - loss: 6.02792s - lo - ETA: 0s - loss: 6.\n",
      "Epoch 100/100\n",
      "156392/156392 [==============================] - 52s 335us/step - loss: 10.5828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d844dd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a deep and wide ANN with high number of nodes \"\"\"\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "regressor_2 = Sequential()\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal',input_dim = 8))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(200, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(20, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_2.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Abs. Error</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.032077</td>\n",
       "      <td>-0.039979</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051497</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.061395</td>\n",
       "      <td>-0.042341</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.026445</td>\n",
       "      <td>0.150429</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.497499</td>\n",
       "      <td>-0.011793</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.090490</td>\n",
       "      <td>-0.037701</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.028487</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.029713</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.379656</td>\n",
       "      <td>-0.047592</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.033119</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.042734</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.044929</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.058720</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.035768</td>\n",
       "      <td>-0.056559</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.036901</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.027188</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.005460</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.028425</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.080863</td>\n",
       "      <td>-0.018531</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.072107</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.112014</td>\n",
       "      <td>-0.061591</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.044972</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.058271</td>\n",
       "      <td>-0.038551</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.027050</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.039430</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.077574</td>\n",
       "      <td>-0.044830</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39069</th>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.042673</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39070</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39071</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.012402</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39072</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.028317</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39073</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39074</th>\n",
       "      <td>0.011187</td>\n",
       "      <td>0.249390</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39075</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>-0.013311</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39076</th>\n",
       "      <td>-0.162813</td>\n",
       "      <td>-0.027400</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39077</th>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.163407</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39078</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.035767</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39079</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.038483</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39080</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.032829</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39081</th>\n",
       "      <td>-0.061395</td>\n",
       "      <td>-0.044032</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39082</th>\n",
       "      <td>0.068953</td>\n",
       "      <td>-0.030179</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39083</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.017358</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39084</th>\n",
       "      <td>-0.184994</td>\n",
       "      <td>-0.053894</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39085</th>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.008870</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39086</th>\n",
       "      <td>0.122851</td>\n",
       "      <td>-0.044454</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39087</th>\n",
       "      <td>-0.040846</td>\n",
       "      <td>-0.028483</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39088</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.050635</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39089</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>-0.043716</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39090</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-0.024862</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39091</th>\n",
       "      <td>-0.003969</td>\n",
       "      <td>-0.022213</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39092</th>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.110095</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39093</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.036529</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39094</th>\n",
       "      <td>0.313097</td>\n",
       "      <td>0.062769</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39095</th>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.050184</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.035188</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39097</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>-0.024640</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39098</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.036786</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39099 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.027183         -0.002557            0.801785   \n",
       "1          -0.032077         -0.039979            0.801785   \n",
       "2          -0.031418         -0.046875            0.801785   \n",
       "3          -0.051497         -0.041220            0.801785   \n",
       "4          -0.029573         -0.005757            0.801785   \n",
       "5          -0.061395         -0.042341            0.801785   \n",
       "6          -0.026445          0.150429            0.801785   \n",
       "7           0.497499         -0.011793            0.801785   \n",
       "8          -0.090490         -0.037701            0.801785   \n",
       "9          -0.031418          0.021603            0.801785   \n",
       "10         -0.033595         -0.028487            0.801785   \n",
       "11         -0.033817         -0.029713            0.801785   \n",
       "12         -0.379656         -0.047592            0.801785   \n",
       "13         -0.026282         -0.033119            0.801785   \n",
       "14         -0.033817         -0.042734            0.801785   \n",
       "15         -0.029573         -0.044929            0.801785   \n",
       "16         -0.033595         -0.058720            0.801785   \n",
       "17         -0.035768         -0.056559            0.801785   \n",
       "18         -0.033595         -0.036901            0.801785   \n",
       "19         -0.031418         -0.027188            0.801785   \n",
       "20         -0.026282         -0.005460            0.801785   \n",
       "21         -0.028425         -0.018437            0.801785   \n",
       "22         -0.080863         -0.018531            0.801785   \n",
       "23         -0.026317          0.072107            0.801785   \n",
       "24         -0.112014         -0.061591            0.801785   \n",
       "25         -0.029573         -0.044972            0.801785   \n",
       "26         -0.058271         -0.038551            0.801785   \n",
       "27         -0.033595         -0.027050            0.801785   \n",
       "28         -0.026282         -0.039430            0.801785   \n",
       "29         -0.077574         -0.044830            0.801785   \n",
       "...              ...               ...                 ...   \n",
       "39069       0.187202         -0.042673            0.801785   \n",
       "39070      -0.031418         -0.037858            0.801785   \n",
       "39071      -0.033595         -0.012402            0.801785   \n",
       "39072      -0.026282         -0.028317            0.801785   \n",
       "39073      -0.078543         -0.024012            0.801785   \n",
       "39074       0.011187          0.249390            0.801785   \n",
       "39075      -0.090653         -0.013311            0.801785   \n",
       "39076      -0.162813         -0.027400            0.801785   \n",
       "39077       0.323026          0.163407            0.801785   \n",
       "39078      -0.031418         -0.035767            0.801785   \n",
       "39079      -0.188500         -0.038483            0.801785   \n",
       "39080      -0.188500         -0.032829            0.801785   \n",
       "39081      -0.061395         -0.044032            0.801785   \n",
       "39082       0.068953         -0.030179            0.801785   \n",
       "39083      -0.026282         -0.017358            0.801785   \n",
       "39084      -0.184994         -0.053894            0.801785   \n",
       "39085      -0.008194         -0.008870            0.801785   \n",
       "39086       0.122851         -0.044454            0.801785   \n",
       "39087      -0.040846         -0.028483            0.801785   \n",
       "39088      -0.026282         -0.050635            0.801785   \n",
       "39089      -0.078543         -0.043716            0.801785   \n",
       "39090      -0.027183         -0.024862            0.801785   \n",
       "39091      -0.003969         -0.022213            0.801785   \n",
       "39092       0.017207          0.110095            0.801785   \n",
       "39093      -0.033595         -0.036529            0.801785   \n",
       "39094       0.313097          0.062769            0.801785   \n",
       "39095      -0.057291         -0.050184            0.801785   \n",
       "39096      -0.031418         -0.035188            0.801785   \n",
       "39097      -0.188500         -0.024640            0.801785   \n",
       "39098      -0.033817         -0.036786            0.801785   \n",
       "\n",
       "       Root Mean Squared Error  Mean Abs. Error  R_Squared  \n",
       "0                     0.895425         0.098569   0.013002  \n",
       "1                     0.895425         0.098569   0.013002  \n",
       "2                     0.895425         0.098569   0.013002  \n",
       "3                     0.895425         0.098569   0.013002  \n",
       "4                     0.895425         0.098569   0.013002  \n",
       "5                     0.895425         0.098569   0.013002  \n",
       "6                     0.895425         0.098569   0.013002  \n",
       "7                     0.895425         0.098569   0.013002  \n",
       "8                     0.895425         0.098569   0.013002  \n",
       "9                     0.895425         0.098569   0.013002  \n",
       "10                    0.895425         0.098569   0.013002  \n",
       "11                    0.895425         0.098569   0.013002  \n",
       "12                    0.895425         0.098569   0.013002  \n",
       "13                    0.895425         0.098569   0.013002  \n",
       "14                    0.895425         0.098569   0.013002  \n",
       "15                    0.895425         0.098569   0.013002  \n",
       "16                    0.895425         0.098569   0.013002  \n",
       "17                    0.895425         0.098569   0.013002  \n",
       "18                    0.895425         0.098569   0.013002  \n",
       "19                    0.895425         0.098569   0.013002  \n",
       "20                    0.895425         0.098569   0.013002  \n",
       "21                    0.895425         0.098569   0.013002  \n",
       "22                    0.895425         0.098569   0.013002  \n",
       "23                    0.895425         0.098569   0.013002  \n",
       "24                    0.895425         0.098569   0.013002  \n",
       "25                    0.895425         0.098569   0.013002  \n",
       "26                    0.895425         0.098569   0.013002  \n",
       "27                    0.895425         0.098569   0.013002  \n",
       "28                    0.895425         0.098569   0.013002  \n",
       "29                    0.895425         0.098569   0.013002  \n",
       "...                        ...              ...        ...  \n",
       "39069                 0.895425         0.098569   0.013002  \n",
       "39070                 0.895425         0.098569   0.013002  \n",
       "39071                 0.895425         0.098569   0.013002  \n",
       "39072                 0.895425         0.098569   0.013002  \n",
       "39073                 0.895425         0.098569   0.013002  \n",
       "39074                 0.895425         0.098569   0.013002  \n",
       "39075                 0.895425         0.098569   0.013002  \n",
       "39076                 0.895425         0.098569   0.013002  \n",
       "39077                 0.895425         0.098569   0.013002  \n",
       "39078                 0.895425         0.098569   0.013002  \n",
       "39079                 0.895425         0.098569   0.013002  \n",
       "39080                 0.895425         0.098569   0.013002  \n",
       "39081                 0.895425         0.098569   0.013002  \n",
       "39082                 0.895425         0.098569   0.013002  \n",
       "39083                 0.895425         0.098569   0.013002  \n",
       "39084                 0.895425         0.098569   0.013002  \n",
       "39085                 0.895425         0.098569   0.013002  \n",
       "39086                 0.895425         0.098569   0.013002  \n",
       "39087                 0.895425         0.098569   0.013002  \n",
       "39088                 0.895425         0.098569   0.013002  \n",
       "39089                 0.895425         0.098569   0.013002  \n",
       "39090                 0.895425         0.098569   0.013002  \n",
       "39091                 0.895425         0.098569   0.013002  \n",
       "39092                 0.895425         0.098569   0.013002  \n",
       "39093                 0.895425         0.098569   0.013002  \n",
       "39094                 0.895425         0.098569   0.013002  \n",
       "39095                 0.895425         0.098569   0.013002  \n",
       "39096                 0.895425         0.098569   0.013002  \n",
       "39097                 0.895425         0.098569   0.013002  \n",
       "39098                 0.895425         0.098569   0.013002  \n",
       "\n",
       "[39099 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_2 = regressor_2.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_2 = y_pred_2.reshape(39099,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_2}\n",
    "y_compare_2 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_2['Mean Squared Error'] = (np.diff(y_compare_2.values) ** 2)\n",
    "y_compare_2['Mean Squared Error'] = np.mean(y_compare_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_2['Root Mean Squared Error'] = y_compare_2['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_2['Mean Abs. Error'] = np.mean(abs(y_compare_2['Actual Values'] - y_compare_2['Predicted Values']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_2['R_Squared'] = r2_score(y_test, y_pred_2)\n",
    "\n",
    "y_compare_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Abs. Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.084480</td>\n",
       "      <td>-0.033485</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.072782</td>\n",
       "      <td>0.263526</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112014</td>\n",
       "      <td>-0.022144</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059294</td>\n",
       "      <td>-0.038433</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.046479</td>\n",
       "      <td>-0.042170</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009217</td>\n",
       "      <td>-0.020358</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.008194</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-0.045689</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.042042</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.072782</td>\n",
       "      <td>-0.037589</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.039806</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.068953</td>\n",
       "      <td>-0.042185</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.067829</td>\n",
       "      <td>-0.035054</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.043390</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.036519</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.064184</td>\n",
       "      <td>0.086452</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.029573</td>\n",
       "      <td>-0.021156</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.033817</td>\n",
       "      <td>-0.023251</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.080906</td>\n",
       "      <td>-0.013787</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.099322</td>\n",
       "      <td>-0.036310</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.078543</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.036384</td>\n",
       "      <td>-0.186804</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.067829</td>\n",
       "      <td>-0.053572</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.076146</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.045703</td>\n",
       "      <td>-0.022741</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.066602</td>\n",
       "      <td>-0.051962</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156362</th>\n",
       "      <td>-0.040846</td>\n",
       "      <td>-0.025900</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156363</th>\n",
       "      <td>-0.016099</td>\n",
       "      <td>-0.049725</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156364</th>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.045478</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156365</th>\n",
       "      <td>-0.143639</td>\n",
       "      <td>-0.018152</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156366</th>\n",
       "      <td>-0.035768</td>\n",
       "      <td>-0.044066</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156367</th>\n",
       "      <td>-0.028425</td>\n",
       "      <td>-0.015346</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156368</th>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.036687</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156369</th>\n",
       "      <td>-0.162813</td>\n",
       "      <td>0.200737</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156370</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.040051</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156371</th>\n",
       "      <td>0.202220</td>\n",
       "      <td>-0.043600</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156372</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.033746</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156373</th>\n",
       "      <td>-0.078494</td>\n",
       "      <td>-0.458163</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156374</th>\n",
       "      <td>-0.046517</td>\n",
       "      <td>-0.040644</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156375</th>\n",
       "      <td>-0.051497</td>\n",
       "      <td>-0.031755</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156376</th>\n",
       "      <td>-0.026282</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156377</th>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.021923</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156378</th>\n",
       "      <td>-0.184994</td>\n",
       "      <td>-0.034290</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156379</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>-0.043262</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156380</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.036284</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156381</th>\n",
       "      <td>-0.188500</td>\n",
       "      <td>0.041325</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156382</th>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.032751</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156383</th>\n",
       "      <td>-0.379656</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156384</th>\n",
       "      <td>-0.090653</td>\n",
       "      <td>-0.038012</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156385</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.040280</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156386</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.043252</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156387</th>\n",
       "      <td>-0.078494</td>\n",
       "      <td>-0.029862</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156388</th>\n",
       "      <td>-0.080863</td>\n",
       "      <td>-0.025895</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156389</th>\n",
       "      <td>-0.033595</td>\n",
       "      <td>-0.036217</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156390</th>\n",
       "      <td>-0.104989</td>\n",
       "      <td>-0.030671</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156391</th>\n",
       "      <td>-0.000773</td>\n",
       "      <td>-0.047730</td>\n",
       "      <td>1.035409</td>\n",
       "      <td>1.017551</td>\n",
       "      <td>0.104573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156392 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                     -0.084480                   -0.033485   \n",
       "1                     -0.072782                    0.263526   \n",
       "2                     -0.112014                   -0.022144   \n",
       "3                     -0.059294                   -0.038433   \n",
       "4                     -0.046479                   -0.042170   \n",
       "5                      0.009217                   -0.020358   \n",
       "6                     -0.008194                    0.000324   \n",
       "7                     -0.027183                   -0.045689   \n",
       "8                     -0.033595                   -0.042042   \n",
       "9                     -0.090653                   -0.005012   \n",
       "10                    -0.072782                   -0.037589   \n",
       "11                    -0.048927                   -0.039806   \n",
       "12                     0.068953                   -0.042185   \n",
       "13                    -0.067829                   -0.035054   \n",
       "14                     0.006270                    0.019742   \n",
       "15                    -0.026282                   -0.043390   \n",
       "16                    -0.091704                   -0.059021   \n",
       "17                    -0.050341                   -0.036519   \n",
       "18                     0.064184                    0.086452   \n",
       "19                    -0.029573                   -0.021156   \n",
       "20                    -0.033817                    0.016053   \n",
       "21                    -0.033817                   -0.023251   \n",
       "22                    -0.080906                   -0.013787   \n",
       "23                    -0.099322                   -0.036310   \n",
       "24                    -0.078543                    0.028071   \n",
       "25                    -0.036384                   -0.186804   \n",
       "26                    -0.067829                   -0.053572   \n",
       "27                    -0.091704                   -0.076146   \n",
       "28                    -0.045703                   -0.022741   \n",
       "29                    -0.066602                   -0.051962   \n",
       "...                         ...                         ...   \n",
       "156362                -0.040846                   -0.025900   \n",
       "156363                -0.016099                   -0.049725   \n",
       "156364                -0.050341                   -0.045478   \n",
       "156365                -0.143639                   -0.018152   \n",
       "156366                -0.035768                   -0.044066   \n",
       "156367                -0.028425                   -0.015346   \n",
       "156368                 0.187202                   -0.036687   \n",
       "156369                -0.162813                    0.200737   \n",
       "156370                -0.026282                   -0.040051   \n",
       "156371                 0.202220                   -0.043600   \n",
       "156372                -0.033595                   -0.033746   \n",
       "156373                -0.078494                   -0.458163   \n",
       "156374                -0.046517                   -0.040644   \n",
       "156375                -0.051497                   -0.031755   \n",
       "156376                -0.026282                    0.029255   \n",
       "156377                -0.048927                   -0.021923   \n",
       "156378                -0.184994                   -0.034290   \n",
       "156379                 0.001314                   -0.043262   \n",
       "156380                -0.033595                   -0.036284   \n",
       "156381                -0.188500                    0.041325   \n",
       "156382                -0.031418                   -0.032751   \n",
       "156383                -0.379656                    0.036452   \n",
       "156384                -0.090653                   -0.038012   \n",
       "156385                -0.033595                   -0.040280   \n",
       "156386                -0.033595                   -0.043252   \n",
       "156387                -0.078494                   -0.029862   \n",
       "156388                -0.080863                   -0.025895   \n",
       "156389                -0.033595                   -0.036217   \n",
       "156390                -0.104989                   -0.030671   \n",
       "156391                -0.000773                   -0.047730   \n",
       "\n",
       "        Mean Squared Error  Root Mean Squared Error  Mean Abs. Error  \n",
       "0                 1.035409                 1.017551         0.104573  \n",
       "1                 1.035409                 1.017551         0.104573  \n",
       "2                 1.035409                 1.017551         0.104573  \n",
       "3                 1.035409                 1.017551         0.104573  \n",
       "4                 1.035409                 1.017551         0.104573  \n",
       "5                 1.035409                 1.017551         0.104573  \n",
       "6                 1.035409                 1.017551         0.104573  \n",
       "7                 1.035409                 1.017551         0.104573  \n",
       "8                 1.035409                 1.017551         0.104573  \n",
       "9                 1.035409                 1.017551         0.104573  \n",
       "10                1.035409                 1.017551         0.104573  \n",
       "11                1.035409                 1.017551         0.104573  \n",
       "12                1.035409                 1.017551         0.104573  \n",
       "13                1.035409                 1.017551         0.104573  \n",
       "14                1.035409                 1.017551         0.104573  \n",
       "15                1.035409                 1.017551         0.104573  \n",
       "16                1.035409                 1.017551         0.104573  \n",
       "17                1.035409                 1.017551         0.104573  \n",
       "18                1.035409                 1.017551         0.104573  \n",
       "19                1.035409                 1.017551         0.104573  \n",
       "20                1.035409                 1.017551         0.104573  \n",
       "21                1.035409                 1.017551         0.104573  \n",
       "22                1.035409                 1.017551         0.104573  \n",
       "23                1.035409                 1.017551         0.104573  \n",
       "24                1.035409                 1.017551         0.104573  \n",
       "25                1.035409                 1.017551         0.104573  \n",
       "26                1.035409                 1.017551         0.104573  \n",
       "27                1.035409                 1.017551         0.104573  \n",
       "28                1.035409                 1.017551         0.104573  \n",
       "29                1.035409                 1.017551         0.104573  \n",
       "...                    ...                      ...              ...  \n",
       "156362            1.035409                 1.017551         0.104573  \n",
       "156363            1.035409                 1.017551         0.104573  \n",
       "156364            1.035409                 1.017551         0.104573  \n",
       "156365            1.035409                 1.017551         0.104573  \n",
       "156366            1.035409                 1.017551         0.104573  \n",
       "156367            1.035409                 1.017551         0.104573  \n",
       "156368            1.035409                 1.017551         0.104573  \n",
       "156369            1.035409                 1.017551         0.104573  \n",
       "156370            1.035409                 1.017551         0.104573  \n",
       "156371            1.035409                 1.017551         0.104573  \n",
       "156372            1.035409                 1.017551         0.104573  \n",
       "156373            1.035409                 1.017551         0.104573  \n",
       "156374            1.035409                 1.017551         0.104573  \n",
       "156375            1.035409                 1.017551         0.104573  \n",
       "156376            1.035409                 1.017551         0.104573  \n",
       "156377            1.035409                 1.017551         0.104573  \n",
       "156378            1.035409                 1.017551         0.104573  \n",
       "156379            1.035409                 1.017551         0.104573  \n",
       "156380            1.035409                 1.017551         0.104573  \n",
       "156381            1.035409                 1.017551         0.104573  \n",
       "156382            1.035409                 1.017551         0.104573  \n",
       "156383            1.035409                 1.017551         0.104573  \n",
       "156384            1.035409                 1.017551         0.104573  \n",
       "156385            1.035409                 1.017551         0.104573  \n",
       "156386            1.035409                 1.017551         0.104573  \n",
       "156387            1.035409                 1.017551         0.104573  \n",
       "156388            1.035409                 1.017551         0.104573  \n",
       "156389            1.035409                 1.017551         0.104573  \n",
       "156390            1.035409                 1.017551         0.104573  \n",
       "156391            1.035409                 1.017551         0.104573  \n",
       "\n",
       "[156392 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_2 = regressor_2.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_2 = y_pred_train_2.reshape(156392,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_2 }\n",
    "y_compare_train_2 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_2['Mean Squared Error'] = (np.diff(y_compare_train_2.values) ** 2)\n",
    "y_compare_train_2['Mean Squared Error'] = np.mean(y_compare_train_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_2['Root Mean Squared Error'] = y_compare_train_2['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_train_2['Mean Abs. Error'] = np.mean(abs(y_compare_train_2['Actual Values(Training)'] - y_compare_train_2['Predicted Values(Training)']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_train['R_Squared'] = r2_score(y_train, y_pred_train_2)\n",
    "\n",
    "y_compare_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156392/156392 [==============================] - 38s 241us/step - loss: 1.0324\n",
      "Epoch 2/100\n",
      "156392/156392 [==============================] - 36s 231us/step - loss: 1.02775s -  - ETA: 4s -  - ETA: 0s - loss: 1\n",
      "Epoch 3/100\n",
      "156392/156392 [==============================] - 51s 323us/step - loss: 1.02966s - ETA: - ETA: 1s - loss:  - E\n",
      "Epoch 4/100\n",
      "156392/156392 [==============================] - 37s 239us/step - loss: 1.0279TA: 8s - loss: 0.9 - E - ETA: 2s - loss: 1.02 - ETA: 1s - loss: 1. -  - ETA: 0s - l\n",
      "Epoch 5/100\n",
      "156392/156392 [==============================] - 35s 227us/step - loss: 1.0275\n",
      "Epoch 6/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.0271\n",
      "Epoch 7/100\n",
      "156392/156392 [==============================] - 37s 240us/step - loss: 1.02784 - ETA: 1s - loss: 0 - ETA: \n",
      "Epoch 8/100\n",
      "156392/156392 [==============================] - 39s 250us/step - loss: 1.02793s - loss: \n",
      "Epoch 9/100\n",
      "156392/156392 [==============================] - 40s 256us/step - loss: 1.0282\n",
      "Epoch 10/100\n",
      "156392/156392 [==============================] - 38s 244us/step - loss: 1.0265\n",
      "Epoch 11/100\n",
      "156392/156392 [==============================] - 37s 238us/step - loss: 1.0252\n",
      "Epoch 12/100\n",
      "156392/156392 [==============================] - 38s 241us/step - loss: 1.0263\n",
      "Epoch 13/100\n",
      "156392/156392 [==============================] - 38s 241us/step - loss: 1.0261\n",
      "Epoch 14/100\n",
      "156392/156392 [==============================] - 36s 228us/step - loss: 1.0249\n",
      "Epoch 15/100\n",
      "156392/156392 [==============================] - 36s 231us/step - loss: 1.0251\n",
      "Epoch 16/100\n",
      "156392/156392 [==============================] - 38s 241us/step - loss: 1.0254\n",
      "Epoch 17/100\n",
      "156392/156392 [==============================] - 37s 236us/step - loss: 1.0264\n",
      "Epoch 18/100\n",
      "156392/156392 [==============================] - 36s 228us/step - loss: 1.0242\n",
      "Epoch 19/100\n",
      "156392/156392 [==============================] - 37s 235us/step - loss: 1.0259\n",
      "Epoch 20/100\n",
      "156392/156392 [==============================] - 39s 248us/step - loss: 1.02580s - loss:\n",
      "Epoch 21/100\n",
      "156392/156392 [==============================] - 39s 249us/step - loss: 1.0263\n",
      "Epoch 22/100\n",
      "156392/156392 [==============================] - 39s 249us/step - loss: 1.0266A: 1s - loss: 1.0 - ETA: - ETA: 0s - loss:\n",
      "Epoch 23/100\n",
      "156392/156392 [==============================] - 36s 233us/step - loss: 1.0221 \n",
      "Epoch 24/100\n",
      "156392/156392 [==============================] - 38s 241us/step - loss: 1.0278\n",
      "Epoch 25/100\n",
      "156392/156392 [==============================] - 37s 237us/step - loss: 1.0258ETA: 0s - loss: 1.0\n",
      "Epoch 26/100\n",
      "156392/156392 [==============================] - 37s 239us/step - loss: 1.02470s - loss: \n",
      "Epoch 27/100\n",
      "156392/156392 [==============================] - 38s 242us/step - loss: 1.0272\n",
      "Epoch 28/100\n",
      "156392/156392 [==============================] - 39s 248us/step - loss: 1.0246\n",
      "Epoch 29/100\n",
      "156392/156392 [==============================] - 39s 249us/step - loss: 1.0260 ETA: 0s - \n",
      "Epoch 30/100\n",
      "156392/156392 [==============================] - 40s 255us/step - loss: 1.0254\n",
      "Epoch 31/100\n",
      "156392/156392 [==============================] - 39s 247us/step - loss: 1.0263ETA: 0s - loss: 1.027\n",
      "Epoch 32/100\n",
      "156392/156392 [==============================] - 36s 233us/step - loss: 1.0269\n",
      "Epoch 33/100\n",
      "156392/156392 [==============================] - 35s 224us/step - loss: 1.02660s - loss: 1.\n",
      "Epoch 34/100\n",
      "156392/156392 [==============================] - 36s 229us/step - loss: 1.02530s - loss\n",
      "Epoch 35/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.0247\n",
      "Epoch 36/100\n",
      "156392/156392 [==============================] - 36s 228us/step - loss: 1.0238\n",
      "Epoch 37/100\n",
      "156392/156392 [==============================] - 35s 225us/step - loss: 1.0277\n",
      "Epoch 38/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.02633s - loss: -  - ETA: 0\n",
      "Epoch 39/100\n",
      "156392/156392 [==============================] - 35s 227us/step - loss: 1.0263\n",
      "Epoch 40/100\n",
      "156392/156392 [==============================] - 36s 227us/step - loss: 1.02660s - l\n",
      "Epoch 41/100\n",
      "156392/156392 [==============================] - 35s 225us/step - loss: 1.0244\n",
      "Epoch 42/100\n",
      "156392/156392 [==============================] - 36s 230us/step - loss: 1.0274\n",
      "Epoch 43/100\n",
      "156392/156392 [==============================] - 42s 269us/step - loss: 1.0256\n",
      "Epoch 44/100\n",
      "156392/156392 [==============================] - 42s 271us/step - loss: 1.0260\n",
      "Epoch 45/100\n",
      "152465/156392 [============================>.] - ETA: 0s - loss: 0.9986- ETA: 2s - loss: - ETA: "
     ]
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with 2 layers of 50 nodes \"\"\"\n",
    "\n",
    "regressor_3 = Sequential()\n",
    "regressor_3.add(Dense(50, kernel_initializer = 'normal',activation = 'relu',input_dim = 8))\n",
    "regressor_3.add(Dense(50, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_3.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_3.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_3.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_3 = regressor_3.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_3 = y_pred_3.reshape(39099,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_3}\n",
    "y_compare_3 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_3['Mean Squared Error'] = (np.diff(y_compare_3.values) ** 2)\n",
    "y_compare_3['Mean Squared Error'] = np.mean(y_compare_3['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_3['Root Mean Squared Error'] = y_compare_3['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_3['Mean Abs. Error'] = np.mean(abs(y_compare_3['Actual Values'] - y_compare_3['Predicted Values']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_3['R_Squared'] = r2_score(y_test, y_pred_3)\n",
    "\n",
    "y_compare_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_3 = regressor_3.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_3 = y_pred_train_3.reshape(156392,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_3 }\n",
    "y_compare_train_3 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_3['Mean Squared Error'] = (np.diff(y_compare_train_3.values) ** 2)\n",
    "y_compare_train_3['Mean Squared Error'] = np.mean(y_compare_train_3['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_3['Root Mean Squared Error'] = y_compare_train_3['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_train_3['Mean Abs. Error'] = np.mean(abs(y_compare_train_3['Actual Values(Training)'] - y_compare_train_3['Predicted Values(Training)']))\n",
    "\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_train_3['R_Squared'] = r2_score(y_train, y_pred_train_3)\n",
    "\n",
    "y_compare_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Building a 3 layer ANN with 2 layers of 20 nodes \"\"\"\n",
    "\n",
    "regressor_4 = Sequential()\n",
    "regressor_4.add(Dense(20, kernel_initializer = 'normal',activation = 'relu',input_dim = 8))\n",
    "regressor_4.add(Dense(20, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_4.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_4.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_4.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_4 = regressor_4.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_4 = y_pred_4.reshape(39099,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_4}\n",
    "y_compare_4 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_4['Mean Squared Error'] = (np.diff(y_compare_4.values) ** 2)\n",
    "y_compare_4['Mean Squared Error'] = np.mean(y_compare_4['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_4['Root Mean Squared Error'] = y_compare_4['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_4['Mean Abs. Error'] = np.mean(abs(y_compare_4['Actual Values'] - y_compare_4['Predicted Values']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_4['R_Squared'] = r2_score(y_test, y_pred_4)\n",
    "\n",
    "y_compare_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_4 = regressor_4.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_4 = y_pred_train_4.reshape(156392,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_4 }\n",
    "y_compare_train_4 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_4['Mean Squared Error'] = (np.diff(y_compare_train_4.values) ** 2)\n",
    "y_compare_train_4['Mean Squared Error'] = np.mean(y_compare_train_4['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_4['Root Mean Squared Error'] = y_compare_train_4['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_train_4['Mean Abs. Error'] = np.mean(abs(y_compare_train_4['Actual Values(Training)'] - y_compare_train_4['Predicted Values(Training)']))\n",
    "\n",
    "# Calculating R-Squared value\n",
    "y_compare_train_4['R_Squared'] = r2_score(y_train, y_pred_train_4)\n",
    "\n",
    "y_compare_train_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
